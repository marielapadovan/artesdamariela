% Encoding: UTF-8
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%	Codifica\{c}c\~ao de arquivo: UTF8, ``[utf8x]{inputenc}`` e todos os demais arquivos de entrada.	%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{dhanoa-experiment:2017,
	title = {{AN} {EXPERIMENT} {BASED} {EXAMINATION} {OF} {ENERGY} {OVERHEAD} {THROUGH} {VM} {MIGRATION}},
	volume = {8},
	issn = {0976-5697},
	url = {http://ijarcs.in/index.php/Ijarcs/article/view/5070},
	doi = {10.26483/ijarcs.v8i9.5070},
	abstract = {Abstract: The use of cloud computing has increased in recent days with tremendous benefits to users and also provoked to rise in total ownership cost due to swift increase in energy consumption of data centers. Out of various approaches, best of virtual machine placement policies can be exploited to reduce the energy consumption during migration in data centers. The virtual machine live migration during placement has enough potential to reduce energy consumption with certain level of utilization. One of the mechanisms to achieve energy efficiency is to manage the migration time parameter of live migration with appropriate network bandwidth in communication aware connected data centers. In spite of this, virtual machine size and network bandwidth have a great impact on energy consumption of sub systems during virtual machine live migration. To follow this study, in this paper, analysis has been made to see the impact of migration time on energy consumption of sub systems during guest virtual machine live migration. For experimentation, Kernel-based Virtual Machine (KVM) hypervisor and Virt Manager was used to perform live migration on Ubuntu 14.04 Linux machines in various conditions. Afterwards, the noted observations are validated with Pearson’s Correlation Coefficient statistical approach to study the strength of relationship of defined parameters.},
	number = {9},
	journal = {International Journal of Advanced Research in Computer Science},
	author = {Dhanoa, Inderjit},
	year = {2017},
	keywords = {Data center, Virtual Machine (VM), Virtualization, Energy Consumption, Live Migration},
	pages = {655--660},
	file = {Dhanoa - 2017 - AN EXPERIMENT BASED EXAMINATION OF ENERGY OVERHEAD.pdf:/home/daniel/Insync/Zotero/storage/R4JWQ6X6/Dhanoa - 2017 - AN EXPERIMENT BASED EXAMINATION OF ENERGY OVERHEAD.pdf:application/pdf}
}

@article{mostafavi-detection:2018,
	title = {Detection of repetitive and irregular hypercall attacks from guest virtual machines to {Xen} hypervisor},
	issn = {2520-8438, 2520-8446},
	url = {https://link.springer.com/article/10.1007/s42044-018-0006-5},
	doi = {10.1007/s42044-018-0006-5},
	abstract = {Virtualization is critical to the infrastructure of cloud computing environment and other online services. Hypercall interface is provided by hypervisor to offer privileged requests by the guest domains. Attackers may use this interface to send malicious hypercalls. In the reported work, repetitive hypercall attacks and sending hypercalls within irregular sequences to Xen hypervisor were analyzed, and finally, an intrusion detection system (IDS) is proposed to detect these attacks. The proposed system is placed in the host domain (Dom0). Monitoring hypercalls traffic the system operates based on the identification of irregular behaviors in hypercalls sent from guest domains to hypervisor. Later on, the association rule algorithm is applied on the collected data within a fixed time window, and a set of thresholds for maximum number of all types of the hypercalls is extracted. The results from the implementation of the proposed system show 91\% true positive rate.},
	language = {en},
	urldate = {2018-02-15},
	journal = {Iran Journal of Computer Science},
	author = {Mostafavi, Mojtaba and Kabiri, Peyman},
	month = jan,
	year = {2018},
	pages = {1--9},
	file = {Mostafavi e Kabiri - 2018 - Detection of repetitive and irregular hypercall at.pdf:/home/daniel/Insync/Zotero/storage/4DQSVAW9/Mostafavi e Kabiri - 2018 - Detection of repetitive and irregular hypercall at.pdf:application/pdf}
}

@book{kusnetzky-virtualization:2011,
	address = {Beijing ; Sebastopol},
	edition = {1 edition},
	title = {Virtualization: {A} {Manager}'s {Guide}: {Big} {Picture} of the {Who}, {What}, and {Where} of {Virtualization}},
	isbn = {978-1-4493-0645-8},
	shorttitle = {Virtualization},
	abstract = {What exactly is virtualization? As this concise book explains, virtualization is a smorgasbord of technologies that offer organizations many advantages, whether you're managing extremely large stores of rapidly changing data, scaling out an application, or harnessing huge amounts of computational power. With this guide, you get an overview of the five main types of virtualization technology, along with information on security, management, and modern use cases.Topics include:Access virtualization—Allows access to any application from any deviceApplication virtualization—Enables applications to run on many different operating systems and hardware platformsProcessing virtualization—Makes one system seem like many, or many seem like oneNetwork virtualization—Presents an artificial view of the network that differs from the physical realityStorage virtualization—Allows many systems to share the same storage devices, enables concealing the location of storage systems, and more},
	language = {English},
	publisher = {O'Reilly Media},
	author = {Kusnetzky, Dan},
	month = jul,
	year = {2011}
}

@techreport{tholeti-hypervisors:2011,
	title = {Hypervisors, virtualization, and the cloud: {Learn} about hypervisors, system virtualization, and how it works in a cloud environment},
	copyright = {© Copyright IBM Corporation 2011},
	url = {http://www.ibm.com/developerworks/cloud/library/cl-hypervisorcompare/index.html},
	abstract = {Read about hypervisor types and system virtualization in the first article of this series. This series starts with a background on hypervisor types, system virtualization, and then offers a look at the features of five hypervisors, their deployment processes, and the management issues you might encounter.},
	language = {en},
	urldate = {2018-02-15},
	institution = {IBM},
	author = {Tholeti, Bhanu P},
	month = sep,
	year = {2011},
	pages = {7},
	file = {Tholeti - 2011 - Hypervisors, virtualization, and the cloud Learn .pdf:/home/daniel/Insync/Zotero/storage/XG5F6Q7I/Tholeti - 2011 - Hypervisors, virtualization, and the cloud Learn .pdf:application/pdf}
}

@incollection{vaezi-virtualization:2017,
	series = {Wireless {Networks}},
	title = {Virtualization and {Cloud} {Computing}},
	isbn = {978-3-319-54495-3 978-3-319-54496-0},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-54496-0:2},
	abstract = {In an effort to move the networking industry from today’s manual configuration to embrace automated solutions that are coordinated with the rest of the infrastructure, there have been several emerging technologies in the past few years, chief among them are network virtualization (NV), network functions virtualization (NFV), and software-defined networking (SDN).},
	language = {en},
	urldate = {2018-02-16},
	booktitle = {Cloud {Mobile} {Networks}},
	publisher = {Springer, Cham},
	author = {Vaezi, Mojtaba and Zhang, Ying},
	year = {2017},
	note = {DOI: 10.1007/978-3-319-54496-0\_2},
	pages = {11--31}
}

@techreport{vesely-nrc:1980,
	address = {Washington, DC, USA},
	title = {{NRC}: {Fault} {Tree} {Handbook} ({NUREG}-0492)},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/staff/sr0492/},
	abstract = {Since 1975, a short course entitled "System Safety and Reliability Analysis" has been presented to over 200 NRC personnel and contractors. The course has been taught jointly by David F. Haasl, Institute of System Sciences, Professor Norman H. Roberts, University of Washington, and members of the Probabilistic Analysis Staff, NRC, as part of a risk assessment training program sponsored by the Probabilistic Analysis Staff. This handbook has been developed not only to serve as text for the System Safety and Reliability Course, but also to make available to others a set of otherwise undocumented material on fault tree construction and evaluation. The publication of this handbook is in accordance with the recommendations of the Risk Assessment Review Group Report (NUREG/CR-0400) in which it was stated that the fault/event tree methodology both can and should be used more widely by the NRC. It is hoped that this document will help to codify and systematize the fault tree approach to systems analysis.},
	number = {NUREG-0492},
	urldate = {2018-02-09},
	institution = {U.S. Nuclear Regulatory Commission},
	author = {Vesely, W.E. and Goldberg, F.F. and Roberts, N.H. and Haasl, D.F.},
	year = {1980}
}

@inproceedings{li-optimizing:2017,
	title = {Optimizing {Backup} {Resources} in the {Cloud}},
	doi = {10.1109/CLOUD.2016.107},
	abstract = {Cloud computing promises high performance and cost-efficiency; however, most cloud infrastructures operate at low utilization which greatly adhere cost effectiveness. Previous works focus on seeking efficient virtual machine (VM) consolidation strategies to increase the utilization of virtual resources in production environment, while overlooking the under-utilization of backup virtual resources. We propose a heuristic time sharing policy derived from the restless multi-armed bandit problem. The proposed policy achieves increasing backup virtual resources utilization while providing high availability. The experiment results show that the traditional 1:1 backup provision can be extended to 1:M (M≥1) between the backup VM and the service VMs, and the utilization of backup VMs can be enhanced significantly. © 2016 IEEE.},
	author = {Li, X. and Qi, Y. and Chen, P. and Zhang, X.},
	year = {2017},
	keywords = {Back up, Cloud computing, Restless multi-armed bandit, Virtualization},
	pages = {790--797},
	file = {Li et al. - 2016 - Optimizing Backup Resources in the Cloud.pdf:/home/daniel/Insync/Zotero/storage/62Q6M9M6/Li et al. - 2016 - Optimizing Backup Resources in the Cloud.pdf:application/pdf}
}

@article{sahoo-cost:2017,
	title = {Cost and energy optimisation of cloud data centres through dual {VM} modes - activation and passivation},
	volume = {18},
	issn = {1754-3916, 1754-3924},
	url = {http://www.inderscience.com/link.php?id=10004670},
	doi = {10.1504/IJCNDS.2017.10004670},
	language = {en},
	number = {3/4},
	urldate = {2018-02-06},
	journal = {International Journal of Communication Networks and Distributed Systems},
	author = {Sahoo, Choudhury N. and Goswami, Veena},
	year = {2017},
	pages = {371}
}

@inproceedings{machado-prototyping:2017,
	title = {Prototyping a high availability {PaaS}: {Performance} analysis and lessons learned},
	shorttitle = {Prototyping a high availability {PaaS}},
	doi = {10.23919/INM.2017.7987367},
	abstract = {With cloud computing consolidation, Platform-as-a-Service (PaaS) has been used as a solution for developing applications with low cost and maximum flexibility. However, an open challenge related to PaaS is the proper handling of multi-tier and stateful applications with support for high availability (HA); and scalability can be considered an essential feature for HA. However, dealing with several instances of the same application that access its state in a common area is not a simple task. This paper presents a novel PaaS framework, named NoPaaS, that supports the deployment of multi-tier and stateful applications assuring their availability according to the Service Availability Forum (SAF) redundancy model. The primary goal of this work is to present NoPaaS framework and prototype, and highlight challenges and open issues when providing multi-tier and stateful applications in high availability clouds.},
	booktitle = {2017 {IFIP}/{IEEE} {Symposium} on {Integrated} {Network} and {Service} {Management} ({IM})},
	author = {Machado, M. and Rosendo, D. and Gomes, D. and Moreira, A. and Bezerra, M. and Sadok, D. and Endo, P. T. and Curescu, C.},
	month = may,
	year = {2017},
	keywords = {cloud computing, Cloud computing, high availability PaaS framework, Measurement, Monitoring, NoPaaS, performance analysis, platform-as-a-service, Prototypes, redundancy, Redundancy, Resource management, SAF, service availability forum redundancy model, Silicon, software performance evaluation, software reliability, stateful applications},
	pages = {805--808},
	file = {Machado et al. - 2017 - Prototyping a high availability PaaS Performance .pdf:/home/daniel/Insync/Zotero/storage/9ZTFUUJW/Machado et al. - 2017 - Prototyping a high availability PaaS Performance .pdf:application/pdf}
}

@book{toeroe-service:2012,
	title = {Service {Availability}: {Principles} and {Practice}},
	isbn = {978-1-119-94167-5},
	shorttitle = {Service {Availability}},
	abstract = {Our society increasingly depends on computer-based systems; the number of applications deployed has increased dramatically in recent years and this trend is accelerating. Many of these applications are expected to provide their services continuously. The Service Availability Forum has recognized this need and developed a set of specifications to help software designers and developers to focus on the value added function of applications, leaving the availability management functions for the middleware. A practical and informative reference for the Service Availability Forum specifications, this book gives a cohesive explanation of the founding principles, motivation behind the design of the specifications, and the solutions, usage scenarios and limitations that a final system may have. Avoiding complex mathematical explanations, the book takes a pragmatic approach by discussing issues that are as close as possible to the daily software design/development by practitioners, and yet at a level that still takes in the overall picture. As a result, practitioners will be able to use the specifications as intended.  Takes a practical approach, giving guidance on the use of the specifications to explain the architecture, redundancy models and dependencies of the Service Availability (SA) Forum services Explains how service availability provides fault tolerance at the service level Clarifies how the SA Forum solution is supported by open source implementations of the middleware Includes fragments of code, simple example and use cases to give readers a practical understanding of the topic Provides a stepping stone for applications and system designers, developers and advanced students to help them understand and use the specifications},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Toeroe, Maria and Tam, Francis},
	month = mar,
	year = {2012},
	keywords = {Technology \& Engineering / Electrical, Technology \& Engineering / Mobile \& Wireless Communications},
	file = {Toeroe e Tam - 2012 - Service Availability Principles and Practice.pdf:/home/daniel/Insync/Zotero/storage/L2DB7AJQ/Toeroe e Tam - 2012 - Service Availability Principles and Practice.pdf:application/pdf}
}

@techreport{nist-sp:2012,
	address = {USA},
	type = {Institutional},
	title = {{SP} 800-30 {Rev}. 1, {Guide} for {Conducting} {Risk} {Assessments}},
	url = {https://csrc.nist.gov/publications/detail/sp/800-30/rev-1/final},
	abstract = {The purpose of Special Publication 800-30 is to provide guidance for conducting risk assessments of federal information systems and organizations, amplifying the guidance in Special Publication 800-39. Risk assessments, carried out at all three tiers in the risk management hierarchy, are part of an overall risk management process—providing senior leaders/executives with the information needed to determine appropriate courses of action in response to identified risks.},
	language = {EN-US},
	number = {SP800-30R1},
	urldate = {2018-02-07},
	institution = {NIST},
	author = {NIST},
	month = sep,
	year = {2012},
	file = {NIST - 2012 - SP 800-30 Rev. 1, Guide for Conducting Risk Assess.pdf:/home/daniel/Insync/Zotero/storage/V7RARSWM/nistspecialpublication800-30r1.pdf:application/pdf}
}

@techreport{cerin-downtime:2014,
	address = {France},
	title = {Downtime {Statistics} of {Current} {Cloud} {Solutions}},
	url = {http://iwgcr.org/wp-content/uploads/2014/03/downtime-statistics-current-1.3.pdf},
	number = {Rev 03-2014},
	institution = {International Working Group on Cloud Computing Resiliency (IWGCR)},
	author = {C\'erin, Christophe and Coti, Camille and Delort, Pierre and Diaz, Felipe and Gagnaire, Maurice and Mijic, Marija and Gaumer, Quentin and Guillaume, Nicolas and Lous, Jonathan Le and Lubiarz, Stephane and Raffaelli, Jean-Luc and Shiozaki, Kazuhiko and Schauer, Hervé and Smets, Jean-Paul and Séguin, Laurent and Ville, Alexandrine},
	month = mar,
	year = {2014},
	pages = {5},
	file = {Cérin et al. - 2014 - Downtime Statistics of Current Cloud Solutions.pdf:/home/daniel/Insync/Zotero/storage/GS2JBLL8/Cérin et al. - 2014 - Downtime Statistics of Current Cloud Solutions.pdf:application/pdf}
}

@article{sahoo-dynamic:2016,
	title = {Dynamic control and resource management for mission critical multi-tier applications in cloud data center},
	volume = {6},
	issn = {2088-8708},
	url = {http://www.iaescore.com/journals/index.php/IJECE/article/view/456},
	doi = {10.11591/ijece.v6i3.10087},
	abstract = {The multi-tier architecture style has become an industry standard in modern data centers with each tier providing certain functionality. To avoid congestion and to adhere the SLA under fluctuating workload and unpredictable failures of Mission Critical Multi-tier applications hosted in the cloud, we need a Dynamic admission control policy, such that the requests must be processed from the first tier to the last without any delay. This paper presents the least strict admission control policy, which will induce the maximal throughput, for a two-tier system with parallel servers. We propose an optimization model to minimize the total number of virtual machines for computing resources in each tier by dynamically varying the mean service rate of the VMs. Some performance indicators and computational results showing the effect of model parameters are presented. This model is also applicable to priority as well as real-time based applications in Cloud based environment.},
	language = {en},
	number = {3},
	journal = {International Journal of Electrical and Computer Engineering (IJECE)},
	author = {Sahoo, C.N. and Goswami, V.},
	month = jun,
	year = {2016},
	keywords = {Cloud computing, Dynamic control, Multi-tier application, Queueing, Resource management, Virtual machines},
	pages = {1023--1030},
	file = {Sahoo e Goswami - 2016 - Dynamic control and resource management for missio.pdf:/home/daniel/Insync/Zotero/storage/666CBWSN/Sahoo e Goswami - 2016 - Dynamic control and resource management for missio.pdf:application/pdf}
}

@article{nguyen-availability:2016,
	title = {Availability modeling and analysis of a data center for disaster tolerance},
	volume = {56},
	issn = {0167-739X},
	url = {http://www.sciencedirect.com/science/article/pii/S0167739X15002824},
	doi = {10.1016/j.future.2015.08.017},
	abstract = {Availability assessment of a data center with disaster tolerance (DT) is demanding for cloud computing based businesses. Previous work attempted to model and analyze the computing systems without a good consideration on disaster occurrence, unexpected failure of network connection and proper dependencies between subsystems in a data center. This paper presents a comprehensive availability model of a data center for DT using stochastic reward nets (SRN). The model incorporates (i) a typical two-level high availability (HA) configuration (i.e., active/active between sites and active/passive within a site), (ii) various fault and disaster tolerant techniques; (iii) dependencies between subsystems (e.g. between a host and virtual machines (VMs), between a network area storage (NAS) and VMs) and dependency between disastrous events and physical subsystems; and (iv) unexpected failures during data transmission between data centers. The constructed SRN model is analyzed on the basis of steady state analysis, downtime cost analysis, and sensitivity analysis with regard to major impacting parameters. The analysis results show the availability improvement of the disaster tolerant data center (DTDC) and featured system responses corresponding to the selected variables. The modeling and analysis of the DTDC in this paper provide a selection basis of designing for disasters in consideration of the trade-off between system availability and downtime cost with infrastructure construction cost.},
	urldate = {2018-02-07},
	journal = {Future Generation Computer Systems},
	author = {Nguyen, Tuan Anh and Kim, Dong Seong and Park, Jong Sou},
	month = mar,
	year = {2016},
	keywords = {Availability, Disaster tolerant data center, Stochastic reward nets, Virtualization},
	pages = {27--50},
	file = {Nguyen et al. - 2016 - Availability modeling and analysis of a data cente.pdf:/home/daniel/Insync/Zotero/storage/DH82GCQG/Nguyen et al. - 2016 - Availability modeling and analysis of a data cente.pdf:application/pdf}
}

@inproceedings{nguyen-model-based:2017,
	series = {Lecture {Notes} of the {Institute} for {Computer} {Sciences}, {Social} {Informatics} and {Telecommunications} {Engineering}},
	title = {Model-{Based} {Sensitivity} of a {Disaster} {Tolerant} {Active}-{Active} {GENESIS} {Cloud} {System}},
	isbn = {978-3-319-74175-8 978-3-319-74176-5},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-74176-5:20},
	doi = {10.1007/978-3-319-74176-5:20},
	abstract = {Modern cloud computing systems are prone to disasters. And the true cost due to service outages is reportedly huge. Some of previous works presented the use of hierarchical models: fault tree (FT), reliability block diagram (RBD) along with state-space models: continuous time Markov chain (CTMC) or stochastic petri nets (SPN) to assess the reliability/availability of cloud systems, but with much simplification. In this paper, we attempt to propose a combinatorial monolithic model using reliability graph (RG) for a real-world cloud system called general purpose integrated cloud system (GENESIS). The system is designed in active-active high availability configuration with two geographically distributed cloud sites for the sake of disaster tolerance (DT). We then present the model-based comprehensive analysis of system reliability/availability and their sensitivity. The results pinpoint different findings in which the architecture of active-active and geographically dispersed sites with appropriate interconnections of the cloud apparently enhance the system reliability/availability and assure disaster tolerance for the cloud.},
	language = {en},
	urldate = {2018-02-07},
	booktitle = {Industrial {Networks} and {Intelligent} {Systems}},
	publisher = {Springer, Cham},
	author = {Nguyen, Tuan Anh and Rui, Xuhua and Lim, Damsub and Oh, Jun and Min, Dugki and Choi, Eunmi and Thang, Tran Duc and Son, Nguyen Nhu},
	month = sep,
	year = {2017},
	pages = {228--241},
	file = {Nguyen et al. - 2017 - Model-Based Sensitivity of a Disaster Tolerant Act.pdf:/home/daniel/Insync/Zotero/storage/HHL2RNRN/Nguyen et al. - 2017 - Model-Based Sensitivity of a Disaster Tolerant Act.pdf:application/pdf}
}

@book{iorga-cloud:2016,
	address = {Boca Raton},
	edition = {1st, Chapter 3},
	series = {Cloud {Computing} {Security}: {Foundations} and {Challenges}},
	title = {Cloud {Computing} {Security} {Essentials} and {Architecture}},
	isbn = {978-1-4822-6095-3},
	url = {https://csrc.nist.gov/publications/detail/book/2016/cloud-computing-security-essentials-and-architecture},
	abstract = {This chapter discusses the essential security challenges and requirements for cloud consumers that intend to adopt cloud-based solutions for their information systems.},
	language = {EN-US},
	urldate = {2018-02-07},
	publisher = {CRC Press},
	author = {Iorga, Michaela and Karmel, Anil},
	editor = {Vacca, John R.},
	year = {2016}
}

@misc{uptime-institute-tier:2018,
	type = {Institutional},
	title = {Tier {Certification} {System}},
	shorttitle = {Tier {Certification}},
	url = {https://uptimeinstitute.com/tiers},
	abstract = {Tiers is the global language of data center performance Tier Classification System Uptime Institute created the standard Tier Classification System as a me...},
	language = {pt},
	urldate = {2018-02-07},
	journal = {Uptime Institute: Tier Certification},
	author = {{Uptime Institute}},
	year = {2018}
}

@article{scarpiniti-energy:2018,
	title = {Energy performance of heuristics and meta-heuristics for real-time joint resource scaling and consolidation in virtualized networked data centers},
	issn = {0920-8542, 1573-0484},
	url = {https://link.springer.com/article/10.1007/s11227-018-2244-6},
	doi = {10.1007/s11227-018-2244-6},
	abstract = {In this paper, we explore on a comparative basis the performance suitability of meta-heuristic, sometime denoted as random search algorithms, and greedy-type heuristics for the energy-saving joint dynamic scaling and consolidation of the network-plus-computing resources hosted by networked virtualized data centers when the target is the support of real-time streaming-type applications. For this purpose, the energy and delay performances of Tabu Search (TS), Simulated Annealing (SA) and Evolutionary Strategy (ES) meta-heuristics are tested and compared with the corresponding ones of Best-Fit Decreasing-type heuristics, in order to give insight on the resulting performance-versus-implementation complexity trade-offs. In principle, the considered meta-heuristics and heuristics are general formal approaches that can be applied to large classes of (typically, non-convex and mixed integer) optimization problems. However, specially for the meta-heuristics, a main challenge is to design them to properly address the real-time joint computing-plus-networking resource consolidation and scaling optimization problem. To this purpose, the aim of this paper is: (i) introduce a novel Virtual Machine Allocation (VMA) scheme that aims at choosing a suitable set of possible Virtual Machine placements among the (possibly, non-homogeneous) set of available servers; (ii) propose a new class of random search algorithms (RSAs) denoted as consolidation meta-heuristic, considering the VMA problem in RSAs. In particular, the design of novel variants of meta-heuristics, namely TS-RSC, SA-RSC and ES-RSC, is particularized to the resource scaling and consolidation (RSC) problem; (iii) compare the results of the obtained new RSAs class against some state-of-the-art heuristic approaches. A set of experimental results, both simulated and real-world ones, support the effectiveness of the proposed approaches against the traditional ones.},
	language = {en},
	urldate = {2018-01-30},
	journal = {The Journal of Supercomputing},
	author = {Scarpiniti, Michele and Baccarelli, Enzo and Naranjo, Paola G. Vinueza and Uncini, Aurelio},
	month = jan,
	year = {2018},
	pages = {1--38},
	file = {Scarpiniti et al. - 2018 - Energy performance of heuristics and meta-heuristi.pdf:/home/daniel/Insync/Zotero/storage/JF47ZHXN/Scarpiniti et al. - 2018 - Energy performance of heuristics and meta-heuristi.pdf:application/pdf;Snapshot:/home/daniel/Insync/Zotero/storage/CH9U28P7/Scarpiniti et al. - 2018 - Energy performance of heuristics and meta-heuristi.html:text/html}
}

@misc{cenelec-importance:2018,
	title = {The {Importance} of {Standards}  - {CEN}-{CENELEC}},
	url = {https://www.cencenelec.eu/research/tools/ImportanceENs/Pages/default.aspx},
	urldate = {2018-01-31},
	author = {CENELEC},
	year = {2018}
}

@article{blind-impact:2017,
	title = {The impact of standards and regulation on innovation in uncertain markets},
	volume = {46},
	issn = {0048-7333},
	url = {http://www.sciencedirect.com/science/article/pii/S0048733316301743},
	doi = {10.1016/j.respol.2016.11.003},
	abstract = {This study analyses the impact of formal standards and regulation on firms’ innovation efficiency, considering different levels of market uncertainty. We argue that formal standards and regulation have different effects, depending on the extent of market uncertainty derived from theoretical considerations about information asymmetry and regulatory capture. Our empirical analysis is based on the German Community Innovation Survey (CIS). The results show that formal standards lead to lower innovation efficiency in markets with low uncertainty, while regulations have the opposite effect. In cases of high market uncertainty, we observe that regulation leads to lower innovation efficiency, while formal standards have the reverse effect. Our results have important implications for the future application of both instruments, showing that their benefits heavily depend on the market environment.},
	number = {1},
	urldate = {2018-02-01},
	journal = {Research Policy},
	author = {Blind, Knut and Petersen, Sören S. and Riillo, Cesare A. F.},
	month = feb,
	year = {2017},
	keywords = {Formal standardization, Information asymmetry, Innovation, Innovation efficiency, Regulation, Regulatory capture},
	pages = {249--264},
	file = {Blind et al. - 2017 - The impact of standards and regulation on innovati.pdf:/home/daniel/Insync/Zotero/storage/264CJLTT/Blind et al. - 2017 - The impact of standards and regulation on innovati.pdf:application/pdf}
}

@techreport{stroyan-study:2013,
	address = {UK},
	type = {{TechReport}},
	title = {Study  on  the  contribution  of standardization to innovation in {European}-funded research projects},
	url = {https://www.cencenelec.eu/standards/Education/JointWorkingGroup/Documents/Study-Contribution-Standardization-Innovation-Final2013.pdf},
	number = {Final},
	institution = {technopolis  Group},
	author = {Stroyan, James and Brown, Neil},
	month = sep,
	year = {2013},
	pages = {122}
}

@article{marrone-automatic:2015,
	series = {The 6th {International} {Conference} on {Ambient} {Systems}, {Networks} and {Technologies} ({ANT}-2015), the 5th {International} {Conference} on {Sustainable} {Energy} {Information} {Technology} ({SEIT}-2015)},
	title = {Automatic {Resource} {Allocation} for {High} {Availability} {Cloud} {Services}},
	volume = {52},
	issn = {1877-0509},
	url = {http://www.sciencedirect.com/science/article/pii/S187705091500976X},
	doi = {10.1016/j.procs.2015.05.176},
	abstract = {This paper proposes an approach to support cloud brokers finding optimal configurations in the deployment of dependability and security sensitive cloud applications. The approach is based on model-driven principles and uses both UML and Bayesian Networks to capture, analyse and optimise cloud deployment configurations. While the paper is most focused on the initial allocation phase, the approach is extensible to the operational phases of the life-cycle. In such a way, a continuous improvement of cloud applications may be realised by monitoring, enforcing and re-negotiating cloud resources following detected anomalies and failures.},
	urldate = {2018-02-01},
	journal = {Procedia Computer Science},
	author = {Marrone, Stefano and Nardone, Roberto},
	month = jan,
	year = {2015},
	keywords = {Bayesian Networks, MARTE-DAM, Model-Driven Engineering, Resiliency, Virtual Machine Allocation},
	pages = {980--987},
	file = {Marrone e Nardone - 2015 - Automatic Resource Allocation for High Availabilit.pdf:/home/daniel/Insync/Zotero/storage/87QGKIBB/Marrone e Nardone - 2015 - Automatic Resource Allocation for High Availabilit.pdf:application/pdf}
}

@article{huang-new:2018,
	title = {A new non-parametric estimator for instant system availability},
	volume = {118},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947317301949},
	doi = {10.1016/j.csda.2017.09.001},
	abstract = {Instant availability of a repairable system is a very important measure of its performance. Among the extensive literature in system availability of the steady state, which is the limit of instant availability as time approaches infinity, many methods and approaches have been explored. However, less has been done on instant system availability owing to its theoretical and computational challenges. A new non-parametric estimator of instant availability is proposed. This estimator is both asymptotically consistent and efficient in numerical computation. Multiple numerical simulations are presented to demonstrate the performance of the new estimator.},
	urldate = {2018-02-01},
	journal = {Computational Statistics \& Data Analysis},
	author = {Huang, Kai and Mi, Jie},
	month = feb,
	year = {2018},
	keywords = {Block-by-Block method, Instant availability, Integral equation, Kernel estimation},
	pages = {18--29},
	file = {ScienceDirect Full Text PDF:/home/daniel/Insync/Zotero/storage/QYQL8PAN/Huang e Mi - 2018 - A new non-parametric estimator for instant system .pdf:application/pdf}
}

@misc{iso-iec-jtc:2018,
	author = {{ISO}},
	year = {2018},
	institution = {{ISO}},
	title = {{ISO}/{IEC} {JTC} 1/{SC} 27 - {IT} {Security} techniques},
	url = {https://www.iso.org/committee/45306.html},
	urldate = {2018-02-02}
}

@article{toy-high:2017,
	series = {Complex {Adaptive} {Systems} {Conference} with {Theme}: {Engineering} {Cyber} {Physical} {Systems}, {CAS} {October} 30 – {November} 1, 2017, {Chicago}, {Illinois}, {USA}},
	title = {High {Availability} {Layers} and {Failure} {Recovery} {Timers} for {Virtualized} {Systems} and {Services}},
	volume = {114},
	issn = {1877-0509},
	url = {http://www.sciencedirect.com/science/article/pii/S1877050917318227},
	doi = {10.1016/j.procs.2017.09.028},
	abstract = {Highly available virtualized systems and services are required for applications that are sensitive to down time. The availability of virtualized systems and services needs to be on par with that for non-virtualized systems and services. However, high availability (HA) designs for virtualized systems and services are much more complicated than those for their non-virtualized counterparts due to the existence of independent multiple layers where each layer may have its own failure recovery mechanism. This paper defines a novel approach to the design of highly available virtualized systems and services. The recovery from failures is self-coordinated. There are no race conditions among layers.},
	urldate = {2018-02-02},
	journal = {Procedia Computer Science},
	author = {Toy, Mehmet},
	month = jan,
	year = {2017},
	keywords = {Availability, Failure, Recovery, Services, Systems, Timer, Virtualized},
	pages = {126--131},
	file = {Toy - 2017 - High Availability Layers and Failure Recovery Time.pdf:/home/daniel/Insync/Zotero/storage/7XJCZICH/Toy - 2017 - High Availability Layers and Failure Recovery Time.pdf:application/pdf}
}

@misc{beierl-high:2017,
	type = {Organization},
	title = {High {Availability} {For} {OPNFV}},
	url = {https://wiki.opnfv.org/display/availability/High+Availability+For+OPNFV},
	abstract = {This project is focused on the high availability requirements of the OPNFV platform, with regards to the Carrier Grade NFV scenarios. In this project, we address HA requirements and solutions in 3 different perspectives; the hardware HA, the virtual infrastructure HA and the service HA, to be specific. Requirement and API definition of high availability of OPNFV will be output from this project.},
	urldate = {2018-02-04},
	journal = {Opnfv.org},
	author = {Beierl, Mark},
	month = oct,
	year = {2017},
	file = {High Availability For OPNFV - High Availability for OPNFV - OPNFV Wiki:/home/daniel/Insync/Zotero/storage/IDRKDQZF/High+Availability+For+OPNFV.html:text/html}
}

@article{thorat-rapid:2017,
	title = {Rapid recovery from link failures in software-defined networks},
	volume = {19},
	issn = {1229-2370},
	doi = {10.1109/JCN.2017.000105},
	abstract = {Carrier-grade networks (CGNs) can leverage the network programmability of software-defined networking (SDN) to ensure fast recovery and high availability. However, for the successful adoption of SDN, the failure recovery requirement must be addressed. Local detouring is a popular approach for faster recovery rather than path-based end-to-end recovery. For fast local recovery, alternate paths must be preinstalled for each individual flow on the link, which in some cases results in storing thousands of alternate path flow rules. Furthermore, the dependence on the controller for dynamic per-flow detouring may delay the recovery. In this paper, we propose local immediate (LIm) and immediate controller dependent (ICoD) recovery mechanisms to address the limitations of OpenFlow-based link recovery approaches. Our proposed mechanisms considerably reduce the alternate path flow rules by aggregating the disrupted flows using virtual local area network (VLAN) tagging. The proposed algorithms achieve recovery within 3 ms and 20 ms, respectively and satisfy the strict 50 ms recovery requirement of CGNs. LIm and ICoD also reduce the alternate path flow storage requirement by up to 99\%. Simulation results reveal that the flow-aggregation also reduces the effort of the controller and minimizes the alternate path installation traffic.},
	number = {6},
	journal = {Journal of Communications and Networks},
	author = {Thorat, P. and Raza, S. M. and Kim, D. S. and Choo, H.},
	month = dec,
	year = {2017},
	keywords = {Delays, Switches, Network topology, Fault tolerance, network management, network reliability, OpenFlow, Ports (Computers), Routing, software-defined networking, Topology},
	pages = {648--665}
}

@article{casellas-highly:2017,
	title = {Highly available {SDN} control of flexi-grid networks with network function virtualization-enabled replication},
	volume = {9},
	issn = {1943-0620},
	doi = {10.1364/JOCN.9.00A207},
	abstract = {New trends and emerging requirements have driven the development of extensions to the path computation element (PCE) architecture beyond the computation of a set of constrained routes and associated resources between endpoints, given a network topology. Such extensions involve the use of a PCE for the control of network services, in which deploying a PCE as a centralized network controller facilitates the adoption of software-defined networking (SDN) principles while allowing a progressive migration of already existing deployments. A key requirement for the adoption of centralized control solutions is the ability to deploy a resilient, secure, dynamically configurable, adaptive, and highly available (virtualized) infrastructure supporting end-to-end services, including critical and vertical ones. Part of this infrastructure is the control plane functional elements (e.g., controllers), and the use of network function virtualization (NFV) is a enabler for the high availability of such elements while additionally reducing OPEX and CAPEX. NFV provides a feature-complete framework for the replication of software components that is a straightforward and commonly adopted approach to address the aforementioned requirement, but it implies the need for timely synchronization of databases between replicas. In this paper we present, implement, and validate an architecture for PCE and SDN control high availability, combining the virtualization of the control function by means of dynamic replication and the timely synchronization of their internal state using the PCEP and BGP-LS protocols. We experimentally validate the approach with a testbed, including a GMPLS/PCE control plane, and a replica management system implemented following the ETSI NFV framework, using the OpenStack cloud management software.},
	number = {2},
	journal = {IEEE/OSA Journal of Optical Communications and Networking},
	author = {Casellas, R. and Vilalta, R. and Martínez, R. and Muñoz, R.},
	month = feb,
	year = {2017},
	keywords = {Computer architecture, Protocols, Software, Synchronization, cloud computing, software components, synchronisation, virtualisation, software defined networking, telecommunication network topology, High availability, software-defined networking, BGP-LS protocols, database synchronization, Databases, dynamic replication, ETSI NFV framework, flexi-grid networks, Flexi-grid networks control and management, GMPLS-PCE control plane, multiprotocol label switching, Network function virtualization, Network function virtualization (NFV), network function virtualization-enabled replication, network topology, OpenStack cloud management software, optical fibre networks, Path computation element (PCE), path computation element architecture, replica management system, Replication, SDN control, Software-defined networking (SDN)},
	pages = {A207--A215}
}

@article{suh-toward:2017,
	title = {Toward {Highly} {Available} and {Scalable} {Software} {Defined} {Networks} for {Service} {Providers}},
	volume = {55},
	issn = {0163-6804},
	doi = {10.1109/MCOM.2017.1600170},
	abstract = {Software-defined networking is moving from its initial deployment in small-scale data center networks to large-scale carrier-grade networks. In such environments, high availability and scalability are two of the most prominent issues, and thus extensive work is ongoing. In this article, we first review the state of the art on high availability and scalability issues in SDN and investigate relevant open source activities. In particular, two well-known open source projects, OpenDaylight (ODL) and Open Network Operating System (ONOS), are analyzed in terms of high availability (i.e., network state database replication/synchronization and controller failover mechanisms) and scalability (i.e., network state database partition/ distribution and controller assignment mechanisms) issues. We also present experimental results on the flow rule installation/read throughput and the failover time upon a controller failure in ONOS and ODL, and identify open research challenges.},
	number = {4},
	journal = {IEEE Communications Magazine},
	author = {Suh, D. and Jang, S. and Han, S. and Pack, S. and Kim, M. S. and Kim, T. and Lim, C. G.},
	month = apr,
	year = {2017},
	keywords = {Control systems, Synchronization, computer centres, operating systems (computers), software defined networking, SDN, carrier-grade networks, controller assignment mechanisms, controller failover mechanisms, data center networks, Distributed databases, flow rule installation, network state database partition-distribution, network state database replication-synchronization, ODL, ONOS, Open Network Operating System, open source projects, OpenDaylight, read throughput, Scalability, service providers, Software defined networking, software defined networks, Standardization, telecommunication control, telecommunication network reliability},
	pages = {100--107}
}

@article{an-cloud:2014,
	title = {A cloud middleware for assuring performance and high availability of soft real-time applications},
	volume = {60},
	issn = {1383-7621},
	url = {http://www.sciencedirect.com/science/article/pii/S1383762114000253},
	doi = {10.1016/j.sysarc.2014.01.009},
	abstract = {Applications are increasingly being deployed in the cloud due to benefits stemming from economy of scale, scalability, flexibility and utility-based pricing model. Although most cloud-based applications have hitherto been enterprise-style, there is an emerging need for hosting real-time streaming applications in the cloud that demand both high availability and low latency. Contemporary cloud computing research has seldom focused on solutions that provide both high availability and real-time assurance to these applications in a way that also optimizes resource consumption in data centers, which is a key consideration for cloud providers. This paper makes three contributions to address this dual challenge. First, it describes an architecture for a fault-tolerant framework that can be used to automatically deploy replicas of virtual machines in data centers in a way that optimizes resources while assuring availability and responsiveness. Second, it describes the design of a pluggable framework within the fault-tolerant architecture that enables plugging in different placement algorithms for VM replica deployment. Third, it illustrates the design of a framework for real-time dissemination of resource utilization information using a real-time publish/subscribe framework, which is required by the replica selection and placement framework. Experimental results using a case study that involves a specific replica placement algorithm are presented to evaluate the effectiveness of our architecture.},
	number = {9},
	urldate = {2018-02-04},
	journal = {Journal of Systems Architecture},
	author = {An, Kyoungho and Shekhar, Shashank and Caglar, Faruk and Gokhale, Aniruddha and Sastry, Shivakumar},
	month = oct,
	year = {2014},
	keywords = {Framework, Cloud computing, High availability, Middleware, Publish/Subscribe, Quality of service, Real-time},
	pages = {757--769},
	file = {ScienceDirect Full Text PDF:/home/daniel/Insync/Zotero/storage/NFAVKE7X/An et al. - 2014 - A cloud middleware for assuring performance and hi.pdf:application/pdf}
}

@incollection{sosinsky-defining:2010,
	title = {Defining {Cloud} {Computing}},
	copyright = {Copyright © 2011 Wiley Publishing, Inc., Indianapolis, Indiana},
	isbn = {978-1-118-25567-4},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/9781118255674.ch1/summary},
	language = {en},
	urldate = {2018-02-04},
	booktitle = {Cloud {Computing} {Bible}},
	publisher = {Wiley Publishing, Inc.},
	author = {Sosinsky, Barrie},
	year = {2010},
	note = {DOI: 10.1002/9781118255674.ch1},
	keywords = {cloud computing, deployment model, NIST model, paradigm shift, service model},
	pages = {1--22}
}

@article{riekstin-survey:2017,
	title = {A {Survey} on {Metrics} and {Measurement} {Tools} for {Sustainable} {Distributed} {Cloud} {Networks}},
	volume = {PP},
	doi = {10.1109/COMST.2017.2784803},
	abstract = {Energy efficiency and emissions awareness are core capabilities for sustainable and lower cost distributed cloud networks. In this context, metrics are fundamental for comparison and management purposes, along with the methods and tools which support such metrics’ capture and analysis. However, prior works on green metrics and tools have presented only a partial view, mainly as a result of the recent advances in green networking technologies. In this survey, we present an extensive study of metrics, methods, and tools to support sustainable operations in distributed cloud networks, with the aim of providing an end-to-end and up-to-date scenario to support current and coming research, as well as to analyze existing gaps.},
	number = {99},
	journal = {IEEE Communications Surveys Tutorials},
	author = {Riekstin, A. C. and Rodrigues, B. B. and Nguyen, K. K. and Carvalho, T. C. M. d B. and Meirosu, C. and Stiller, B. and Cheriet, M.},
	year = {2017},
	keywords = {Energy consumption, Measurement, Metrics, Cloud computing, Distributed Cloud Networks, Methods, Network Management, Sustainability., Sustainable development, Tools, Tutorials},
	pages = {1--1},
	file = {Riekstin et al. - 2017 - A Survey on Metrics and Measurement Tools for Sust.pdf:/home/daniel/Insync/Zotero/storage/CQNQ6QVX/Riekstin et al. - 2017 - A Survey on Metrics and Measurement Tools for Sust.pdf:application/pdf}
}

@book{buyya-cloud:2011,
	address = {Hoboken, N.J},
	edition = {1 edition},
	title = {Cloud {Computing}: {Principles} and {Paradigms}},
	isbn = {978-0-470-88799-8},
	shorttitle = {Cloud {Computing}},
	abstract = {The primary purpose of this book is to capture the state-of-the-art in Cloud Computing technologies and applications. The book will also aim to identify potential research directions and technologies that will facilitate creation a global market-place of cloud computing services supporting scientific, industrial, business, and consumer applications. We expect the book to serve as a reference for larger audience such as systems architects, practitioners, developers, new researchers and graduate level students. This area of research is relatively recent, and as such has no existing reference book that addresses it. This book will be a timely contribution to a field that is gaining considerable research interest, momentum, and is expected to be of increasing interest to commercial developers. The book is targeted for professional computer science developers and graduate students especially at Masters level. As Cloud Computing is recognized as one of the top five emerging technologies that will have a major impact on the quality of science and society over the next 20 years, its knowledge will help position our readers at the forefront of the field.},
	language = {English},
	publisher = {Wiley},
	editor = {Buyya, Rajkumar and Broberg, James and Goscinski, Andrzej M.},
	month = mar,
	year = {2011}
}

@article{keshavarzi-adaptive:2017,
	title = {Adaptive {Resource} {Management} and {Provisioning} in the {Cloud} {Computing}: {A} {Survey} of {Definitions}, {Standards} and {Research} {Roadmaps}},
	volume = {11},
	shorttitle = {Adaptive {Resource} {Management} and {Provisioning} in the {Cloud} {Computing}},
	url = {http://itiis.org/digital-library/manuscript/1788},
	abstract = {TIIS Paper Details},
	number = {9},
	urldate = {2018-02-06},
	journal = {KSII Transactions on Internet and Information Systems},
	author = {Keshavarzi, Amin and Haghighat, Abolfazl Toroghi and Bohlouli, Mahdi},
	month = sep,
	year = {2017},
	pages = {4280--4300}
}

@inproceedings{rady-formal:2013,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Formal {Definition} of {Service} {Availability} in {Cloud} {Computing} {Using} {OWL}},
	isbn = {978-3-642-53855-1 978-3-642-53856-8},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-53856-8:24},
	doi = {10.1007/978-3-642-53856-8:24},
	abstract = {Fulfilling cloud customers needs entails describing a quality of service on top of the services functional description. Currently, the only guarantees that are offered by cloud providers are imprecise and incomplete Service Level Agreements (SLA). We present a model to describe one of the main attributes discussed in SLAs which is availability. The model is developed using Web Ontology Language OWL. And it aims at covering the different concepts of availability and availability-related attributes that should be present in a service contract in order to guarantee the quality of service the consumer is expecting.},
	language = {en},
	urldate = {2018-02-06},
	booktitle = {Computer {Aided} {Systems} {Theory} - {EUROCAST} 2013},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Rady, Mariam},
	month = feb,
	year = {2013},
	pages = {189--194}
}

@incollection{hossain-cloud:2014,
	title = {Cloud computing terms, definitions, and taxonomy},
	volume = {1},
	abstract = {Cloud computing has taken the IT industry by storm. It has ushered a new era of computing and IT delivery model. This chapter introduces terms and terminologies associated with cloud computing from a vendor neutral perspective. Readers are gradually introduced to cloud computing elements which pave the way for better understanding in later chapters. © 2015 by IGI Global. All rights reserved.},
	booktitle = {Cloud {Technology}: {Concepts}, {Methodologies}, {Tools}, and {Applications}},
	author = {Hossain, S.},
	year = {2014},
	note = {DOI: 10.4018/978-1-4666-6539-2.ch002},
	pages = {25--49}
}

@article{xiong-database:2016,
	title = {A database-specific pattern for multi-cloud high availability and disaster recovery},
	volume = {567},
	doi = {10.1007/978-3-319-33313-7_29},
	abstract = {High availability and disaster recovery (HADR) are often discussed in highly critical business systems for business function recovery and continuity concerns. With the development of cloud computing, virtual cloud services are perfectly matched to HADR scenarios, and interoperability is a significant aspect to help users to use HADR service across different cloud platforms and providers. In this paper, we present an architectural pattern describing the integration of high availability and disaster recovery. We focus on database cluster replication between private cloud and public cloud environments. This HADR pattern for database cluster replication implements both synchronous and asynchronous replication concurrently for high availability and disaster recovery purposes. To evaluate the effectiveness of this pattern, we simulate a MySQL-database-cluster HADR scenario under three strategies: hot standby, warm standby and cold standby, and analyze the performance, business continuity features and cost. © Springer International Publishing Switzerland 2016.},
	journal = {Communications in Computer and Information Science},
	author = {Xiong, H. and Fowley, F. and Pahl, C.},
	year = {2016},
	keywords = {Architecture pattern, Clustering, Database replication, Disaster recovery, High availability, Multi-cloud},
	pages = {374--388},
	file = {SCOPUS Snapshot:/home/daniel/Insync/Zotero/storage/GG9DJEKN/Xiong et al. - 2016 - A database-specific pattern for multi-cloud high a.html:text/html}
}

@article{Tange2011a,
      title = {GNU Parallel - The Command-Line Power Tool},
      author = {O. Tange},
      address = {Frederiksberg, Denmark},
      journal = {;login: The USENIX Magazine},
      month = {Feb},
      number = {1},
      volume = {36},
      url = {http://www.gnu.org/s/parallel},
      year = {2011},
      pages = {42-47},
      doi = {http://dx.doi.org/10.5281/zenodo.16303}
}


@inproceedings{nguyen-virtual:2017,
	title = {Virtual {Machine} {Boot} {Time} {Model}},
	isbn = {978-1-5090-6058-0},
	url = {http://ieeexplore.ieee.org/document/7912684/},
	doi = {10.1109/PDP.2017.58},
	urldate = {2017-11-24},
	publisher = {IEEE},
	author = {Nguyen, Thuy Linh and Lebre, Adrien},
	year = {2017},
	booktitle={2017 25th Euromicro International Conference on Parallel, Distributed and Network-Based Processing},
	pages = {430--437}
}

@inproceedings{kominos-bare:2017,
	title = {Bare-metal, virtual machines and containers in {OpenStack}},
	doi = {10.1109/ICIN.2017.7899247},
	abstract = {Cloud computing is an on-demand access model for computing resources most notably embodied by the OpenStack project. As of release Liberty, OpenStack supports provisioning Bare-metal, Virtual machine (VM) and container based hosts. These different hosts incur different overheads. Consequently, the main goal of this paper is to empirically quantify that overhead through a series of experiments. The following drivers are leveraged in this process: Ironic for Bare-metal or Metal as a Service (MaaS), nova-compute for VM-based hosts, and nova-docker for Docker based containers. We make use of a private-cloud in order to compare the different options. This cloud is then used to compare the different hosts in terms of performance (CPU, networking, disk I/O and RAM) by using various open-source benchmarking tools. We also measure boot-up times. The output of these benchmarks is collected and results are compared. In this paper we discuss our learnings as well as the different configurations and fine-tuning that we implemented. As a result, we provide a set of recommendations based on the advantages and disadvantages of each host in present and future cloud deployments. © 2017 IEEE.},
	author = {Kominos, C.G. and Seyvet, N. and Vandikas, K.},
	year = {2017},
	booktitle={20th Conference on Innovations in Clouds, Internet and Networks (ICIN), 2017},
	pages = {36--43}
}

@article{persico-measuring:2015,
	title = {Measuring {Network} {Throughput} in the {Cloud}},
	volume = {93},
	issn = {1389-1286},
	url = {http://dx.doi.org/10.1016/j.comnet.2015.09.037},
	doi = {10.1016/j.comnet.2015.09.037},
	abstract = {Cloud providers employ sophisticated virtualization techniques and strategies for sharing resources among a large number of largely uncoordinated and mutually untrusted customers. The shared networking environment, in particular, dictates the need for mechanisms to partition network resources among virtual machines. At the same time, the performance of applications deployed over these virtual machines may be heavily impacted by the performance of the underlying network, and therefore by such mechanisms. Nevertheless, due to security and commercial reasons, providers rarely provide detailed information on network organization, performance, and mechanisms employed to regulate it. In addition, the scientific literature only provides a blurred image of the network performance inside the cloud. The few available pioneer works marginally focus on this aspect, use different methodologies, operate in few limited scenarios, or report conflicting results.In this paper, we present a detailed analysis of the performance of the internal network of Amazon EC2, performed by adopting a non-cooperative experimental evaluation approach (i.e.¿not relying on provider support). Our aim is to provide a quantitative assessment of the networking performance as a function of the several variables available, such as geographic region, resource price or size. We propose a detailed methodology to perform this kind of analysis, which we believe is essential in a such complex and dynamic environment. During this analysis we have discovered and analyzed the limitations enforced by Amazon over customer traffic in terms of maximum throughput allowed. Thanks to our work it is possible to understand how the complex mechanisms enforced by the provider in order to manage its infrastructure impact the performance perceived by the cloud customers and potentially tamper with monitoring and controlling approaches previously proposed in literature. Leveraging our knowledge of the bandwidth-limiting mechanisms, we then present a clear picture of the maximum throughput achievable in Amazon EC2 network, shedding light on when and how such maximum throughput can be achieved and at which cost.},
	number = {P3},
	urldate = {2017-11-22},
	journal = {Comput. Netw.},
	author = {Persico, Valerio and Marchetta, Pietro and Botta, Alessio and Pescapè, Antonio},
	month = dec,
	year = {2015},
	keywords = {Cloud network throughput, Cloud networking monitoring and measurement, Cloud networking performance},
	pages = {408--422}
}

@article{wolski-using:2014,
	title = {Using {Parametric} {Models} to {Represent} {Private} {Cloud} {Workloads}},
	volume = {7},
	issn = {1939-1374},
	doi = {10.1109/TSC.2013.48},
	abstract = {Cloud computing has become a popular metaphor for dynamic and secure self-service access to computational and storage capabilities. In this study, we analyze and model workloads gathered from enterprise-operated commercial private clouds that implement “Infrastructure as a Service.” Our results show that 3-phase hyperexponential distributions fit using the Estimation Maximization (E-M) algorithm capture workload attributes accurately. In addition, these models of individual attributes compose to produce estimates of overall cloud performance that our results verify to be accurate. As an early study of commercial enterprise private clouds, this work provides guidance to those researching, designing, or maintaining such installations. In particular, the cloud workloads under study do not exhibit “heavy-tailed” distributional properties in the same way that “bare metal” operating systems do, potentially leading to different design and engineering tradeoffs.},
	number = {4},
	journal = {IEEE Transactions on Services Computing},
	author = {Wolski, R. and Brevik, J.},
	month = oct,
	year = {2014},
	keywords = {bare metal operating systems, cloud computing, Cloud computing, cloud performance, cloud workload, Cloud workload, Computational modeling, Data models, data privacy, Data storage, enterprise-operated commercial private clouds, estimation maximization algorithm, infrastructure as a service, parametric modeling, Parametric modeling, parametric models, performance evaluation, Performance evaluation, private cloud workload representation, self-service access},
	pages = {714--725}
}

@techreport{chen-analysis:2010,
	address = {EECS Department, University of California, Berkeley},
	title = {Analysis and lessons from a publicly available google cluster trace},
	number = {UCB/EECS-2010-95 94},
	institution = {EECS Department, University of California, Berkeley},
	author = {Chen, Yanpei and Ganapathi, Archana Sulochana and Griffith, Rean and Katz, Randy H},
	year = {2010},
	note = {UCB/EECS-2010-95 94}
}

@book{helal-replication:2006,
	title = {Replication {Techniques} in {Distributed} {Systems}},
	isbn = {978-0-306-47796-6},
	abstract = {Replication Techniques in Distributed Systems organizes and surveys the spectrum of replication protocols and systems that achieve high availability by replicating entities in failure-prone distributed computing environments. The entities discussed in this book vary from passive untyped data objects, to typed and complex objects, to processes and messages.  Replication Techniques in Distributed Systems contains definitions and introductory material suitable for a beginner, theoretical foundations and algorithms, an annotated bibliography of commercial and experimental prototype systems, as well as short guides to recommended further readings in specialized subtopics.  This book can be used as recommended or required reading in graduate courses in academia, as well as a handbook for designers and implementors of systems that must deal with replication issues in distributed systems.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Helal, Abdelsalam A. and Heddaya, Abdelsalam A. and Bhargava, Bharat B.},
	month = apr,
	year = {2006},
	keywords = {Computers / Information Technology, Computers / Systems Architecture / General, Computers / Information Theory, Computers / Networking / Hardware, Computers / Operating Systems / General, Computers / Programming / Algorithms}
}

@article{moreno-vozmediano-orchestrating:2017,
	title = {Orchestrating the {Deployment} of {High} {Availability} {Services} on {Multi}-zone and {Multi}-cloud {Scenarios}},
	issn = {1570-7873, 1572-9184},
	url = {https://link.springer.com/article/10.1007/s10723-017-9417-z},
	doi = {10.1007/s10723-017-9417-z},
	abstract = {Cloud computing has become one of the most used platforms to deploy High Availability (HA) solutions for its flexibility, on-demand provisioning, and elasticity. However, although many providers offer specific tools for HA support, like floating IPs and load balancing, the analysis of downtime at public cloud providers in previous years shows that a combination of several availability zones or cloud providers is required to achieve “five nines” availability. Besides reducing the chances of failure, the use of multiple availability zones and geographically distributed clouds may additionally bring performance and cost benefits. However, the orchestration, in an efficient and adaptive way, of HA multi-tier services in multi-zone and multi-cloud environments brings several challenges. This paper presents a novel orchestration method to automate the deployment and management of high availability multi-tier services on multiple availability zones, by introducing new affinity mechanisms, such as VM to location and role to role affinity/anti-affinity rules. Furthermore, we also extend this solution to multi-cloud scenarios, based on the replication or distribution of the service components among various clouds, along with their corresponding affinity rules.},
	language = {en},
	urldate = {2017-11-21},
	journal = {Journal of Grid Computing},
	author = {Moreno-Vozmediano, R. and Montero, R. S. and Huedo, E. and Llorente, I. M.},
	year = {2017},
	note = {DOI: 10.1007/s10723-017-9417-z},
	keywords = {Affinity and anti-affinity mechanisms, High-availability, Multi-tier services and applications, Multi-zone and multi-cloud orchestration},
	pages = {1--15},
	file = {Moreno-Vozmediano et al. - 2017 - Orchestrating the Deployment of High Availability .pdf:/home/daniel/Insync/Zotero/storage/J3E24YX8/Moreno-Vozmediano et al. - 2017 - Orchestrating the Deployment of High Availability .pdf:application/pdf}
}

@article{chen-dynamically:2017,
	title = {Dynamically {Predicting} the {Quality} of {Service}: {Batch}, {Online}, and {Hybrid} {Algorithms}},
	volume = {2017},
	shorttitle = {Dynamically {Predicting} the {Quality} of {Service}},
	url = {https://www.hindawi.com/journals/jece/2017/9547869/},
	doi = {10.1155/2017/9547869},
	abstract = {This paper studies the problem of dynamically modeling the quality of web service. The philosophy of designing practical web service recommender systems is delivered in this paper. A general system architecture for such systems continuously collects the user-service invocation records and includes both an online training module and an offline training module for quality prediction. In addition, we introduce matrix factorization-based online and offline training algorithms based on the gradient descent algorithms and demonstrate the fitness of this online/offline algorithm framework to the proposed architecture. The superiority of the proposed model is confirmed by empirical studies on a real-life quality of web service data set and comparisons with existing web service recommendation algorithms.},
	language = {en},
	urldate = {2017-11-22},
	journal = {Journal of Electrical and Computer Engineering},
	author = {Chen, Ya and Jiang, Zhong-an},
	year = {2017},
	note = {DOI: 10.1155/2017/9547869},
	file = {Chen e Jiang - 2017 - Dynamically Predicting the Quality of Service Bat.pdf:/home/daniel/Insync/Zotero/storage/VL973UF8/Chen e Jiang - 2017 - Dynamically Predicting the Quality of Service Bat.pdf:application/pdf}
}

@article{dosa-tight:2013,
	title = {Tight absolute bound for {First} {Fit} {Decreasing} bin-packing: {FFD} ({L}) <= 11/9 {OPT} ({L}) + 6/9},
	volume = {510},
	shorttitle = {Tight absolute bound for {First} {Fit} {Decreasing} bin-packing},
	doi = {10.1016/j.tcs.2013.09.007},
	abstract = {First Fit Decreasing is a classical bin-packing algorithm: the items are ordered by non-increasing size, and then in this order the next item is always packed into the first bin where it fits. For an instance L let FFD(L) and OPT(L) denote the number of bins used by algorithm FFD and by an optimal algorithm, respectively. In this paper we give the first complete proof of the inequalityFFD(L)<=11/9×OPT(L)+6/9. This result is best possible, as was shown earlier by D\'osa (2007) [3]. The asymptotic coefficient 11/9 was proved already in 1973 by Johnson, but the tight bound of the additive constant was an open question for four decades. © 2013 Elsevier B.V.},
	journal = {Theoretical Computer Science},
	author = {D\'osa, G. and Li, R. and Han, X. and Tuza, Z.},
	year = {2013},
	keywords = {First Fit Decreasing, Tight bound},
	pages = {13--61},
	annote = {Cited By :14}
}

@inproceedings{alahmadi-enhanced:2014,
	title = {Enhanced {First}-{Fit} {Decreasing} {Algorithm} for {Energy}-{Aware} {Job} {Scheduling} in {Cloud}},
	volume = {2},
	doi = {10.1109/CSCI.2014.97},
	abstract = {With the emerging of many data centers around the globe, heavy loads of large-scale commercial and scientific applications executed in the cloud call for efficient cloud resource management strategies to save energy without compromising the performance and system throughput. According to the statistics from the Data Centre Dynamic (DCD) organization, the expected energy consumption by computer servers would increase by 19\% in 2013 compared with the previous year. Such trend may continue for many years. Moreover, the estimated energy consumption of computers in the U.S. was about 2\% out of the total electricity consumption in 2010, which makes IT industry the second pollution contributor after aviation. In this paper, a novel approach for scheduling, sharing and migrating Virtual Machines (VMs) for a bag of cloud tasks is designed and developed to reduce energy consumption with guaranteed certain execution time and high system throughput. This approach is derived from an Enhanced First Fit Decreasing (EFFD) algorithm combined with our VM reuse strategy. Furthermore, virtual machine migration method is introduced to dynamically monitor the cloud situation for necessary migration. Our simulation results using Cloud Report show that EFFD with our VM reuse strategy gains higher resource utilization rate and lower energy consumption than Greedy, Round Robin (RR) and FDD without VM reuse.},
	booktitle = {2014 {International} {Conference} on {Computational} {Science} and {Computational} {Intelligence}},
	author = {Alahmadi, A. and Alnowiser, A. and Zhu, M. M. and Che, D. and Ghodous, P.},
	month = mar,
	year = {2014},
	keywords = {Algorithm design and analysis, Energy consumption, Power demand, Resource management, Scheduling, Servers, Virtual machining, cloud computing, computer centres, information technology, resource allocation, virtual machines, cloud resource management, Coud Computing, data centre dynamic organization, DCD organization, EFFD algorithm, electricity consumption, energy consumption, energy-aware job scheduling, enhanced first fit decreasing algorithm, IT industry, job shop scheduling, large-scale commercial applications, scientific applications, VM scheduling},
	pages = {69--74}
}

@inproceedings{muchalski-alocacao:2014,
	title = {Aloca{c}c\~ao de M\'aquinas Virtuais em Ambientes de Computa{c}c\~ao em Nuvem Considerando o Compartilhamento de Mem\'oria},
	abstract = {Nos ambientes de computa{c}c\~ao em nuvem, \'e importante manter sob controle a aloca{c}c\~ao de m\'aquinas virtuais nos servidores f\'isicos. Uma aloca{c}c\~ao adequada implica na redu{c}c\~ao de custos com hardware, energia e refrigera{c}c\~ao, al\'em da melhora da qualidade de servi{c}co. Hipervisores recentes implementam mecanismos para reduzir o consumo de mem\'oria RAM atrav\'es do comparti-lhamento de p\'aginas id\^enticas entre m\'aquinas virtuais. Este artigo apresenta um novo algoritmo de aloca{c}c\~ao de m\'aquinas virtuais que busca o equil\'ibrio no uso dos recursos de CPU, mem\'oria, disco e rede e, sobretudo, considera o potencial de compartilhamento de mem\'oria entre m\'aquinas virtuais. Atrav\'es de simula{c}cões em tr\^es cen\'arios distintos, verificou-se que o algoritmo \'e superior \`a abordagem padr\~ao na quest\~ao do uso equilibrado de recursos e que, con-siderando o compartilhamento de mem\'oria, houve um ganho significativo na disponibilidade deste recurso ao final das aloca{c}cões. Abstract. In cloud computing environments it is important to keep under control the allocation of virtual machines in physical servers. A good allocation brings benefits such as reduction costs in hardware, power, and cooling, also improving the quality of service. Recent hypervisors implement mechanisms to reduce RAM consumption by sharing identical pages between virtual machines. This paper presents a new algorithm for virtual machines allocation that seeks the balanced use of CPU, memory, disk, and network. In addition, it considers the potential for sharing memory among virtual machines. Simulations on three distinct scenarios demonstrate that it is superior to the standard approach when considering the balanced use of resources. Considering shared memory, there was an appreciable gain in availability of resources.},
	author = {Muchalski, Fernando and Maziero, Carlos},
	address = {Florian\'opolis/SC--Brazil},
	booktitle = {XII Workshop de Computa{c}c\~ao em Clouds e Aplica{c}cões - {WCGA} 2014},
	publisher = {XII {WCGA} 2014},
	month = {may},
	year = {2014},
	pages = {81--92},
	file = {ST3-1.pdf:/home/daniel/Insync/Zotero/storage/NBSZ8C2R/ST3-1.pdf:application/pdf}
}

@inproceedings{ihara-many-objective:2015,
	title = {Many-{Objective} {Virtual} {Machine} {Placement} for {Dynamic} {Environments}},
	abstract = {This paper presents for the first time a formulation of the Virtual Machine Placement as a Many-Objective problem (MaVMP), considering the simultaneous optimization of the following five objective functions for dynamic environments: (1) power consumption, (2) inter-VM network traffic, (3) economical revenue, (4) number of VM migrations and (5) network traffic overhead for VM migrations. To solve the formulated MaVMP
problem, a novel Memetic Algorithm is proposed. As a potentially large number of feasible solutions at any time is one of the challenges of MaVMP, five selection strategies are evaluated in order to automatically select one solution at each time. The proposed algorithm with the considered selection strategies were evaluated in two different scenarios.},
	author = {Ihara, Diego and Lopez-Pires, Fabio and Baran, Benjamin},
	month = {dec},
	year = {2015}
}

@book{beyer-site:2016,
	address = {Sebastopol, CA},
	edition = {1st},
	title = {Site {Reliability} {Engineering}},
	isbn = {978-1-4919-2912-4},
	abstract = {The overwhelming majority of a software system's lifespan is spent in use, not in design or implementation. So, why does conventional wisdom insist that software engineers focus primarily on the design and development of large-scale computing systems?In this collection of essays and articles, key members of Google's Site Reliability Team explain how and why their commitment to the entire lifecycle has enabled the company to successfully build, deploy, monitor, and maintain some of the largest software systems in the world. You'll learn the principles and practices that enable Google engineers to make systems more scalable, reliable, and efficient--lessons directly applicable to your organization.This book is divided into four sections: Introduction--Learn what site reliability engineering is and why it differs from conventional IT industry practicesPrinciples--Examine the patterns, behaviors, and areas of concern that influence the work of a site reliability engineer (SRE)Practices--Understand the theory and practice of an SRE's day-to-day work: building and operating large distributed computing systemsManagement--Explore Google's best practices for training, communication, and meetings that your organization can use},
	language = {Ingl\^es},
	publisher = {O'Reilly},
	author = {Beyer, Betsy and Petoff, Jennifer and Jones, Chris and Murphy, Niall Richard},
	year = {2016}
}

@inproceedings{ford-availability:2010,
	title = {Availability in {Globally} {Distributed} {Storage} {Systems}},
	url = {https://research.google.com/pubs/pub36737.html},
	urldate = {2017-10-27},
	booktitle = {Proceedings of the 9th {USENIX} {Symposium} on {Operating} {Systems} {Design} and {Implementation}},
	author = {Ford, Daniel and Labelle, Francois and Popovici, Florentina and Stokely, Murray and Truong, Van-Anh and Barroso, Luiz and Grimes, Carrie and Quinlan, Sean},
	year = {2010},
	file = {Ford et al. - 2010 - Availability in Globally Distributed Storage Syste.pdf:/home/daniel/Insync/Zotero/storage/NFT5AGT9/Ford et al. - 2010 - Availability in Globally Distributed Storage Syste.pdf:application/pdf}
}

@inproceedings{ferdaus-virtual:2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Virtual {Machine} {Consolidation} in {Cloud} {Data} {Centers} {Using} {ACO} {Metaheuristic}},
	isbn = {978-3-319-09872-2 978-3-319-09873-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-09873-9_26},
	doi = {10.1007/978-3-319-09873-9_26},
	abstract = {In this paper, we propose the AVVMC VM consolidation scheme that focuses on balanced resource utilization of servers across different computing resources (CPU, memory, and network I/O) with the goal of minimizing power consumption and resource wastage. Since the VM consolidation problem is strictly NP-hard and computationally infeasible for large data centers, we propose adaptation and integration of the Ant Colony Optimization (ACO) metaheuristic with balanced usage of computing resources based on vector algebra. Our simulation results show that AVVMC outperforms existing methods and achieves improvement in both energy consumption and resource wastage reduction.},
	language = {en},
	urldate = {2017-10-27},
	booktitle = {Euro-{Par} 2014 {Parallel} {Processing}},
	publisher = {Springer, Cham},
	author = {Ferdaus, Md Hasanul and Murshed, Manzur and Calheiros, Rodrigo N. and Buyya, Rajkumar},
	month = {aug},
	year = {2014},
	pages = {306--317},
	file = {Ferdaus et al. - 2014 - Virtual Machine Consolidation in Cloud Data Center.pdf:/home/daniel/Insync/Zotero/storage/AGJIVXH7/Ferdaus et al. - 2014 - Virtual Machine Consolidation in Cloud Data Center.pdf:application/pdf}
}

@misc{openstack-masakari:2017,
	title = {Masakari - {OpenStack}},
	url = {https://wiki.openstack.org/wiki/Masakari},
	urldate = {2017-10-23},
	author = {Masakari},
	year = {2017},
	file = {S6_NTTcom.pdf:/home/daniel/Insync/Zotero/storage/6ZXF3GM8/S6_NTTcom.pdf:application/pdf}
}

@inproceedings{wang-achieve:2015,
	title = {Achieve high availability about point-single failures in {OpenStack}},
	volume = {01},
	doi = {10.1109/ICCSNT.2015.7490705},
	abstract = {This paper describes a method to solve the complexity of distributed environment in cloud technology and the single-point failure problem. In this paper, we take the virtual machine failure and host failure in OpenStack into consideration. The ability of fast restoration of this service is achieved by components in OpenStack which is called ceilometer and new components named Senlin. The function is achieved by adding patches and modifying the source code in OpenStack. Ceilometer plays a role of collecting information of the virtual machine failure and host failure in OpenStack and transfers this information to Senlin. Then Senlin can make a decision to restore the failure. This clever method achieves the high availability of OpenStack. We implement the proposed method and show the effectiveness of fast restoration.},
	booktitle = {2015 4th {International} {Conference} on {Computer} {Science} and {Network} {Technology} ({ICCSNT})},
	author = {Wang, Yiping and Li, Xiaoyong},
	year = {2015},
	keywords = {ceilometer, cloud, cloud computing, Computer architecture, High Availability, IaaS, OpenStack, Reliability, Senlin, Servers, Telecommunications, Uniform resource locators, Virtual machining},
	pages = {45--48},
	file = {Wang e Li - 2015 - Achieve high availability about point-single failu.pdf:/home/daniel/Insync/Zotero/storage/CFNZT5TV/Wang e Li - 2015 - Achieve high availability about point-single failu.pdf:application/pdf}
}

@inproceedings{unuvar-predictive:2014,
	title = {A {Predictive} {Method} for {Identifying} {Optimum} {Cloud} {Availability} {Zones}},
	doi = {10.1109/CLOUD.2014.20},
	abstract = {Cloud service providers enable enterprises with the ability to place their business applications into availability zones across multiple locations worldwide. While this capability helps achieve higher availability with smaller failure rates, business applications deployed across these independent zones may experience different Quality of Service (QoS) due to heterogeneous physical infrastructures. Since the perceived QoS against specific requirements are not usually advertised by cloud providers, selecting an availability zone that would best satisfy the user requirements is a challenge. In this paper, we introduce a predictive approach to identify the cloud availability zone that maximizes satisfaction of an incoming request against a set of requirements. The predictive models are built from historical usage data for each availability zone and are updated as the nature of the zones and requests change. Simulation results show that our method successfully predicts the unpublished zone behavior from historical data and identifies the availability zone that maximizes user satisfaction against specific requirements.},
	booktitle = {2014 {IEEE} 7th {International} {Conference} on {Cloud} {Computing}},
	author = {Unuvar, M. and Doganata, Y. and Steinder, M. and Tantawi, A. and Tosi, S.},
	month = {jun},
	year = {2014},
	keywords = {availability, Availability zones, business applications, business data processing, cloud, cloud computing, cloud service providers, Data models, multiple data centers, optimum cloud availability zones, performance analysis, predictive analytics, Predictive models, QoS, quality of service, Training, unpublished zone behavior prediction, Vectors},
	pages = {72--79},
	file = {Unuvar et al. - 2014 - A Predictive Method for Identifying Optimum Cloud .pdf:/home/daniel/Insync/Zotero/storage/VQWKWHBK/Unuvar et al. - 2014 - A Predictive Method for Identifying Optimum Cloud .pdf:application/pdf}
}

@book{david-benchmarking:2014,
	title = {Benchmarking, {Consistency}, {Distributed} {Database} {Management} {Systems}, {Distributed} {Systems}, {Eventual} {Consistency}},
	isbn = {978-3-7315-0186-2},
	language = {en},
	publisher = {KIT Scientific Publishing},
	author = {David, Bermbach},
	month = jul,
	year = {2014},
	annote = {multi-az, az}
}

@inproceedings{kanso-enhancing:2017,
	title = {Enhancing {OpenStack} {Fault} {Tolerance} for {Provisioning} {Computing} {Environments}},
	doi = {10.1109/HASE.2017.27},
	abstract = {With the rise of cloud computing and virtualization of resources, cloud management systems are becoming a key differentiator for the quality of service offered by the cloud providers. OpenStack is considered the de-facto open-source cloud management system at the infrastructure as a service layer. Despite the efforts of hardening the high availability of OpenStack, its fault tolerance during the provisioning of resources is yet to be proven. In this paper we present a testing framework for the fault tolerance of OpenStack, namely TestStack. We expose the limitations of OpenStack by injecting runtime failures into a highly available OpenStack environment. Our testing results reveal inconsistencies in the behavior of OpenStack in the presence of failures that we address by proposing our solution, namely FTStack, to harden its fault tolerance.},
	booktitle = {2017 {IEEE} 18th {International} {Symposium} on {High} {Assurance} {Systems} {Engineering} ({HASE})},
	author = {Kanso, A. and Deixionne, N. and Gherbi, A. and Moghaddam, F. F.},
	month = jan,
	year = {2017},
	keywords = {cloud applications, cloud computing, Containers, fault tolerance, Fault tolerant systems, High Availability, Linux containers, load balancing, OpenStack, Servers, software components, Testing, virtual machines, Virtual machining},
	pages = {77--83},
	file = {Kanso et al. - 2017 - Enhancing OpenStack Fault Tolerance for Provisioni.pdf:/home/daniel/Insync/Zotero/storage/QM2CAGSH/Kanso et al. - 2017 - Enhancing OpenStack Fault Tolerance for Provisioni.pdf:application/pdf}
}

@article{tamura-kemari::2008,
	title = {Kemari: {Virtual} {Machine} {Synchronization} for {Fault} {Tolerance} using {DomT}},
	shorttitle = {Kemari},
	doi = {10.1.1.580.7704},
	abstract = {In recent years, Internet services have been growing in number and functionality. They are typically hosted on a number of commodity servers, and reducing the run-ning cost of these servers is a crucial problem for service},
	journal = {Xen Summit 2008, USENIX ATC '08},
	author = {Tamura, Yoshi and {Sato, Koji} and {Kihara, Seiji} and {Moriai, Satoshi}},
	month = jun,
	year = {2008},
	keywords = {2008, fault-tolerant, transparency, virtualization, xen},
	pages = {2},
	file = {0.5.kemari-kvm-forum-2010.pdf:/home/daniel/Insync/Zotero/storage/FP6S9QTQ/0.5.kemari-kvm-forum-2010.pdf:application/pdf;Tamura et al. - 2008 - Kemari Virtual Machine Synchronization for Fault .pdf:/home/daniel/Insync/Zotero/storage/ZWS4VN4K/Tamura et al. - 2008 - Kemari Virtual Machine Synchronization for Fault .pdf:application/pdf}
}

@inproceedings{machida-redundant:2010,
	title = {Redundant virtual machine placement for fault-tolerant consolidated server clusters},
	doi = {10.1109/NOMS.2010.5488431},
	abstract = {Consolidated server systems using server virtualization involves serious risks of host server failures that induce unexpected downs of all hosted virtual machines and applications. To protect applications requiring high-availability from unpredictable host server failures, redundant configuration using virtual machines can be an effective countermeasure. This paper presents a virtual machine placement method for establishing a redundant configuration against host server failures with less host servers. The proposed method estimates the requisite minimum number of virtual machines according to the performance requirements of application services and decides an optimum virtual machine placement so that minimum configurations survive at any k host server failures. The evaluation results clarify that the proposed method achieves requested fault-tolerance level with less number of hosting servers compared to the conventional N+M redundant configuration approach.},
	booktitle = {2010 {IEEE} {Network} {Operations} and {Management} {Symposium} - {NOMS} 2010},
	author = {Machida, F. and Kawato, Masahiro and Maeno, Y.},
	month = apr,
	year = {2010},
	keywords = {fault tolerance, Fault-tolerant, fault tolerant computing, fault-tolerant consolidated server clusters, Fault tolerant systems, Hardware, host server failures, Laboratories, National electric code, Placement Algorithm, Platform virtualization, Protection, Redundant Configuration, redundant virtual machine placement, Resource management, Resource virtualization, virtual machine, virtual machines, Virtual machining},
	pages = {32--39},
	file = {Machida et al. - 2010 - Redundant virtual machine placement for fault-tole.pdf:/home/daniel/Insync/Zotero/storage/33NHDDXV/Machida et al. - 2010 - Redundant virtual machine placement for fault-tole.pdf:application/pdf}
}
{weber-um:2002,
	title = {Um roteiro para explora\{c}c\~ao dos conceitos b\'asicos de toler\^ancia a falhas},
	url = {http://www.inf.ufrgs.br/~taisy/disciplinas/textos/},
	abstract = {Em  um  ambiente  distribu\'ido  suportado  por  in...},
	language = {pt-BR},
	urldate = {2017-10-14},
	institution = {Instituto de Inform\'atica – UFRGS},
	author = {Weber, Taisy Silva},
	year = {2002},
	pages = {62},
	file = {Dependabilidade.pdf:/home/daniel/Insync/Zotero/storage/3USBQ4CT/Dependabilidade.pdf:application/pdf}
}

@article{matos-redundant:2017,
	title = {Redundant {Eucalyptus} {Private} {Clouds}: {Availability} {Modeling} and {Sensitivity} {Analysis}},
	volume = {15},
	issn = {1570-7873, 1572-9184},
	shorttitle = {Redundant {Eucalyptus} {Private} {Clouds}},
	url = {https://link.springer.com/article/10.1007/s10723-016-9381-z},
	doi = {10.1007/s10723-016-9381-z},
	abstract = {Cloud computing infrastructures are designed to be accessible anywhere and anytime. This requires various fault tolerance mechanisms for coping with software and hardware failures. Hierarchical modeling approaches are often used to evaluate the availability of such systems, leveraging the representation of complex failure and repair events in distinct parts of the system. This paper presents an availability evaluation for redundant private clouds, represented by RBDs and Markov chains, hierarchically assembled. These private clouds follow the basic architecture of Eucalyptus-based environments, but employing warm-standby redundant hosts for some of its main components. Closed-form equations for the steady-state availability are presented, allowing direct analytical solution for large systems. The availability equations are symbolically differentiated, allowing parametric sensitivity analysis. The results from sensitivity analysis enables system planning for improving the steady- state availability. The sensitivity indices show that failure of the Eucalyptus Cloud Manager subsystem and the respective repair activities deserve priority for maximizing the system availability.},
	language = {en},
	number = {1},
	urldate = {2017-10-14},
	journal = {Journal of Grid Computing},
	author = {Matos, Rubens and Dantas, Jamilson and Araujo, Jean and Trivedi, Kishor S. and Maciel, Paulo},
	month = mar,
	year = {2017},
	pages = {1--22},
	file = {Matos et al. - 2017 - Redundant Eucalyptus Private Clouds Availability .pdf:/home/daniel/Insync/Zotero/storage/KJZ75ZGR/Matos et al. - 2017 - Redundant Eucalyptus Private Clouds Availability .pdf:application/pdf}
}

@article{burns-high:2017,
	type = {techtarget: {SearchITOperations}},
	title = {High availability in cloud computing prevents a {SPOF}},
	shorttitle = {techtarget: {SearchITOperations}},
	url = {http://searchitoperations.techtarget.com/tip/High-availability-in-cloud-computing-prevents-a-SPOF},
	abstract = {Design high availability in cloud computing to preserve application stability during server maintenance work and outages. It's about services, not servers.},
	urldate = {2017-09-28},
	journal = {TechTarget: SearchITOperations (07/2017)},
	author = {Burns, Stuart},
	month = jul,
	year = {2017}
}

@article{tamura-kemari:2008,
    author = {Tamura, Yoshi and Sato, Koji and Kihara, Seiji and Moriai, Satoshi},
    journal = {Xen Summit 2008, USENIX ATC '08},
    keywords = {2008, fault-tolerant, transparency, virtualization, xen},
    location = {Boston-{USA}},
    month = jun,
    title = {Kemari: Virtual Machine Synchronization for Fault Tolerance using {DomT}},
    year = {2008}
}

@inproceedings{medina-live:2011,
	title = {Live replication of virtual machines},
	url = {http://www.wseas.us/e-library/conferences/2011/Cambridge/SEPADS/SEPADS-01.pdf},
	urldate = {2017-10-07},
	booktitle = {Proc. 10th {WSEAS} {Intl}. {Conf}. {Software} {Engineering}, {Parallel} and {Distributed} {Systems},({Stevens} {Point}, {WI})},
	author = {Medina, Violeta and Garcıa, J. M.},
	year = {2011},
	pages = {15--23},
	file = {SEPADS-01.pdf:/home/daniel/Insync/Zotero/storage/62PIK69B/SEPADS-01.pdf:application/pdf}
}

@Article{Liu2013,
  author   = {Liu, Haikun and Jin, Hai and Xu, Cheng-Zhong and Liao, Xiaofei},
  title    = {Performance and energy modeling for live migration of virtual machines},
  journal  = {Cluster Computing},
  year     = {2013},
  volume   = {16},
  number   = {2},
  pages    = {249--264},
  month    = jun,
  issn     = {1386-7857, 1573-7543},
  abstract = {Live migration of virtual machine (VM) provides a significant benefit for virtual server mobility without disrupting service. It is widely used for system management in virtualized data centers. However, migration costs may vary significantly for different workloads due to the variety of VM configurations and workload characteristics. To take into account the migration overhead in migration decision-making, we investigate design methodologies to quantitatively predict the migration performance and energy consumption. We thoroughly analyze the key parameters that affect the migration cost from theory to practice. We construct application-oblivious models for the cost prediction by using learned knowledge about the workloads at the hypervisor (also called VMM) level. This should be the first kind of work to estimate VM live migration cost in terms of both performance and energy in a quantitative approach. We evaluate the models using five representative workloads on a Xen virtualized environment. Experimental results show that the refined model yields higher than 90\% prediction accuracy in comparison with measured cost. Model-guided decisions can significantly reduce the migration cost by more than 72.9\% at an energy saving of 73.6\%.},
  doi      = {10.1007/s10586-011-0194-3},
  file     = {Liu et al. - 2013 - Performance and energy modeling for live migration.pdf:/home/daniel/Insync/Zotero/storage/U582D6AU/Liu et al. - 2013 - Performance and energy modeling for live migration.pdf:application/pdf},
  language = {en},
  url      = {https://link.springer.com/article/10.1007/s10586-011-0194-3},
  urldate  = {2017-10-11},
}

@techreport{jansen-nist:2011,
	address = {Gaithersburg, MD, United States},
	title = {{SP} 800-144. {Guidelines} on {Security} and {Privacy} in {Public} {Cloud} {Computing}},
	abstract = {Cloud computing can and does mean different things to different people. The common characteristics most interpretations share are on-demand scalability of highly available and reliable pooled computing resources, secure access to metered services from nearly anywhere, and displacement of data and services from inside to outside the organization. While aspects of these characteristics have been realized to a certain extent, cloud computing remains a work in progress. This publication provides an overview of the security and privacy challenges pertinent to public cloud computing and points out considerations organizations should take when outsourcing data, applications, and infrastructure to a public cloud environment.},
	institution = {National Institute of Standards \& Technology -- {NIST}},
	author = {Jansen, Wayne and Grance, Timothy},
	year = {2011},
	file = {nistspecialpublication800-144.pdf:/home/daniel/Insync/Zotero/storage/HXKGEX66/nistspecialpublication800-144.pdf:application/pdf}
}

@inproceedings{chan-approach:2012,
	address = {New York, NY, USA},
	series = {{MIDDLEWARE} '12},
	title = {An {Approach} to {High} {Availability} for {Cloud} {Servers} with {Snapshot} {Mechanism}},
	isbn = {978-1-4503-1613-2},
	url = {http://doi.acm.org/10.1145/2405146.2405152},
	doi = {10.1145/2405146.2405152},
	abstract = {Virtualization technologies enable the execution of multiple virtual machine instances (VMs) with different operating systems (OSs) on the same physical host. Each VM instance functions independently as an isolated system with its own physical resources, OS and applications. Due to significant cost saving and efficiency, the virtualization model has been increasingly adapted by enterprises and service providers as their main computing and service delivery infrastructure, running critical internal business and external customer facing applications. To minimize down time due to unexpected VM crashes, a high availability or backup system is usually built into the infrastructure. There are many high availability technology options available such as replication, mirroring and fail over clustering. Most of these solutions are usually designed based on the traditional computing model, they are costly to implement, complicated and tedious to maintain, especially in a virtualized environment, and they often require additional expensive hardware and software components. In this paper, we introduce a simple, flexible, scalable, extensible, efficient and cost effective system which utilizes the current VM infrastructure and common utilities to provide a high availability solution in the virtualization environment. Our smart adaptive snapshot replication technique provides a smooth and reliable mechanism for cost-performance, wherein the amount of resources allocated for high availability solution can be adjusted based on available resources, utilization and customer requirements.},
	urldate = {2017-03-22},
	booktitle = {Proceedings of the {Industrial} {Track} of the 13th {ACM}/{IFIP}/{USENIX} {International} {Middleware} {Conference}},
	publisher = {ACM},
	author = {Chan, Hoi and Chieu, Trieu},
	year = {2012},
	keywords = {cloud, High Availability, Virtualization, VM},
	pages = {6:1--6:6},
	file = {Chan e Chieu - 2012 - An Approach to High Availability for Cloud Servers.pdf:/home/daniel/Insync/Zotero/storage/H7225UFC/Chan e Chieu - 2012 - An Approach to High Availability for Cloud Servers.pdf:application/pdf}
}

@inproceedings{zhang-hybridfs:2017,
	title = {{HybridFS} \#x2014; {A} {High} {Performance} and {Balanced} {File} {System} {Framework} with {Multiple} {Distributed} {File} {Systems}},
	volume = {01},
	doi = {10.1109/COMPSAC.2017.140},
	abstract = {In the big data era, the distributed file system is getting more and more significant due to the characteristics of its scale-out capability, high availability, and high performance. Different distributed file systems may have different design goals. For example, some of them are designed to have good performance for small file operations, such as GlusterFS, while some of them are designed for large file operations, such as Hadoop distributed file system. With the divergence of big data applications, a distributed file system may provide good performance for some applications but fails for some other applications, that is, there has no universal distributed file system that can produce good performance for all applications. In this paper, we propose a hybrid file system framework, HybridFS, which can deliver satisfactory performance for all applications. HybridFS is composed of multiple distributed file systems with the integration of advantages of these distributed file systems. In HybridFS, on top of multiple distributed file systems, we have designed a metadata management server to perform three functions: file placement, partial metadata store, and dynamic file migration. The file placement is performed based on a decision tree. The partial metadata store is performed for files whose size is less than a few hundred Bytes to increase throughput. The dynamic file migration is performed to balance the storage usage of distributed file systems without throttling performance. We have implemented HybridFS in java on eight nodes and choose Ceph, HDFS, and GlusterFS as designated distributed file systems. The experimental results show that, in the best case, HybridFS can have up to 30\% performance improvement of read/write operations over a single distributed file system. In addition, if the difference of storage usage among multiple distributed file systems is less than 40\%, the performance of HybridFS is guaranteed, that is, no performance degradation.},
	booktitle = {2017 {IEEE} 41st {Annual} {Computer} {Software} and {Applications} {Conference} ({COMPSAC})},
	author = {Zhang, L. and Wu, Y. and Xue, R. and Hsu, T. C. and Yang, H. and Chung, Y. C.},
	month = jul,
	year = {2017},
	keywords = {Algorithm design and analysis, Big Data applications, Electronic mail, File systems, Metadata, Servers, Throughput},
	pages = {796--805}
}

@book{coulouris-distributed:2011,
	address = {Boston},
	edition = {5 edition},
	series = {International computer science series},
	title = {Distributed {Systems}: {Concepts} and {Design}},
	isbn = {978-0-13-214301-1},
	shorttitle = {Distributed {Systems}},
	abstract = {Broad and up-to-date coverage of the principles and practice in the fast moving area of Distributed Systems.   Distributed Systems provides students of computer science and engineering with the skills they will need to design and maintain software for distributed applications. It will also be invaluable to software engineers and systems designers wishing to understand new and future developments in the field.  From mobile phones to the Internet, our lives depend increasingly on distributed systems linking computers and other devices together in a seamless and transparent way. The fifth edition of this best-selling text continues to provide a comprehensive source of material on the principles and practice of distributed computer systems and the exciting new developments based on them, using a wealth of modern case studies to illustrate their design and development. The depth of coverage will enable readers to evaluate existing distributed systems and design new ones.},
	language = {English},
	publisher = {Pearson},
	author = {Coulouris, George and Dollimore, Jean and Kindberg, Tim and Blair, Gordon},
	month = may,
	year = {2011},
	keywords = {Computers / Client-Server Computing, Computers / Networking / Network Protocols}
}

@inproceedings{bin-guaranteeing:2011,
	title = {Guaranteeing {High} {Availability} {Goals} for {Virtual} {Machine} {Placement}},
	doi = {10.1109/ICDCS.2011.72},
	abstract = {The placement of virtual machines (VMs) on a cluster of hosts under multiple constraints, including administrative (security, regulations) resource-oriented (capacity, energy), and QoS-oriented (performance) is a highly complex task. We define a new high-availability property for a VM; when a VM is marked as k-resilient, as long as there are up to k host failures, it should be guaranteed that it can be relocated to a non-failed host without relocating other VMs. Together with Hardware Predictive Failure Analysis and live migration, which enable VMs to be evacuated from a host before it fails, this property allows the continuous running of YMs on the cluster despite host failures. The complexity of the constraints associated with k-resiliency, which are naturally expressed by Second Order logic statements, prevented their integration into the placement computation until now. We present a novel algorithm which enables this integration by transforming the k-resiliency constraints to rules consumable by a generic Constraint Programming engine, prove that it guarantees the required resiliency and describe the implementation. We provide some preliminary results and compare our high availability support with naive solutions.},
	booktitle = {2011 31st {International} {Conference} on {Distributed} {Computing} {Systems}},
	author = {Bin, E. and Biran, O. and Boni, O. and Hadad, E. and Kolodner, E. K. and Moatti, Y. and Lorenz, D. H.},
	month = jun,
	year = {2011},
	keywords = {administrative constraints, availability, constraint, constraint handling, Engines, Equations, failure, generic constraint programming engine, hardware predictive failure analysis, High Availability, high availability goals, Indexes, k-resiliency, machine, numbering, performance evaluation, placement, QoS oriented constraints, quality of service, Resource management, resource oriented constraints, second order logic statements, Transforms, Virtual, virtual machine placement, virtual machines, Virtual machining},
	pages = {700--709},
	file = {Bin et al. - 2011 - Guaranteeing High Availability Goals for Virtual M.pdf:/home/daniel/Insync/Zotero/storage/SI9VUF7C/Bin et al. - 2011 - Guaranteeing High Availability Goals for Virtual M.pdf:application/pdf}
}

@article{gagnaire-downtime:2012,
	title = {Downtime statistics of current cloud solutions},
	url = {http://iwgcr.org/wp-content/uploads/2012/06/IWGCR-Paris.Ranking-002-en.pdf},
	urldate = {2017-10-02},
	journal = {International Working Group on Cloud Computing Resiliency, Tech. Rep},
	author = {Gagnaire, Maurice and Diaz, Felipe and Coti, Camille and Cerin, Christophe and Shiozaki, Kazuhiko and Xu, Yingjie and Delort, Pierre and Smets, Jean-Paul and Le Lous, Jonathan and Lubiarz, Stephen and {others}},
	year = {2012},
	file = {Gagnaire et al. - 2012 - Downtime statistics of current cloud solutions.pdf:/home/daniel/Insync/Zotero/storage/JVQWGUD8/Gagnaire et al. - 2012 - Downtime statistics of current cloud solutions.pdf:application/pdf}
}

@article{butler-and:2016,
	title = {And the cloud provider with the best uptime in 2015 is…},
	shorttitle = {And the cloud provider with the best uptime in 2015 is…},
	url = {https://www.networkworld.com/article/3020235/cloud-computing/and-the-cloud-provider-with-the-best-uptime-in-2015-is.html},
	abstract = {Amazon’s cloud bests those of Microsoft and Google by this reliability test},
	urldate = {2017-10-02},
	journal = {networkworld.com},
	author = {Butler, Brandon},
	month = jan,
	year = {2016},
	file = {And the cloud provider with the best uptime in 2015 is… | Network World:/home/daniel/Insync/Zotero/storage/5P3W27D3/and-the-cloud-provider-with-the-best-uptime-in-2015-is.html:text/html}
}
{santos-analyzing:2017,
	title = {Analyzing the {IT} subsystem failure impact on availability of cloud services},
	doi = {10.1109/ISCC.2017.8024612},
	abstract = {Cloud computing has gained popularity in recent years due to its pay-as-you-go business model, high availability of services, and scalability. Service unavailability does not affect just user experience but is also translated into direct costs for cloud providers and companies. Part of this costs is due to SLA breaches, once interruption time greater than those signed in the contract generate financial penalties. Thus, cloud providers have tried to identify failure points and estimate the availability of their services. This paper proposes models to assess the availability of services running in a cloud data center infrastructure. The models follow the TIA-942 standard. We propose Tier I and IV models using the Reliability Block Diagram (RBD) to allow modeling of different types of applications, and Stochastic Petri Net (SPN) to represent the failure behavior of information technology (IT) components in a data center. We perform stationary analysis to measure the service availability, and sensitivity analysis to understand which metrics have major impacts on data center availability.},
	booktitle = {2017 {IEEE} {Symposium} on {Computers} and {Communications} ({ISCC})},
	author = {Santos, G. L. and Endo, P. T. and Gon\{c}calves, G. and Rosendo, D. and Gomes, D. and Kelner, J. and Sadok, D. and Mahloo, M.},
	month = jul,
	year = {2017},
	keywords = {cloud companies, cloud computing, cloud data center infrastructure, cloud providers, cloud services, Computational modeling, computer centres, contracts, data center availability, Data models, failure points, financial penalties, information technology components, IT subsystem failure impact, pay-as-you-go business model, Petri nets, Reliability, reliability block diagram, sensitivity analysis, Servers, service availability, SLA breaches, Standards, stationary analysis, stochastic Petri net, stochastic processes, TIA-942 standard, Tier Iand models, Tier IV models, user experience},
	pages = {717--723},
	file = {Santos et al. - 2017 - Analyzing the IT subsystem failure impact on avail.pdf:/home/daniel/Insync/Zotero/storage/784B3774/Santos et al. - 2017 - Analyzing the IT subsystem failure impact on avail.pdf:application/pdf}
}

@inproceedings{islam-predicting:2017,
	title = {Predicting {Application} {Failure} in {Cloud}: {A} {Machine} {Learning} {Approach}},
	shorttitle = {Predicting {Application} {Failure} in {Cloud}},
	doi = {10.1109/IEEE.ICCC.2017.11},
	abstract = {Despite employing the architectures designed for high service reliability and availability, cloud computing systems do experience service outages and performance slowdown. In addition to these, large-scale cloud systems experience failures in their hardware and software components which often result in node and application (e.g., jobs and tasks) failures. Therefore, to build a reliable cloud system, it is important to understand and characterize the observed failures. The goal of this work is to identify the key features that correlate to application failures in cloud and present a failure prediction model that can correctly predict the outcome of a task or job before it actually finishes, fails or gets killed. To accomplish this, we perform a failure characterization study of the Google cluster workload trace. Our analysis reveals that, there is a significant consumption of resources due to failed and killed jobs. We further explore the potential for failure prediction in cloud applications so that we can reduce the wastage of resources by better managing the jobs and tasks that ultimately fail or get killed. For this, we propose a prediction method based on a special type of Recurrent NeuralNetwork (RNN) named Long Short-Term Memory Network(LSTM) to identify application failures in cloud. It takes resource usage measurements or performance data for each job and task, and the goal is to predict the termination status (e.g., failed and finished etc.) of them. Our algorithm can predict task failures with 87\%accuracy and achieves a true positive rate of 85\% and false positive rate of 11\%.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Cognitive} {Computing} ({ICCC})},
	author = {Islam, T. and Manivannan, D.},
	month = jun,
	year = {2017},
	keywords = {cloud computing, Correlation, Google, Predictive models, Recurrent neural networks, Reliability, Runtime},
	pages = {24--31},
	file = {Islam e Manivannan - 2017 - Predicting Application Failure in Cloud A Machine.pdf:/home/daniel/Insync/Zotero/storage/MN3VIVAS/Islam e Manivannan - 2017 - Predicting Application Failure in Cloud A Machine.pdf:application/pdf}
}

@inproceedings{prathiba-survey:2017,
	title = {Survey of failures and fault tolerance in cloud},
	doi = {10.1109/ICCCT2.2017.7972271},
	abstract = {Cloud computing provides support for hosting client's application. Cloud is a distributed platform that provides hardware, software and network resources to both execute consumer's application and also to store and mange user's data. Cloud is also used to execute scientific workflow applications that are in general complex in nature when compared to other applications. Since cloud is a distributed platform, it is more prone to errors and failures. In such an environment, avoiding a failure is difficult and identifying the source of failure is also complex. Because of this, fault tolerance mechanisms are implemented on the cloud platform. This ensures that even if there are failures in the environment, critical data of the client is not lost and user's application running on cloud is not affected in any manner. Fault tolerance mechanisms also help in improving the cloud's performance by proving the services to the users as required on demand. In this paper a survey of existing fault tolerance mechanisms for the cloud platform are discussed. This paper also discusses the failures, fault tolerant clustering methods and fault tolerant models that are specific for scientific workflow applications.},
	booktitle = {2017 2nd {International} {Conference} on {Computing} and {Communications} {Technologies} ({ICCCT})},
	author = {Prathiba, S. and Sowvarnica, S.},
	month = feb,
	year = {2017},
	keywords = {cloud, cloud computing, cloud performance improvement, Clustering methods, Computational modeling, consumer application, distributed platform, failure, failure analysis, fault tolerance, fault tolerance mechanisms, fault tolerant clustering methods, fault tolerant computing, Fault tolerant systems, Hardware, hardware resources, Measurement, network resources, scientific information systems, scientific workflow applications, software resources, user data management, user data storage},
	pages = {169--172},
	file = {Prathiba e Sowvarnica - 2017 - Survey of failures and fault tolerance in cloud.pdf:/home/daniel/Insync/Zotero/storage/WPSBIQDV/Prathiba e Sowvarnica - 2017 - Survey of failures and fault tolerance in cloud.pdf:application/pdf}
}

@inproceedings{zhang-ceph:2015,
	title = {Ceph {Distributed} {File} {System} {Benchmarks} on an {Openstack} {Cloud}},
	doi = {10.1109/CCEM.2015.12},
	abstract = {Ceph is a distributed file system that provides high performance, reliability, and scalability. Ceph maximizes the separation between data and metadata management by replacing allocation tables with a pseudo-random data distribution function (CRUSH) designed for heterogeneous and dynamic clusters of unreliable object storage devices (OSDs). In this paper, we investigate the performance of Ceph on an Open Stack cloud using well-known benchmarks. Our results show its good performance and scalability.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Cloud} {Computing} in {Emerging} {Markets} ({CCEM})},
	author = {Zhang, X. and Gaddam, S. and Chronopoulos, A. T.},
	month = nov,
	year = {2015},
	keywords = {Bandwidth, benchmarks, Benchmark testing, Ceph distributed file storage, Ceph distributed file system benchmark, Ceph performance, Ceph reliability, Ceph scalability, cloud computing, Computer architecture, CRUSH, data management, dynamic clusters, File systems, heterogeneous clusters, meta data, metadata management, Monitoring, Open Stack Cloud, Openstack cloud, performance evaluation, pseudorandom data distribution function, public domain software, storage management, unreliable object storage devices},
	pages = {113--120},
	file = {Zhang et al. - 2015 - Ceph Distributed File System Benchmarks on an Open.pdf:/home/daniel/Insync/Zotero/storage/TKZJJN9V/Zhang et al. - 2015 - Ceph Distributed File System Benchmarks on an Open.pdf:application/pdf}
}

@inproceedings{riasetiawan-distributed:2015,
	title = {Distributed {Replicated} {Block} {Device} ({DRDB}) implementation on cluster storage data migration},
	doi = {10.1109/ICODSE.2015.7436978},
	abstract = {Data Center systems are required to have high availability in order to meet the continuing needs of the user. If the server or application in which a failure or require maintenance, the virtual machine will be migrated to another server in the cluster are still available. The role of shared storage is very important here to keep a virtual machine that can continue the work and do not lose data on the destination server. This study seeks to implement virtualization at the server cluster system uses a virtual machine on Proxmox VE and Distributed Replicated Block Device (DRBD) as shared storage. Implementation is done by using two nodes, and made a comparison with two other nodes in the cluster system that does not use shared storage. Shared storage works by synchronizing and replication of virtual machine data that can then migrate online. The use of shared storage will affect virtual machine performance, especially on the speed of the disk during the process of sending and receiving data, and the availability of services. Measurement of downtime during the migration to test the success of the system. Testing the TCP connection is made to ensure the network throughput and connection test results compared to test disk performance.},
	booktitle = {2015 {International} {Conference} on {Data} and {Software} {Engineering} ({ICoDSE})},
	author = {Riasetiawan, M. and Ashari, A. and Endrayanto, I.},
	month = nov,
	year = {2015},
	keywords = {Cluster, cluster storage data migration, computer centres, data handling, destination server, disc storage, disk performance, disk speed, distributed replicated block device implementation, DRBD, DRDBt, Hardware, network servers, network throughput, performance evaluation, Proxmox VE, server cluster system, Servers, shared storage, storage management, synchronisation, TCP connection test, Testing, transport protocols, virtualisation, Virtualization, virtual machine, virtual machine data replication, virtual machine data synchronization, Virtual machine monitors, virtual machine performance, virtual machines, Virtual machining},
	pages = {93--97},
	file = {Riasetiawan et al. - 2015 - Distributed Replicated Block Device (DRDB) impleme.pdf:/home/daniel/Insync/Zotero/storage/QRH9X46V/Riasetiawan et al. - 2015 - Distributed Replicated Block Device (DRDB) impleme.pdf:application/pdf}
}

@article{zhou-cloud:2016,
	title = {Cloud service reliability enhancement via virtual machine placement optimization},
	url = {http://ieeexplore.ieee.org/abstract/document/7387769/},
	urldate = {2017-10-02},
	journal = {IEEE Transactions on Services Computing},
	author = {Zhou, Ao and Wang, Shangguang and Cheng, Bo and Zheng, Zibin and Yang, Fangchun and Chang, Rong and Lyu, Michael and Buyya, Rajkumar},
	year = {2016},
	file = {Zhou et al. - 2016 - Cloud service reliability enhancement via virtual .pdf:/home/daniel/Insync/Zotero/storage/DI7TCN2J/Zhou et al. - 2016 - Cloud service reliability enhancement via virtual .pdf:application/pdf}
}

@article{zhou-enhancing:2017,
	title = {Enhancing reliability via checkpointing in cloud computing systems},
	volume = {14},
	issn = {1673-5447},
	doi = {10.1109/CC.2017.8010962},
	abstract = {Cloud computing is becoming an important solution for providing scalable computing resources via Internet. Because there are tens of thousands of nodes in data center, the probability of server failures is nontrivial. Therefore, it is a critical challenge to guarantee the service reliability. Fault-tolerance strategies, such as checkpoint, are commonly employed. Because of the failure of the edge switches, the checkpoint image may become inaccessible. Therefore, current checkpoint-based fault tolerance method cannot achieve the best effect. In this paper, we propose an optimal checkpoint method with edge switch failure-aware. The edge switch failure-aware checkpoint method includes two algorithms. The first algorithm employs the data center topology and communication characteristic for checkpoint image storage server selection. The second algorithm employs the checkpoint image storage characteristic as well as the data center topology to select the recovery server. Simulation experiments are performed to demonstrate the effectiveness of the proposed method.},
	number = {7},
	journal = {China Communications},
	author = {Zhou, A. and Sun, Q. and Li, J.},
	month = jul,
	year = {2017},
	keywords = {checkpoint image storage characteristic, checkpointing, cloud computing, cloud computing systems, cloud service, Data center, data center network, data center topology, edge switch failure-aware checkpoint method, fault tolerance, fault-tolerance strategies, Image edge detection, optimal checkpoint method, Random access memory, Redundancy, Reliability, scalable computing resource, Servers, service reliability, software reliability, Virtual machining},
	pages = {1--10},
	file = {Zhou et al. - 2017 - Enhancing reliability via checkpointing in cloud c.pdf:/home/daniel/Insync/Zotero/storage/JSW964WD/Zhou et al. - 2017 - Enhancing reliability via checkpointing in cloud c.pdf:application/pdf}
}

@inproceedings{feller-energy:2012,
	title = {Energy {Management} in {IaaS} {Clouds}: {A} {Holistic} {Approach}},
	shorttitle = {Energy {Management} in {IaaS} {Clouds}},
	doi = {10.1109/CLOUD.2012.50},
	abstract = {Energy efficiency has now become one of the major design constraints for current and future cloud data center operators. One way to conserve energy is to transition idle servers into a lower power-state (e.g. suspend). Therefore, virtual machine (VM) placement and dynamic VM scheduling algorithms are proposed to facilitate the creation of idle times. However, these algorithms are rarely integrated in a holistic approach and experimentally evaluated in a realistic environment. In this paper we present the energy management algorithms and mechanisms of a novel holistic energy-aware VM management framework for private clouds called Snooze. We conduct an extensive evaluation of the energy and performance implications of our system on 34 power-metered machines of the Grid'5000 experimentation testbed under dynamic web workloads. The results show that the energy saving mechanisms allow Snooze to dynamically scale data center energy consumption proportionally to the load, thus achieving substantial energy savings with only limited impact on application performance.},
	booktitle = {2012 {IEEE} {Fifth} {International} {Conference} on {Cloud} {Computing}},
	author = {Feller, E. and Rohr, C. and Margery, D. and Morin, C.},
	month = jun,
	year = {2012},
	keywords = {cloud computing, cloud data center operators, computer centres, consolidation, dynamic energy consumption scaling, dynamic VM scheduling algorithms, dynamic Web workloads, energy conservation, Energy efficiency, Energy management, energy management algorithms, energy management mechanisms, energy management systems, energy saving mechanisms, Estimation, Grid'5000 experimentation testbed, Heuristic algorithms, holistic approach, holistic energy-aware VM management framework, IaaS clouds, live migration, Monitoring, power aware computing, power-metered machines, private clouds, realistic environment, Relocation, resource allocation, Resource management, Servers, snooze, Vectors, Virtualization, virtual machine placement, virtual machines},
	pages = {204--212},
	file = {Feller et al. - 2012 - Energy Management in IaaS Clouds A Holistic Appro.pdf:/home/daniel/Insync/Zotero/storage/FU4FKED7/Feller et al. - 2012 - Energy Management in IaaS Clouds A Holistic Appro.pdf:application/pdf}
}

@inproceedings{villamizar-evaluating:2015,
	title = {Evaluating the monolithic and the microservice architecture pattern to deploy web applications in the cloud},
	doi = {10.1109/ColumbianCC.2015.7333476},
	abstract = {Cloud computing provides new opportunities to deploy scalable application in an efficient way, allowing enterprise applications to dynamically adjust their computing resources on demand. In this paper we analyze and test the microservice architecture pattern, used during the last years by large Internet companies like Amazon, Netflix and LinkedIn to deploy large applications in the cloud as a set of small services that can be developed, tested, deployed, scaled, operated and upgraded independently, allowing these companies to gain agility, reduce complexity and scale their applications in the cloud in a more efficient way. We present a case study where an enterprise application was developed and deployed in the cloud using a monolithic approach and a microservice architecture using the Play web framework. We show the results of performance tests executed on both applications, and we describe the benefits and challenges that existing enterprises can get and face when they implement microservices in their applications.},
	booktitle = {2015 10th {Computing} {Colombian} {Conference} (10CCC)},
	author = {Villamizar, M. and Garc\'es, O. and Castro, H. and Verano, M. and Salamanca, L. and Casallas, R. and Gil, S.},
	month = sep,
	year = {2015},
	keywords = {cloud computing, Companies, Complexity theory, Computer architecture, continuous delivery, enterprise applications, IaaS, infrastructure as a services, Internet companies, microservice architecture, microservice architecture pattern, microservices, monolithic architecture pattern, PaaS, platform as a service, Play Web framework, scalable applications, Service-oriented architecture, service oriented architectures, SOA, software architecture, software engineering, Web applications},
	pages = {583--590},
	file = {Villamizar et al. - 2015 - Evaluating the monolithic and the microservice arc.pdf:/home/daniel/Insync/Zotero/storage/PDISCTC5/Villamizar et al. - 2015 - Evaluating the monolithic and the microservice arc.pdf:application/pdf}
}

@article{balalaie-microservices:2016,
	title = {Microservices {Architecture} {Enables} {DevOps}: {Migration} to a {Cloud}-{Native} {Architecture}},
	volume = {33},
	issn = {0740-7459},
	shorttitle = {Microservices {Architecture} {Enables} {DevOps}},
	doi = {10.1109/MS.2016.64},
	abstract = {This article reports on experiences and lessons learned during incremental migration and architectural refactoring of a commercial mobile back end as a service to microservices architecture. It explains how the researchers adopted DevOps and how this facilitated a smooth migration.},
	number = {3},
	journal = {IEEE Software},
	author = {Balalaie, A. and Heydarnoori, A. and Jamshidi, P.},
	month = may,
	year = {2016},
	keywords = {architectural refactoring, cloud computing, cloud-native architecture, Computer architecture, DevOps, incremental migration, microservices, microservices architecture, migration pattern, mobile back end as a service, Mobile communication, Refractoring, scalability, Servers, software architecture, software development, software engineering, software maintenance},
	pages = {42--52},
	file = {Balalaie et al. - 2016 - Microservices Architecture Enables DevOps Migrati.pdf:/home/daniel/Insync/Zotero/storage/BSVRZRRS/Balalaie et al. - 2016 - Microservices Architecture Enables DevOps Migrati.pdf:application/pdf}
}

@inproceedings{huang-processor:2010,
	title = {Processor allocation policies for reducing resource fragmentation in multi-cluster grid and cloud environments},
	doi = {10.1109/COMPSYM.2010.5685368},
	abstract = {Multi-cluster is the common underlying architecture of most grid and cloud environments, which usually consist of multiple clusters located at different places. One important characteristic of such computing environments is the performance difference between intra-cluster and inter-cluster communications. Intra-cluster communication networks usually have shorter latency and larger bandwidth than inter-cluster networks. Therefore, in those systems parallel jobs are intended to be executed within a single one of the clusters to achieve better performance although co-allocation across multiple clusters is sometimes technically possible. Under such job execution policy resource fragmentation becomes a crucial issue that happens when there is no single cluster being able to accommodate a job while the total number of processors in the entire grid or cloud is enough for the job. This paper proposes a most-fit policy to reduce resource fragmentation occurrences and evaluates it with several existing processor allocation policies. The experimental results indicate that careful selection of processor allocation policies can improve overall system performance greatly and the proposed most-fit policy can outperform other policies in most conditions.},
	booktitle = {2010 {International} {Computer} {Symposium} ({ICS}2010)},
	author = {Huang, K. C. and Lai, K. P.},
	month = dec,
	year = {2010},
	keywords = {cloud, cloud computing, cloud environment, Clouds, coallocation across multiple cluster, Complexity theory, Computers, grid, grid computing, intercluster communication, intracluster communication, job execution policy resource fragmentation, most fit policy, multicluster grid, parallel processing, pattern clustering, processor allocation, processor allocation policy, processor scheduling, resource allocation, resource fragmentation, Resource management, Schedules, System performance, telecommunication networks},
	pages = {971--976}
}

@article{bias-history:2016,
	title = {The {History} of {Pets} vs {Cattle} and {How} to {Use} the {Analogy} {Properly}},
	url = {http://cloudscaling.com/blog/cloud-computing/the-history-of-pets-vs-cattle/},
	abstract = {I have been meaning to write this post for a long time, but one thing or another has gotten in the way. It’s important to me to provide an accurate history, ...},
	urldate = {2017-09-28},
	journal = {Cloudscaling website, (04/2016)},
	author = {Bias, Randy},
	month = apr,
	year = {2016}
}

@article{bias-ranchers:2016,
	title = {The {Rancher}'s {Dilemma}: {Reconciling} {Pets} \& {Cattle}},
	shorttitle = {The {Rancher}'s {Dilemma}},
	url = {http://cloudscaling.com/blog/openstack/the-ranchers-dilemma/},
	abstract = {When I first started promulgating the pets vs. cattle meme, it really helped me get through roadblocks of confusion. Many in IT couldn’t tell the difference ...},
	urldate = {2017-09-28},
	journal = {Cloudscaling website, (04/2016)},
	author = {Bias, Randy},
	month = apr,
	year = {2016}
}

@book{bhowmik-cloud:2017,
	title = {Cloud {Computing}},
	isbn = {978-1-316-63810-1},
	abstract = {Written in a tutorial style, this comprehensive guide follows a structured approach explaining cloud techniques, models and platforms. Popular cloud services such as Amazon, Google and Microsoft Azure are explained in the text. The security risks and challenges of cloud computing are discussed in detail with useful examples. Emerging trends including mobile cloud computing and internet of things are discussed in the book for the benefit of the readers. Numerous review questions, multiple choice exercises and case studies facilitate enhanced understanding. This textbook is ideal for undergraduate and graduate students of computer science engineering, and information technology.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Bhowmik, Sandeep},
	month = jul,
	year = {2017},
	keywords = {Computers / Networking / General}
}

@inproceedings{zhang-column:2017,
	title = {A column generation-based algorithm for two-stage, two-dimensional bin packing problem with a variant variable sized constraint},
	doi = {10.23919/ChiCC.2017.8027796},
	abstract = {In this paper, we consider two-dimensional bin packing problem with a variant variable sized constraint, where the width of the bin is continuously changed and the height of the bin is discretely changed, with the further restrictions that packing can be rotated and done in two stages. A column generation-based algorithm is proposed when the first cutting stage is the vertical direction. The problem is decomposed into a level packing problem and a level combining problem. Afterwards, a column generation (CG) algorithm and a cutting rule (CR) scheme are proposed respectively. Computational results for the practical instances show the effectiveness of the proposed method. Using the column generation-based algorithm above mentioned we solved the instances found at the OR-LIBRARY.},
	booktitle = {2017 36th {Chinese} {Control} {Conference} ({CCC})},
	author = {Zhang, Q. and Liu, S. and Qin, S. and Shi, Y.},
	month = jul,
	year = {2017},
	keywords = {Algorithm design and analysis, Approximation algorithms, column generation, Electronic mail, Information science, Linear programming, Pricing, two-dimensional bin packing, two stage packing, Upper bound, variable size},
	pages = {2841--2845},
	file = {Zhang et al. - 2017 - A column generation-based algorithm for two-stage,.pdf:/home/daniel/Insync/Zotero/storage/QEITGQA9/Zhang et al. - 2017 - A column generation-based algorithm for two-stage,.pdf:application/pdf}
}

@article{ngenzi-framework:2016,
	title = {Framework of {Resource} {Management} using {Server} {Consolidation} to {Minimize} {Live} {Migration} and {Load} {Balancing}},
	volume = {7},
	url = {https://www.researchgate.net/profile/Alexander_Ngenzi/publication/311385728_Framework_of_Resource_Management_using_Server_Consolidation_to_Minimize_Live_Migration_and_Load_Balancing/links/5843c4e208aeda696815c64e.pdf},
	number = {11},
	urldate = {2017-09-26},
	journal = {Framework},
	author = {Ngenzi, Alexander and Selvarani, R. and Suchithra, R.},
	year = {2016},
	file = {Paper_9-Framework_of_Resource_Management_using_Server_Consolidation.pdf:/home/daniel/Insync/Zotero/storage/PXPAFFHE/Paper_9-Framework_of_Resource_Management_using_Server_Consolidation.pdf:application/pdf}
}

@article{ferreto-server:2011,
	title = {Server {Consolidation} with {Migration} {Control} for {Virtualized} {Data} {Centers}},
	volume = {27},
	issn = {0167-739X},
	url = {http://dx.doi.org/10.1016/j.future.2011.04.016},
	doi = {10.1016/j.future.2011.04.016},
	abstract = {Virtualization has become a key technology for simplifying service management and reducing energy costs in data centers. One of the challenges faced by data centers is to decide when, how, and which virtual machines (VMs) have to be consolidated into a single physical server. Server consolidation involves VM migration, which has a direct impact on service response time. Most of the existing solutions for server consolidation rely on eager migrations, which try to minimize the number of physical servers running VMs. These solutions generate unnecessary migrations due to unpredictable workloads that require VM resizing. This paper proposes an LP formulation and heuristics to control VM migration, which prioritize virtual machines with steady capacity. We performed experiments using TU-Berlin and Google data center workloads to compare our migration control strategy against existing eager-migration-based solutions. We observed that avoiding migration of VMs with steady capacity reduces the number of migrations with minimal penalty in the number of physical servers.},
	number = {8},
	urldate = {2017-09-26},
	journal = {Future Gener. Comput. Syst.},
	author = {Ferreto, Tiago C. and Netto, Marco A. S. and Calheiros, Rodrigo N. and De Rose, C\'esar A. F.},
	month = oct,
	year = {2011},
	keywords = {Data centers, Migration control, Server consolidation, Virtualization},
	pages = {1027--1034},
	file = {2011fgcs_ferreto.pdf:/home/daniel/Insync/Zotero/storage/DEIW5SNU/2011fgcs_ferreto.pdf:application/pdf}
}

@article{speitkamp-mathematical:2010,
	title = {A {Mathematical} {Programming} {Approach} for {Server} {Consolidation} {Problems} in {Virtualized} {Data} {Centers}},
	volume = {3},
	issn = {1939-1374},
	url = {http://ieeexplore.ieee.org/document/5467027/},
	doi = {10.1109/TSC.2010.25},
	number = {4},
	urldate = {2017-09-26},
	journal = {IEEE Transactions on Services Computing},
	author = {Speitkamp, B and Bichler, M},
	month = oct,
	year = {2010},
	pages = {266--278},
	file = {05467027.pdf:/home/daniel/Insync/Zotero/storage/MAQD3RQE/05467027.pdf:application/pdf}
}

@article{martello-lower:1990,
	title = {Lower bounds and reduction procedures for the bin packing problem},
	volume = {28},
	issn = {0166-218X},
	url = {http://www.sciencedirect.com/science/article/pii/0166218X9090094S},
	doi = {10.1016/0166-218X(90)90094-S},
	abstract = {The bin packing problem, in which a set of items of various sizes has to be packed into a minimum number of identical bins, has been extensively studied during the past fifteen years, mainly with the aim of finding fast heuristic algorithms to provide good approximate solutions. We present lower bounds and a dominance criterion and derive a reduction algorithm. Lower bounds are evaluated through an extension of the concept of worst-case performance. For both lower bounds and reduction algorithm an experimental analysis is provided.},
	number = {1},
	urldate = {2016-12-05},
	journal = {Discrete Applied Mathematics},
	author = {Martello, Silvano and Toth, Paolo},
	month = jul,
	year = {1990},
	keywords = {bin packing problem, dominance criterion, lower bound, reduction algorithm, worst-case performance},
	pages = {59--70}
}

@book{aggarwal-reliability:1993,
	title = {Reliability {Engineering}},
	isbn = {978-0-7923-2524-6},
	abstract = {Modern society depends heavily upon a host of systems of varying complexity to perform the services required. The importance of reliability assumes new dimensions, primarily because of the higher cost of these highly complex machines required by mankind and the implication of their failure. This is why all industrial organizations wish to equip their scientists, engineers, managers and administrators with a knowledge of reliability concepts and applications. Based on the author's 20 years experience as reliability educator, researcher and consultant, Reliability Engineering introduces the reader systematically to reliability evaluation, prediction, allocation and optimization.  It also covers further topics, such as maintainability and availability, software reliability, economics of reliability, reliability management, reliability testing, etc. A reliability study of some typical systems has been included to introduce the reader to the practical aspects.  The book is intended for graduate students of engineering schools and also professional engineers, managers and reliability administrators as it has a wide coverage of reliability concepts.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Aggarwal, K. K.},
	month = oct,
	year = {1993},
	keywords = {Mathematics / Probability \& Statistics / General, Technology \& Engineering / Civil / General, Technology \& Engineering / Engineering (General), Technology \& Engineering / General, Technology \& Engineering / Manufacturing, Technology \& Engineering / Quality Control}
}

@book{critchley-high:2014,
	title = {High {Availability} {IT} {Services}},
	isbn = {978-1-4822-5591-1},
	abstract = {This book starts with the basic premise that a service is comprised of the 3Ps—products, processes, and people. Moreover, these entities and their sub-entities interlink to support the services that end users require to run and support a business. This widens the scope of any availability design far beyond hardware and software. It also increases the potential for service failure for reasons beyond just hardware and software; the concept of logical outages.High Availability IT Services details the considerations for designing and running highly available ''services'' and not just the systems infrastructure that supports those services. Providing an overview of virtualization and cloud computing, it supplies a detailed look at availability, redundancy, fault tolerance, and security. It also stresses the importance of human factors.The book starts off by providing an availability primer and detailing the reasons why you need to be concerned with high availability. Next, it outlines the theory of reliability and availability and the elements of actual practices in this high availability (HA) area, including Service Level Agreements (SLAs) and Change Management.Examining what the major hardware and software vendors have to offer in the HA world, the book considers the ubiquitous world of clouds and virtualization as well as the availability considerations they present.The book examines high availability concepts and architectures such as reliability, availability, and serviceability (RAS); clusters; grids; and redundant arrays of independent disks (RAID) storage. It also covers the role of security in providing high availability, cluster offerings, emergent Linux clusters, online transaction processing (OLTP), and relational databases.},
	language = {en},
	publisher = {CRC Press},
	author = {Critchley, Terry},
	month = dec,
	year = {2014},
	keywords = {Business \& Economics / Production \& Operations Management, Computers / Information Technology, Computers / Networking / General, Technology \& Engineering / Engineering (General)}
}

@book{stapelberg-handbook:2009,
	title = {Handbook of {Reliability}, {Availability}, {Maintainability} and {Safety} in {Engineering} {Design}},
	isbn = {978-1-84800-175-6},
	abstract = {Handbook of Reliability, Availability, Maintainability and Safety in Engineering Design studies the combination of various methods of designing for reliability, availability, maintainability and safety, as well as the latest techniques in probability and possibility modelling, mathematical algorithmic modelling, evolutionary algorithmic modelling, symbolic logic modelling, artificial intelligence modelling, and object-oriented computer modelling, in a logically structured approach to determining the integrity of engineering design.  Handbook of Reliability, Availability, Maintainability and Safety in Engineering Design not only encompasses a depth of research into engineering design methods and techniques ranging from quantitative probability theory and expert judgement in Bayesian analysis to qualitative possibility theory, fuzzy logic and uncertainty in Markov analysis; from reliability block diagrams, fault trees, event trees and cause-consequence diagrams to Petri nets, genetic algorithms and artificial neural networks; but it also covers a breadth of research into the concept of integrity in engineering design. Such breadth of research is represented by the inclusion of the topics of reliability and performance, availability and maintainability, and safety and risk, in an overall concept of designing for integrity during the different phases of the engineering design process. These topics add significant value to the theoretical expertise and practical experience of process, chemical, civil, mechanical, electrical, and electronic engineers, by considering process engineering design from the point of view of ''what should be achieved'' to meet criteria for designing for reliability, availability, maintainability and safety.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Stapelberg, Rudolph Frederick},
	month = feb,
	year = {2009},
	keywords = {Business \& Economics / Production \& Operations Management, Business \& Economics / Research \& Development, Technology \& Engineering / Civil / General, Technology \& Engineering / Industrial Design / General, Technology \& Engineering / Industrial Design / Product, Technology \& Engineering / Manufacturing, Technology \& Engineering / Quality Control, Technology \& Engineering / Technical \& Manufacturing Industries \& Trades}
}

@incollection{maciel-modeling:2016,
	series = {Springer {Series} in {Reliability} {Engineering}},
	title = {Modeling {Availability} {Impact} in {Cloud} {Computing}},
	isbn = {978-3-319-30597-4 978-3-319-30599-8},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-30599-8:11},
	abstract = {Internet-based services have become critical to several businesses in which many aspects of our lives depend on (e.g., online banking, collaborative work, videoconferencing). Business continuity is a remarkable property and it is a chief concern for many companies, since service disruption may cause huge revenue and market share losses. In recent years, cloud computing has turned into a remarkable alternative due to its resource on-demand and pay-as-you-go models. More specifically, additional resources, such as virtual machines (VMs), are only allocated when disaster takes place, and the automated virtual platform also performs a transparent recovery to minimize the service time to restore. This chapter presents availability models to evaluate cloud computing infrastructures.},
	language = {en},
	urldate = {2017-09-22},
	booktitle = {Principles of {Performance} and {Reliability} {Modeling} and {Evaluation}},
	publisher = {Springer, Cham},
	author = {Maciel, Paulo Romero Martins},
	year = {2016},
	note = {DOI: 10.1007/978-3-319-30599-8\:11},
	pages = {287--320}
}

@book{bauer-reliability:2012,
	address = {Piscataway, NJ : Hoboken, NJ},
	edition = {1 edition},
	title = {Reliability and {Availability} of {Cloud} {Computing}},
	isbn = {978-1-118-17701-3},
	abstract = {A holistic approach to service reliability and availability of cloud computing Reliability and Availability of Cloud Computing provides IS/IT system and solution architects, developers, and engineers with the knowledge needed to assess the impact of virtualization and cloud computing on service reliability and availability. It reveals how to select the most appropriate design for reliability diligence to assure that user expectations are met. Organized in three parts (basics, risk analysis, and recommendations), this resource is accessible to readers of diverse backgrounds and experience levels. Numerous examples and more than 100 figures throughout the book help readers visualize problems to better understand the topic—and the authors present risks and options in bulleted lists that can be applied directly to specific applications/problems. Special features of this book include:  Rigorous analysis of the reliability and availability risks that are inherent in cloud computing Simple formulas that explain the quantitative aspects of reliability and availability Enlightening discussions of the ways in which virtualized applications and cloud deployments differ from traditional system implementations and deployments Specific recommendations for developing reliable virtualized applications and cloud-based solutions  Reliability and Availability of Cloud Computing is the guide for IS/IT staff in business, government, academia, and non-governmental organizations who are moving their applications to the cloud. It is also an important reference for professionals in technical sales, product management, and quality management, as well as software and quality engineers looking to broaden their expertise.},
	language = {English},
	publisher = {Wiley-IEEE Press},
	author = {Bauer, Eric and Adams, Randee},
	month = aug,
	year = {2012},
	keywords = {Computers / Cloud Computing, Computers / Networking / General}
}

@book{fiondella-principles:2016,
	address = {Cham},
	series = {Springer {Series} in {Reliability} {Engineering}},
	title = {Principles of {Performance} and {Reliability} {Modeling} and {Evaluation}},
	isbn = {978-3-319-30597-4 978-3-319-30599-8},
	url = {http://link.springer.com/10.1007/978-3-319-30599-8},
	urldate = {2017-09-22},
	publisher = {Springer International Publishing},
	editor = {Fiondella, Lance and Puliafito, Antonio},
	year = {2016},
	note = {DOI: 10.1007/978-3-319-30599-8}
}

@book{wu-cloud:2015,
	title = {Cloud {Data} {Centers} and {Cost} {Modeling}: {A} {Complete} {Guide} {To} {Planning}, {Designing} and {Building} a {Cloud} {Data} {Center}},
	isbn = {978-0-12-801688-6},
	shorttitle = {Cloud {Data} {Centers} and {Cost} {Modeling}},
	abstract = {Cloud Data Centers and Cost Modeling establishes a framework for strategic decision-makers to facilitate the development of cloud data centers. Just as building a house requires a clear understanding of the blueprints, architecture, and costs of the project; building a cloud-based data center requires similar knowledge. The authors take a theoretical and practical approach, starting with the key questions to help uncover needs and clarify project scope. They then demonstrate probability tools to test and support decisions, and provide processes that resolve key issues. After laying a foundation of cloud concepts and definitions, the book addresses data center creation, infrastructure development, cost modeling, and simulations in decision-making, each part building on the previous. In this way the authors bridge technology, management, and infrastructure as a service, in one complete guide to data centers that facilitates educated decision making.Explains how to balance cloud computing functionality with data center efficiencyCovers key requirements for power management, cooling, server planning, virtualization, and storage managementDescribes advanced methods for modeling cloud computing cost including Real Option Theory and Monte Carlo SimulationsBlends theoretical and practical discussions with insights for developers, consultants, and analysts considering data center development},
	language = {en},
	publisher = {Morgan Kaufmann},
	author = {Wu, Caesar and Buyya, Rajkumar},
	month = feb,
	year = {2015},
	keywords = {Computers / Internet / General, Computers / Networking / General}
}

@article{weibull-reliability:2007,
	title = {Reliability Basics: Availability and the Different Ways to Calculate It},
	volume = {79},
	url = {http://www.weibull.com/hotwire/issue79/relbasics79.htm},
	journaltitle = {Weibull: Reliability {HotWire}},
	journal = {Weibull: Reliability {HotWire}},
	author = {Weibull},
	urldate = {2017-09-19},
	year = {2007},
	file = {Reliability Basics\: Availability and the Different Ways to Calculate It:/home/daniel/Insync/Zotero/storage/KTXD5NKQ/relbasics79.html:text/html}
}
{silva-adaptive:2015,
	title = {Adaptive Remus: replica\{c}c\~ao de m\'aquinas virtuais Xen com checkpointing adapt\'avel},
	url = {http://tede.udesc.br//handle/handle/2046},
	shorttitle = {Adaptive Remus},
	abstract = {With the ever-increasing dependence on computers and networks, many systems are required to be continuously available in order to fulfill their mission. Virtualization technology enables high availability to be offered in a convenient, cost-effective manner: with the encapsulation provided by virtual machines ({VMs}), entire systems can be replicated transparently in software, obviating the need for expensive fault-tolerant hardware. Remus is a {VM} replication mechanism for the Xen hypervisor that provides high availability despite crash failures. Replication is performed by checkpointing the {VM} at fixed intervals. However, there is an antagonism between processing and communication regarding the optimal checkpointing interval: while longer intervals benefit processorintensive applications, shorter intervals favor network-intensive applications. Thus, any chosen interval may not always be suitable for the hosted applications, limiting Remus usage in many scenarios. This work introduces Adaptive Remus, a proposal for adaptive checkpointing in Remus that dynamically adjusts the replication frequency according to the characteristics of running applications. Experimental results indicate that our proposal improves performance for applications that require both processing and communication, without harming applications that use only one type of resource.},
	author = {Silva, Marcelo Pereira da},
	urldate = {2017-09-03},
	year = {2015},
	file = {Silva - 2015 - Adaptive Remus replica\{c}c\~ao de m\'aquinas virtuais Xe.pdf:/home/daniel/Insync/Zotero/storage/DEM3A5S9/Silva - 2015 - Adaptive Remus replica\{c}c\~ao de m\'aquinas virtuais Xe.pdf:application/pdf;Snapshot:/home/daniel/Insync/Zotero/storage/NHIV5MMS/2046.html:text/html}
}

@article{petri-modular:2014,
	title = {A modular optimisation model for reducing energy consumption in large scale building facilities},
	volume = {38},
	issn = {1364-0321},
	url = {http://www.sciencedirect.com/science/article/pii/S1364032114004961},
	doi = {10.1016/j.rser.2014.07.044},
	abstract = {With the pressing regulatory requirement to increase energy efficiency in our built environment, significant researching efforts have been recently directed towards energy optimisation with the overall objective of reducing energy consumption. Energy simulation and optimisation identify a class of applications that demand high performance processing power in order to be realised within a feasible time-frame. The problem becomes increasingly complex when undertaking such energy simulation and optimisation in large scale buildings such as sport facilities where the generation of optimal set points can be timing inefficient. In this paper we present how a modular based optimisation system can be efficiently used for running energy simulation and optimisation in order to fulfil a number of energy related objectives. The solution can address the variability in building dynamics and provide support for building managers in implementing energy efficient optimisation plans. We present the optimisation system that has been implemented based on energy saving specifications from {EU} {FP}7 project – {SportE}2 (Energy Efficiency for Sport Facilities) and evaluate the efficiency of the system over a number of relevant use-case scenarios.},
	pages = {990--1002},
	journaltitle = {Renewable and Sustainable Energy Reviews},
	shortjournal = {Renewable and Sustainable Energy Reviews},
	author = {Petri, Ioan and Li, Haijiang and Rezgui, Yacine and Chunfeng, Yang and Yuce, Baris and Jayan, Bejay},
	urldate = {2017-08-28},
	year = {2014},
	langid = {english},
	keywords = {Artificial neural network, Building simulation, Energy optimisation, genetic algorithm, High performance computing},
	file = {Petri et al. - 2014 - A modular optimisation model for reducing energy c.pdf:/home/daniel/Insync/Zotero/storage/BM9WRA5V/Petri et al. - 2014 - A modular optimisation model for reducing energy c.pdf:application/pdf;ScienceDirect Snapshot:/home/daniel/Insync/Zotero/storage/C9NGDSAV/S1364032114004961.html:text/html}
}

@inproceedings{koslovski-reliability:2010,
	title = {Reliability Support in Virtual Infrastructures},
	doi = {10.1109/CloudCom.2010.23},
	abstract = {Through the recent emergence of joint resource and network virtualization, dynamic composition and provisioning of time-limited and isolated virtual infrastructures is now possible. One other benefit of infrastructure virtualization is the capability of transparent reliability provisioning (reliability becomes a service provided by the infrastructure). In this context, we discuss the motivations and gains of introducing customizable reliability of virtual infrastructures when executing large-scale distributed applications, and present a framework to specify, allocate and deploy virtualized infrastructure with reliability capabilities. An approach to efficiently specify and control the reliability at runtime is proposed. We illustrate these ideas by analyzing the introduction of reliability at the virtual-infrastructure level on a real application. Experimental results, obtained with an actual medical-imaging application running in virtual infrastructures provisioned in the experimental large-scale Grid'5000 platform, show the benefits of the virtualization of reliability.},
	eventtitle = {2010 {IEEE} Second International Conference on Cloud Computing Technology and Science},
	pages = {49--58},
	booktitle = {2010 {IEEE} Second International Conference on Cloud Computing Technology and Science},
	author = {Koslovski, G. and Yeow, W. L. and Westphal, C. and Huu, T. T. and Montagnat, J. and Vicat-Blanc, P.},
	year = {2010},
	keywords = {allocation, Computational modeling, customizable reliability, description language, distributed processing, dynamic composition, Grid 5000 platform, joint resource, large scale distributed application, medical imaging application, network virtualization, Redundancy, Reliability, Reliability engineering, reliability support, Resource management, Substrates, Synchronization, virtual enterprises, virtual infrastructure, virtual infrastructures},
	file = {IEEE Xplore Abstract Record:/home/daniel/Insync/Zotero/storage/RMRWWWKT/5708433.html:text/html;Koslovski et al. - 2010 - Reliability Support in Virtual Infrastructures.pdf:/home/daniel/Insync/Zotero/storage/B6JD4HBV/Koslovski et al. - 2010 - Reliability Support in Virtual Infrastructures.pdf:application/pdf}
}

@inproceedings{oechsner-flexible:2015,
	title = {Flexible support of {VNF} placement functions in {OpenStack}},
	url = {http://ieeexplore.ieee.org/abstract/document/7116178/},
	pages = {1--6},
	booktitle = {Network Softwarization ({NetSoft}), 2015 1st {IEEE} Conference on},
	publisher = {{IEEE}},
	author = {Oechsner, Simon and Ripke, Andreas},
	urldate = {2017-08-31},
	year = {2015},
	file = {oechsner_mission_cr.pdf:/home/daniel/Insync/Zotero/storage/KND6VUEZ/oechsner_mission_cr.pdf:application/pdf}
}
{endo-high:2016,
	title = {High availability in clouds: systematic review and research challenges},
	volume = {5},
	issn = {2192-113X},
	url = {https://doi.org/10.1186/s13677-016-0066-8},
	doi = {10.1186/s13677-016-0066-8},
	shorttitle = {High availability in clouds},
	abstract = {Cloud Computing has been used by different types of clients because it has many advantages, including the minimization of infrastructure resources costs, and its elasticity property, which allows services to be scaled up or down according to the current demand. From the Cloud provider point-of-view, there are many challenges to be overcome in order to deliver Cloud services that meet all requirements defined in Service Level Agreements ({SLAs}). High availability has been one of the biggest challenges for providers, and many services can be used to improve the availability of a service, such as checkpointing, load balancing, and redundancy. Beyond services, we can also find infrastructure and middleware solutions. This systematic review has as its main goal to present and discuss high available ({HA}) solutions for Cloud Computing, and to introduce some research challenges in this area. We hope this work can be used as a starting point to understanding and coping with {HA} problems in Cloud.},
	pages = {16},
	journal = {Journal of Cloud Computing},
	shortjournal = {Journal of Cloud Computing},
	author = {Endo, Patricia T. and Rodrigues, Mois\'es and Gon\{c}calves, Glauco E. and Kelner, Judith and Sadok, Djamel H. and Curescu, Calin},
	urldate = {2017-08-01},
	year = {2016},
	month = oct,
	keywords = {cloud computing, High Availability, Research challenges, Systematic review},
	file = {Endo et al. - 2016 - High availability in clouds systematic review and.pdf:/home/daniel/Insync/Zotero/storage/7JQNVNRA/Endo et al. - 2016 - High availability in clouds systematic review and.pdf:application/pdf}
}

@article{sharma-sla:2017,
	title = {{SLA} and Performance Efficient Heuristics for Virtual Machines Placement in Cloud Data Centers},
	volume = {9},
	rights = {Access limited to members},
	issn = {1938-0259 {DOI}: 10.4018/{IJGHPC}.2017070102},
	url = {https://www.igi-global.com/article/sla-and-performance-efficient-heuristics-for-virtual-machines-placement-in-cloud-data-centers/185771},
	doi = {10.4018/IJGHPC.2017070102},
	abstract = {{SLA} and Performance Efficient Heuristics for Virtual Machines Placement in Cloud Data Centers: 10.4018/{IJGHPC}.2017070102: Cloud computing has revolutionized the working models of {IT} industry and increasing the demand of cloud resources which further leads to increase in energy},
	pages = {17--33},
	number = {3},
	journaltitle = {International Journal of Grid and High Performance Computing ({IJGHPC})},
	shortjournal = {{IJGHPC}},
	author = {Sharma, Oshin and Saini, Hemraj},
	urldate = {2017-08-08},
	year = {2017},
	langid = {english}
}

@inproceedings{brenner-adaptive:2014,
	title = {Adaptive and scalable high availability for infrastructure clouds},
	url = {http://link.springer.com/chapter/10.1007/978-3-662-43352-2_2},
	pages = {16--30},
	booktitle = {{IFIP} International Conference on Distributed Applications and Interoperable Systems},
	publisher = {Springer},
	author = {Brenner, Stefan and Garbers, Benjamin and Kapitza, Rüdiger},
	urldate = {2017-08-31},
	year = {2014},
	file = {Brenner et al. - 2014 - Adaptive and scalable high availability for infras.pdf:/home/daniel/Insync/Zotero/storage/ZH8BJ9RT/Brenner et al. - 2014 - Adaptive and scalable high availability for infras.pdf:application/pdf}
}

@inproceedings{caraman-continuous:2012,
	title = {Continuous disaster tolerance in the iaas clouds},
	url = {http://ieeexplore.ieee.org/abstract/document/6231987/},
	pages = {1226--1232},
	booktitle = {Optimization of Electrical and Electronic Equipment ({OPTIM}), 2012 13th International Conference on},
	publisher = {{IEEE}},
	author = {Caraman, Mihai Claudiu and Moraru, Sorin Aurel and Dan, Stefan and Grama, Catalin},
	urldate = {2017-08-31},
	year = {2012},
	file = {Caraman et al. - 2012 - Continuous disaster tolerance in the iaas clouds.pdf:/home/daniel/Insync/Zotero/storage/PSTJX5JC/Caraman et al. - 2012 - Continuous disaster tolerance in the iaas clouds.pdf:application/pdf}
}

@collection{kiriha-2010:2010,
	location = {Piscataway, {NJ}},
	title = {2010 {IEEE} Network Operations and Management Symposium: {NOMS} 2010 ; Osaka, Japan, 19 - 23 April 2010},
	isbn = {978-1-4244-5366-5 978-1-4244-5367-2},
	shorttitle = {2010 {IEEE} Network Operations and Management Symposium},
	pagetotal = {948},
	publisher = {{IEEE}},
	editor = {Kiriha, Yoshiaki and {Institute of Electrical and Electronics Engineers} and {Communications Society} and {International Federation for Information Processing}},
	year = {2010},
	note = {{OCLC}: 838470083},
	annotation = {Kongr.-Thema: Towards management of future networks and services Parallel als Online-Ausg. erschienen}
}

@article{dong-colo:2013,
	title = {{COLO}: {COarse}-grained {LOck}-stepping virtual machines for non-stop service},
	isbn = {978-1-4503-2428-1},
	url = {http://dl.acm.org/citation.cfm?doid=2523616.2523630},
	doi = {10.1145/2523616.2523630},
	shorttitle = {{COLO}},
	pages = {1--16},
	publisher = {{ACM} Press},
	journal = {{ACM} Press},
	author = {Dong, {YaoZu} and Ye, Wei and Jiang, {YunHong} and Pratt, Ian and Ma, {ShiQing} and Li, Jian and Guan, {HaiBing}},
	urldate = {2017-08-30},
	year = {2013},
	langid = {english},
	file = {a3-dong.pdf:/home/daniel/Insync/Zotero/storage/ZQHJTDRV/a3-dong.pdf:application/pdf}
}

@inproceedings{molina-addressing:2013,
	title = {Addressing memory exhaustion failures in Virtual Machines in a cloud environment},
	url = {http://ieeexplore.ieee.org/abstract/document/6575330/},
	pages = {1--6},
	booktitle = {Dependable Systems and Networks ({DSN}), 2013 43rd Annual {IEEE}/{IFIP} International Conference on},
	publisher = {{IEEE}},
	author = {Molina, Jose Antonio Navas and Mishra, Shivakant},
	urldate = {2017-09-03},
	year = {2013},
	file = {Molina e Mishra - 2013 - Addressing memory exhaustion failures in Virtual M.pdf:/home/daniel/Insync/Zotero/storage/6MRBSHP5/Molina e Mishra - 2013 - Addressing memory exhaustion failures in Virtual M.pdf:application/pdf}
}

@book{elsayed-reliability:2012,
	title = {Reliability Engineering},
	isbn = {978-1-118-30954-4},
	abstract = {A newly revised and updated edition that details both the theoretical foundations and practical applications of reliability engineering Reliability is one of the most important quality characteristics of components, products, and large and complex systems—but it takes a significant amount of time and resources to bring reliability to fruition. Thoroughly classroom- and industry-tested, this book helps ensure that engineers see reliability success with every product they design, test, and manufacture. Divided into three parts, Reliability Engineering, Second Edition handily describes the theories and their practical uses while presenting readers with real-world examples and problems to solve. Part I focuses on system reliability estimation for time independent and failure dependent models, helping engineers create a reliable design. Part {II} aids the reader in assembling necessary components and configuring them to achieve desired reliability objectives, conducting reliability tests on components, and using field data from similar components. Part {III} follows what happens once a product is produced and sold, how the manufacturer must ensure its reliability objectives by providing preventive and scheduled maintenance and warranty policies. This Second Edition includes in-depth and enhanced chapter coverage of:  Reliability and Hazard Functions System Reliability Evaluation Time- and Failure-Dependent Reliability Estimation Methods of the Parameters of Failure-Time Distributions Parametric Reliability Models Models for Accelerated Life Testing Renewal Processes and Expected Number of Failures Preventive Maintenance and Inspection Warranty Models Case Studies  A comprehensive reference for practitioners and professionals in quality and reliability engineering, Reliability Engineering can also be used for senior undergraduate or graduate courses in industrial and systems, mechanical, and electrical engineering programs.},
	pagetotal = {791},
	publisher = {John Wiley \& Sons},
	author = {Elsayed, Elsayed A.},
	year = {2012},
	langid = {english},
	keywords = {Technology \& Engineering / Electrical, Technology \& Engineering / Quality Control}
}

@article{almihoub-marginal:2013,
	title = {Marginal Abatement Cost Curves ({MACCs}): Important Approaches to Obtain (Firm and Sector) Greenhouse Gases ({GHGs}) Reduction},
	volume = {5},
	issn = {1916-9728, 1916-971X},
	url = {http://www.ccsenet.org/journal/index.php/ijef/article/view/26701},
	doi = {10.5539/ijef.v5n5p35},
	shorttitle = {Marginal Abatement Cost Curves ({MACCs})},
	number = {5},
	journaltitle = {International Journal of Economics and Finance},
	author = {Almihoub, Ali Ahmed Ali and Mula, Joseph M. and Rahman, Mohammad Mafizur},
	urldate = {2017-08-28},
	year = {2013},
	file = {16306.pdf:/home/daniel/Insync/Zotero/storage/TCVZAB6H/16306.pdf:application/pdf}
}

@article{barringer-availability:1997,
	title = {Availability, Reliability, Maintainability, and Capability},
	url = {https://pdfs.semanticscholar.org/973c/a4acc67b5d0b13c79c98653e23d8b0a2289e.pdf},
	series = {Barringer \& Associates, Inc},
	abstract = {Availability,  reliability,  maintainability,  and  capability  are  components  of  the  effectiveness  equation.    The
effectiveness equation is a figure of merit which is helpful for deciding which component(s) detract from
performance  measures.    In  many  continuous  process  plants  the  reliability  component  is  the  largest
detractor  from  better  performance.    Calculation  of  the  components  are  illustrated  by  use  of  a  small  data
set.},
	pages = {11},
	author = {Barringer, H. P.},
	urldate = {2017-08-21},
	year = {1997},
	file = {Barringer - 1997 - Availability, Reliability, Maintainability, and Ca.pdf:/home/daniel/Insync/Zotero/storage/X8Q5ZV5H/Barringer - 1997 - Availability, Reliability, Maintainability, and Ca.pdf:application/pdf}
}

@techreport{evo-world-international:2002,
	title = {International Performance Measurement and Verification Protocol: Concepts and Options for Determining Energy and Water Savings},
	url = {https://eric.ed.gov/?id=ED144007},
	number = {{DOE}/{GO}-102002-1554},
	institution = {U.S. Department of Energy, {EVO}-World},
	author = {{EVO}-{WORLD}, , Org},
	urldate = {2017-08-28},
	year = {2002},
	file = {31505.pdf:/home/daniel/Insync/Zotero/storage/65JJ6UR9/31505.pdf:application/pdf;ipmvp_volume_i__2012.pdf:/home/daniel/Insync/Zotero/storage/KQGXS3SE/ipmvp_volume_i__2012.pdf:application/pdf}
}

@inproceedings{chavan-clustered:2014,
	title = {Clustered virtual machines for higher availability of resources with improved scalability in cloud computing},
	doi = {10.1109/CNSC.2014.6906707},
	abstract = {Cloud computing a big pool of resources dynamically reconfigures its resources as per user requirement in real time. Cloud environment mostly works with virtualized environment, which is a key consideration for providing virtual machines as a service to the users. It is difficult to manage virtual machine, and to deploy on any data centers. In cloud environment users expects better services from the vendors, in order to improve resource utilization. The factors in cloud environment as if scalability and availability are consider for better outcomes for users. This not only saves time, but also improves cost utilization. This paper proposes architecture, based on clustering virtual machines in datacenters for higher availability of resources with improved scalability. Clustering helps virtual machines to reconfigure and easy scheduling. The resource sharing in cloud will optimize and users get maximized result. Further, the paper directs a mathematical model for explaining the concepts of the proposed system. The existing system is being modulated using simulation tools and further elaborated in the paper.},
	eventtitle = {2014 First International Conference on Networks Soft Computing ({ICNSC}2014)},
	pages = {221--225},
	booktitle = {2014 First International Conference on Networks Soft Computing ({ICNSC}2014)},
	author = {Chavan, V. and Kaveri, P. R.},
	year = {2014},
	keywords = {architecture, availability, cloud computing, cloud environment, Cloud Report, {CloudSim}, Cluster, clustering, Computer architecture, cost utilization, Data centers, Mathematical model, pattern clustering, real time, resource allocation, Resource management, resources availability, resource sharing, resource utilization, scalability, Scheduling, simulation tools, software architecture, user requirement, virtualized environment, virtual machines, Virtual machining},
	file = {Chavan e Kaveri - 2014 - Clustered virtual machines for higher availability.pdf:/home/daniel/Insync/Zotero/storage/6RCQ376K/Chavan e Kaveri - 2014 - Clustered virtual machines for higher availability.pdf:application/pdf}
}

@techreport{odca-master:2014,
	title = {Master Usage Model: Compute Infrastructure as a Service ({CIaaS}) Rev2.0},
	url = {https://opendatacenteralliance.org/docs/compute_infrastructure_as_a_service_rev_2.pdf},
	pages = {58},
	institution = {{OPEN} {DATA} {CENTER} {ALLIANCE}},
	type = {Master {USAGE} {MODEL}},
	author = {{ODCA}},
	urldate = {2017-09-23},
	year = {2014},
	file = {ODCA - 2014 - Master Usage Model Compute Infrastructure as a Se.pdf:/home/daniel/Insync/Zotero/storage/2PC9JJ28/ODCA - 2014 - Master Usage Model Compute Infrastructure as a Se.pdf:application/pdf}
}

@misc{rieck-basic:2010,
	title = {Basic Analysis of Bin-Packing Heuristics},
	url = {http://bastian.rieck.ru/uni/bin_packing/bin_packing.pdf},
	abstract = {The benchmarks have been performed using an Intel Celeron M 1.5 {GHz}. The results are
not too surprising: Obviously, the Next-Fit heuristic is fastest because only 1 bin has to be
managed. However, due to the efficient data structure (a priority queue) that has been used
for the Max-Rest heuristic, this heuristic will generally be almost as fast as Next-Fit.
Furthermore, the implementation of the Best-Fit heuristic has a worst-case running time of O
(Kn), where K is the maximum weight. Thus, the slowest algorithms are First-Fit and First},
	publisher = {Interdisciplinary Center for Scientific Computing. Heildelberg University},
	author = {Rieck, Bastian},
	urldate = {2017-09-17},
	year = {2010},
	file = {Basic Analysis of Bin-Packing Heuristics - bin_packing.pdf:/home/daniel/Insync/Zotero/storage/Q8XHCMA9/bin_packing.pdf:application/pdf}
}

@article{fischer-high:2006,
	title = {High availability clustering of virtual machines–possibilities and pitfalls},
	volume = {1},
	url = {https://pdfs.semanticscholar.org/0072/1298260d3458b7d3555fa1e347e8ec11c84c.pdf},
	urldate = {2017-08-01},
	journal = {Paper for the talk at the 12th Linuxtag, May 3rd-6th, Wiesbaden/Germany Version},
	author = {Fischer, Werner and Mitasch, Christoph},
	year = {2006},
	file = {download.pdf:/home/dani/Insync/Zotero/storage/J6Z7JDNG/download.pdf:application/pdf}
}

@inproceedings{cully-remus:2008,
	title = {Remus: {High} availability via asynchronous virtual machine replication},
	shorttitle = {Remus},
	url = {https://www.usenix.org/legacy/event/nsdi08/tech/full_papers/cully/cully_html/},
	urldate = {2017-03-20},
	booktitle = {Proceedings of the 5th {USENIX} {Symposium} on {Networked} {Systems} {Design} and {Implementation}},
	publisher = {San Francisco},
	author = {Cully, Brendan and Lefebvre, Geoffrey and Meyer, Dutch and Feeley, Mike and Hutchinson, Norm and Warfield, Andrew},
	year = {2008},
	pages = {161--174},
	file = {cully.pdf:/home/dani/Insync/Zotero/storage/UQDCC5F3/cully.pdf:application/pdf;Remus\: High Availability via Asynchronous Virtual Machine Replication:/home/dani/Insync/Zotero/storage/Q2FCWBVT/index.html:text/html}
}

@inproceedings{yeow-designing:2010,
	title = {Designing and embedding reliable virtual infrastructures},
	isbn = {978-1-4503-0199-2},
	url = {http://portal.acm.org/citation.cfm?doid=1851399.1851406},
	doi = {10.1145/1851399.1851406},
	language = {en},
	urldate = {2017-06-21},
	publisher = {ACM Press},
	booktitle = {VISA '10 - ACM SIGCOMM workshop on Virtualized infrastructure systems and architectures},
	author = {Yeow, Wai-Leong and Westphal, C\'edric and Kozat, Ulaş},
	year = {2010},
	pages = {33},
	file = {1971162-1971173.pdf:/home/dani/Insync/Zotero/storage/E7WEA4G5/1971162-1971173.pdf:application/pdf}
}

@article{capone-design:2012,
	title = {Design and implementation of a reliable and cost-effective cloud computing infrastructure: the {INFN} {Napoli} experience},
	volume = {396},
	issn = {1742-6596},
	shorttitle = {Design and implementation of a reliable and cost-effective cloud computing infrastructure},
	url = {http://stacks.iop.org/1742-6596/396/i=4/a=042012},
	doi = {10.1088/1742-6596/396/4/042012},
	abstract = {Over the last few years we have seen an increasing number of services and applications needed to manage and maintain cloud computing facilities. This is particularly true for computing in high energy physics, which often requires complex configurations and distributed infrastructures. In this scenario a cost effective rationalization and consolidation strategy is the key to success in terms of scalability and reliability. In this work we describe an IaaS (Infrastructure as a Service) cloud computing system, with high availability and redundancy features, which is currently in production at INFN-Naples and ATLAS Tier-2 data centre. The main goal we intended to achieve was a simplified method to manage our computing resources and deliver reliable user services, reusing existing hardware without incurring heavy costs. A combined usage of virtualization and clustering technologies allowed us to consolidate our services on a small number of physical machines, reducing electric power costs. As a result of our efforts we developed a complete solution for data and computing centres that can be easily replicated using commodity hardware. Our architecture consists of 2 main subsystems: a clustered storage solution, built on top of disk servers running GlusterFS file system, and a virtual machines execution environment. GlusterFS is a network file system able to perform parallel writes on multiple disk servers, providing this way live replication of data. High availability is also achieved via a network configuration using redundant switches and multiple paths between hypervisor hosts and disk servers. We also developed a set of management scripts to easily perform basic system administration tasks such as automatic deployment of new virtual machines, adaptive scheduling of virtual machines on hypervisor hosts, live migration and automated restart in case of hypervisor failures.},
	language = {en},
	number = {4},
	urldate = {2017-07-27},
	journal = {J. Phys.: Conf. Ser.},
	author = {Capone, V. and Esposito, R. and Pardi, S. and Taurino, F. and Tortone, G.},
	year = {2012},
	pages = {042012},
	file = {IOP Full Text PDF:/home/dani/Insync/Zotero/storage/763WIF2D/Capone et al. - 2012 - Design and implementation of a reliable and cost-e.pdf:application/pdf}
}

@article{lopez-pires-virtual:2015,
	title = {Virtual {Machine} {Placement} {Literature} {Review}},
	url = {http://arxiv.org/abs/1506.01509},
	abstract = {Cloud Computing Datacenters host millions of virtual machines (VMs) on real world scenarios. In this context, Virtual Machine Placement (VMP) is one of the most challenging problems in cloud infrastructure management, considering also the large number of possible optimization criteria and different formulations that could be studied. VMP literature include relevant topics such as energy-efficiency, Service Level Agreements (SLA), cloud service markets, Quality of Service (QoS) and carbon dioxide emissions, all of them with high economical and ecological impact. This work presents an extensive up-to-date review of the most relevant VMP literature in order to identify research opportunities.},
	urldate = {2017-07-30},
	journal = {arXiv:1506.01509 [cs]},
	author = {Lopez-Pires, Fabio and Baran, Benjamin},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.01509},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {arXiv\:1506.01509 PDF:/home/dani/Insync/Zotero/storage/MWZ9VBRS/Lopez-Pires e Baran - 2015 - Virtual Machine Placement Literature Review.pdf:application/pdf;arXiv.org Snapshot:/home/dani/Insync/Zotero/storage/EBQDKNQH/1506.html:text/html}
}

@inproceedings{jin-partners:2013,
	title = {A {Partners} {Assisted} {Virtual} {Machine} {Live} {Storage} {Migration} for {Intensive} {Disk} {I}/{O} {Workloads}},
	doi = {10.1109/HPCC.and.EUC.2013.240},
	abstract = {Live migration of virtual machine (VM) enables mobility of VM and contributes to advantages of virtualization like energy saving, high availability, fault tolerance and work load balancing. However solutions of VMs' migration in both theoretical and industrial areas concentrate more on memory migration other than storage migration. Lots of applications with intensive disk I/O operations rely on local storage, especially when it comes to high performance computing. Migration of shared storage is also of necessity for consolidation and workload balance. Current approaches on storage migration can hardly work effectively in disk I/O intensive environment. They cannot reduce migration time and guarantee the disk I/O performance of VMs at the same time. This paper proposes an approach called Partners Assisted Storage Migration (PASM). We are the first to utilize disk I/O ability of pre-allocated storage nodes to relieve the competition between VMs' intensive disk I/O and storage migration. It can migrate VMs' storage effectively comparing to current methods: post-copy and write-mirror. Experiments including single VM's migration and multiple VMs' migration show that PASM can save 78.9\% migration time and achieve additional 27.1\% in disk I/O performance over existing methods.},
	booktitle = {2013 {IEEE} 10th {International} {Conference} on {High} {Performance} {Computing} and {Communications} 2013 {IEEE} {International} {Conference} on {Embedded} and {Ubiquitous} {Computing}},
	author = {Jin, X. and Wang, H. and Wang, J. and Cheng, S. and Li, J.},
	month = nov,
	year = {2013},
	keywords = {cloud computing, Degradation, disk I/O intensive applications, energy saving, fault tolerance, High performance computing, intensive disk I/O workloads, Kernel, live migration, Maintenance engineering, memory migration, parallel processing, partners assisted virtual machine live storage migration, PASM, post-copy method, pre-allocated storage nodes, resource allocation, shared storage migration, storage management, storage migration, Synchronization, virtualisation, Virtualization, virtual machines, VM intensive disk I/O and storage migration, work load balancing, write-mirror method, Writing},
	pages = {1693--1698},
	file = {IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/IKUZ243U/6832122.html:text/html;IEEE Xplore Full Text PDF:/home/dani/Insync/Zotero/storage/TGT4K94Q/Jin et al. - 2013 - A Partners Assisted Virtual Machine Live Storage M.pdf:application/pdf}
}

@inproceedings{wang-improving:2014,
	title = {Improving utilization through dynamic {VM} resource allocation in hybrid cloud environment},
	doi = {10.1109/PADSW.2014.7097814},
	abstract = {Virtualization is one of the most fascinating techniques because it can facilitate the infrastructure management and provide isolated execution for running workloads. Despite the benefits gained from virtualization and resource sharing, improved resource utilization is still far from settled due to the dynamic resource requirements and the widely-used over-provision strategy for guaranteed QoS. Additionally, with the emerging demands for big data analytic, how to effectively manage hybrid workloads such as traditional batch task and long-running virtual machine (VM) service needs to be dealt with. In this paper, we propose a system to combine long-running VM service with typical batch workload like MapReduce. The objectives are to improve the holistic cluster utilization through dynamic resource adjustment mechanism for VM without violating other batch workload executions. Furthermore, VM migration is utilized to ensure high availability and avoid potential performance degradation. The experimental results reveal that the dynamically allocated memory is close to the real usage with only 10\% estimation margin, and the performance impact on VM and MapReduce jobs are both within 1\%. Additionally, at most 50\% increment of resource utilization could be achieved. We believe that these findings are in the right direction to solving workload consolidation issues in hybrid computing environments.},
	booktitle = {2014 20th {IEEE} {International} {Conference} on {Parallel} and {Distributed} {Systems} ({ICPADS})},
	author = {Wang, Y. and Yang, R. and Wo, T. and Jiang, W. and Hu, C.},
	month = dec,
	year = {2014},
	keywords = {batch workload executions, Benchmark testing, big data analytic, cloud computing, cluster utilization, Containers, data analysis, dynamic memory allocation, dynamic resource adjustment mechanism, dynamic resource requirements, Dynamic scheduling, dynamic VM resource allocation, hybrid cloud environment, hybrid computing environments, improved resource utilization, infrastructure management, long-running virtual machine service, MapReduce, Memory management, parallel processing, Protocols, QoS, quality of service, resource allocation, Resource management, resource sharing, virtualisation, Virtualization, virtual machines, VM migration, VM Resource Dynamic Allocation, VM service, workload consolidation issues, Yarn},
	pages = {241--248},
	file = {IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/UMRBEQ5J/7097814.html:text/html;IEEE Xplore Full Text PDF:/home/dani/Insync/Zotero/storage/T59E9TWH/Wang et al. - 2014 - Improving utilization through dynamic VM resource .pdf:application/pdf}
}

@inproceedings{simonin-autonomic:2013,
	title = {An {Autonomic} and {Scalable} {Management} {System} for {Private} {Clouds}},
	doi = {10.1109/CCGrid.2013.44},
	abstract = {Snooze is an open-source scalable, autonomic, and energy-efficient virtual machine (VM) management framework for private clouds. It allows users to build compute infrastructures from virtualized resources. Particularly, once installed and configured, it allows its users to submit and control the life-cycle of a large number of VMs. For scalability, the system relies on a self-organizing hierarchical architecture. Moreover, it implements self-healing mechanisms in case of failure to enable high availability. It also performs energy-efficient distributed VM management through consolidation and power management techniques. This poster focuses on the experimental validation of two main properties of Snooze: scalability and fault-tolerance.},
	booktitle = {2013 13th {IEEE}/{ACM} {International} {Symposium} on {Cluster}, {Cloud}, and {Grid} {Computing}},
	author = {Simonin, M. and Feller, E. and Orgerie, A. C. and J\'egou, Y. and Morin, C.},
	month = may,
	year = {2013},
	keywords = {autonomic computing, autonomic management system, autonomic virtual machine management framework, cloud computing, Computer architecture, data privacy, distributed VM management, energy-efficient virtual machine management framework, fault tolerance, fault-tolerance, fault tolerant computing, Fault tolerant systems, Monitoring, open-source scalable virtual machine management framework, power aware computing, power management techniques, private clouds, public domain software, Resource management, scalability, scalable management system, self-organizing hierarchical architecture, snooze, virtualized resources, virtual machines},
	pages = {198--199},
	file = {IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/K9EZDBTG/6546091.html:text/html;IEEE Xplore Full Text PDF:/home/dani/Insync/Zotero/storage/BDWXVE2E/Simonin et al. - 2013 - An Autonomic and Scalable Management System for Pr.pdf:application/pdf}
}

@InProceedings{Li2017,
  author    = {Li, X. and Qi, Y. and Chen, P. and Zhang, X.},
  title     = {Optimizing {Backup} {Resources} in the {Cloud}},
  booktitle = {2016 {IEEE} 9th {International} {Conference} on {Cloud} {Computing} ({CLOUD})},
  year      = {2017},
  pages     = {790--797},
  month     = jun,
  abstract  = {Cloud computing promises high performance and cost-efficiency, however, most cloud infrastructures operate at low utilization which greatly adhere cost effectiveness. Previous works focus on seeking efficient virtual machine (VM) consolidation strategies to increase the utilization of virtual resources in production environment, while overlooking the under-utilization of backup virtual resources. We propose a heuristic time sharing policy derived from the restless multi-armed bandit problem. The proposed policy achieves increasing backup virtual resources utilization while providing high availability. The experiment results show that the traditional 1:1 backup provision can be extended to 1:M (M{\textgreater}{\textgreater}1) between the backup VM and the service VMs, and the utilization of backup VMs can be enhanced significantly.},
  doi       = {10.1109/CLOUD.2016.0109},
  file      = {IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/7CA9J6D8/7820346.html:text/html;IEEE Xplore Full Text PDF:/home/dani/Insync/Zotero/storage/62Q6M9M6/Li et al. - 2016 - Optimizing Backup Resources in the Cloud.pdf:application/pdf},
  keywords  = {back up, backup resource optimization, backup virtual resource under-utilization, backup virtual resource utilization, cloud computing, cloud infrastructures, Computer bugs, Dynamic scheduling, Google, heuristic time sharing policy, Maintenance engineering, Markov processes, production environment, restless multi-armed bandit, restless multiarmed bandit problem, Virtualization, virtual machine, virtual machines, VM consolidation strategy},
}

@inproceedings{strunk-does:2013,
	title = {Does live migration of virtual machines cost energy?},
	url = {http://ieeexplore.ieee.org/abstract/document/6531798/},
	urldate = {2017-06-14},
	booktitle = {Advanced {Information} {Networking} and {Applications} ({AINA}), 2013 {IEEE} 27th {International} {Conference} on},
	publisher = {IEEE},
	author = {Strunk, Anja and Dargie, Waltenegus},
	year = {2013},
	pages = {514--521},
	file = {Strunk e Dargie - 2013 - Does live migration of virtual machines cost energ.pdf:/home/dani/Insync/Zotero/storage/9QXWZ4C9/Strunk e Dargie - 2013 - Does live migration of virtual machines cost energ.pdf:application/pdf}
}

@article{liu-performance:2013,
	title = {Performance and energy modeling for live migration of virtual machines},
	volume = {16},
	issn = {1386-7857, 1573-7543},
	url = {http://link.springer.com/10.1007/s10586-011-0194-3},
	doi = {10.1007/s10586-011-0194-3},
	language = {en},
	number = {2},
	urldate = {2017-06-14},
	journal = {Cluster Computing},
	author = {Liu, Haikun and Jin, Hai and Xu, Cheng-Zhong and Liao, Xiaofei},
	month = jun,
	year = {2013},
	pages = {249--264},
	file = {Liu et al. - 2013 - Performance and energy modeling for live migration.pdf:/home/dani/Insync/Zotero/storage/972IRNNC/Liu et al. - 2013 - Performance and energy modeling for live migration.pdf:application/pdf}
}

@inproceedings{huang-power:2011,
	title = {Power {Consumption} of {Virtual} {Machine} {Live} {Migration} in {Clouds}},
	isbn = {978-1-61284-312-4},
	url = {http://ieeexplore.ieee.org/document/5931175/},
	doi = {10.1109/CMC.2011.62},
	abstract = {Virtualization Technology has been employed increasingly widely in modern data centers in order to improve its energy efficiency. In particular, the capability of virtual machine(VM) migration brings multiple benefits for such as resources(CPU, memory, et al.) distribution, energy aware consolidation. However, the migration of virtual machines itself brings extra power consumption. For this reason, a better understanding of its effect on system power consumption is highly desirable. In this paper, we present a power consumption evaluation on the effects of live migration of VMs. Results show that the power overhead of migration is much less in the scenario of employing the strategy of consolidation than the regular deployment without using consolidation. Our results are based on the typical physical server, the power of which is linear model of CPU utilization percentage.},
	booktitle = {2011 {Third} {International} {Conference} on {Communications} and {Mobile} {Computing}},
	publisher = {IEEE},
	author = {Huang, Q. and Gao, F. and Wang, R. and Qi, Z.},
	month = apr,
	year = {2011},
	keywords = {cloud computing, Clouds, Computational modeling, computer centres, Computers, CPU utilization percentage, Data center, Data centers, energy aware consolidation, live migration, physical server, power aware computing, power consumption, Power demand, quality of service, resource allocation, resources distribution, Servers, USA Councils, virtualization technology, virtual machine live migration, virtual machines, Virtual machining},
	pages = {122--125},
	file = {Huang et al. - 2011 - Power Consumption of Virtual Machine Live Migratio.pdf:/home/dani/Insync/Zotero/storage/7TJCXWZK/Huang et al. - 2011 - Power Consumption of Virtual Machine Live Migratio.pdf:application/pdf;IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/79PTNVFS/5931175.html:text/html}
}

@inproceedings{deshpande-inter-rack:2012,
	address = {New York, NY, USA},
	series = {{VTDC} '12},
	title = {Inter-rack {Live} {Migration} of {Multiple} {Virtual} {Machines}},
	url = {http://dl.acm.org/citation.cfm?id=2287062},
	doi = {10.1145/2287056.2287062},
	abstract = {Within datacenters, often multiple virtual machines (VMs) need to be live migrated simultaneously for various reasons such as maintenance, power savings, and load balancing. Such mass simultaneous live migration of multiple VMs can trigger large data transfers across the core network links and switches, and negatively affect the cluster-wide performance of network-bound applications. In this paper, we present a distributed system for inter-rack live migration (IRLM), i.e., parallel live migration of multiple VMs across racks. The key performance objective of IRLM is to reduce the traffic load on the core network links during mass VM migration through distributed deduplication of VMs' memory images. We present an initial prototype of IRLM that migrates multiple QEMU/KVM VMs within a Gigabit Ethernet cluster with 10GigE core links. We also present preliminary evaluation on a small testbed having 6 hosts per rack and 4 VMs per host. Our evaluations show that, compared to the default live migration technique in QEMU/KVM, IRLM reduces the network traffic on core links by up to 44\% and the total migration time by up to 26\%. We also demonstrate that network-bound applications experience a smaller degradation during migration using IRLM.},
	urldate = {2017-06-14},
	booktitle = {Proceedings of the 6th international workshop on {Virtualization} {Technologies} in {Distributed} {Computing} {Date}},
	publisher = {ACM},
	author = {Deshpande, Umesh and Kulkarni, Unmesh and Gopalan, Kartik},
	year = {2012},
	keywords = {live migration, Operating systems, virtual machines},
	pages = {19--26},
	file = {Deshpande et al. - 2012 - Inter-rack Live Migration of Multiple Virtual Mach.pdf:/home/dani/Insync/Zotero/storage/M3ESW7GZ/Deshpande et al. - 2012 - Inter-rack Live Migration of Multiple Virtual Mach.pdf:application/pdf}
}

@inproceedings{chen-network-aware:2013,
	title = {Network-aware coordination of virtual machine migrations in enterprise data centers and clouds},
	abstract = {Virtual machine(VM) migration usually requires a considerable amount of system resources such as the network bandwidth. In the case of multiple simultaneous migrations, such resource demands will increase dramatically and are difficult to be satisfied immediately. This paper proposes a scheduling method for multiple VM migrations to guarantee the fast completion of those tasks and hence the reduced impacts on system performance. We discover the best bandwidth sharing policy for each network link, and further propose a bin-packing algorithm to organize bandwidth resources from all the network links. As a result, the migration tasks can fully utilize available resources in the whole network to achieve the fast completion.},
	booktitle = {2013 {IFIP}/{IEEE} {International} {Symposium} on {Integrated} {Network} {Management} ({IM} 2013)},
	author = {Chen, H. and Kang, H. and Jiang, G. and Zhang, Y.},
	month = may,
	year = {2013},
	keywords = {Approximation algorithms, Bandwidth, bandwidth sharing policy, bin packing, bin-packing algorithm, cloud computing, Clouds, computer centres, enterprise data centers, Mathematical model, multiple VM migrations, network-aware coordination, network bandwidth, network links, resource demands, Schedules, Scheduling, scheduling method, Simulation, Switches, Vectors, virtual machine migrations, virtual machines, Virtual machining, VM migration},
	pages = {888--891},
	file = {IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/8C88KEKH/6573104.html:text/html;IEEE Xplore Full Text PDF:/home/dani/Insync/Zotero/storage/T8DW8733/Chen et al. - 2013 - Network-aware coordination of virtual machine migr.pdf:application/pdf}
}

@article{abdelsamea-virtual:2017,
	title = {Virtual machine consolidation enhancement using hybrid regression algorithms},
	issn = {1110-8665},
	url = {http://www.sciencedirect.com/science/article/pii/S1110866516300925},
	doi = {10.1016/j.eij.2016.12.002},
	abstract = {Cloud computing data centers are growing rapidly in both number and capacity to meet the increasing demands for highly-responsive computing and massive storage. Such data centers consume enormous amounts of electrical energy resulting in high operating costs and carbon dioxide emissions. The reason for this extremely high energy consumption is not just the quantity of computing resources and the power inefficiency of hardware, but rather lies in the inefficient usage of these resources. VM consolidation involves live migration of VMs hence the capability of transferring a VM between physical servers with a close to zero down time. It is an effective way to improve the utilization of resources and increase energy efficiency in cloud data centers. VM consolidation consists of host overload/underload detection, VM selection and VM placement. Most of the current VM consolidation approaches apply either heuristic-based techniques, such as static utilization thresholds, decision-making based on statistical analysis of historical data; or simply periodic adaptation of the VM allocation. Most of those algorithms rely on CPU utilization only for host overload detection. In this paper we propose using hybrid factors to enhance VM consolidation. Specifically we developed a multiple regression algorithm that uses CPU utilization, memory utilization and bandwidth utilization for host overload detection. The proposed algorithm, Multiple Regression Host Overload Detection (MRHOD), significantly reduces energy consumption while ensuring a high level of adherence to Service Level Agreements (SLA) since it gives a real indication of host utilization based on three parameters (CPU, Memory, Bandwidth) utilizations instead of one parameter only (CPU utilization). Through simulations we show that our approach reduces power consumption by 6 times compared to single factor algorithms using random workload. Also using PlanetLab workload traces we show that MRHOD improves the ESV metric by about 24\% better than other single factor regression algorithms (LR and LRR). Also we developed Hybrid Local Regression Host Overload Detection algorithm (HLRHOD) that is based on local regression using hybrid factors. It outperforms the single factor algorithms.},
	month = jan,
	year = {2017},
	journal = {Egyptian Informatics Journal},
	author = {Abdelsamea, Amany and El-Moursy, Ali A. and Hemayed, Elsayed E. and Eldeeb, Hesham},
	keywords = {Host overload detection, Multiple factors, Multiple regression, Single factors, VM consolidation}
}

@book{schlossnagle-scalable:2006,
	title = {Scalable {Internet} {Architectures}},
	isbn = {978-0-672-33285-2},
	abstract = {As a developer, you are aware of the increasing concern amongst developers and site architects that websites be able to handle the vast number of visitors that flood the Internet on a daily basis. Scalable Internet Architectures addresses these concerns by teaching you both good and bad design methodologies for building new sites and how to scale existing websites to robust, high-availability websites. Primarily example-based, the book discusses major topics in web architectural design, presenting existing solutions and how they work. Technology budget tight? This book will work for you, too, as it introduces new and innovative concepts to solving traditionally expensive problems without a large technology budget. Using open source and proprietary examples, you will be engaged in best practice design methodologies for building new sites, as well as appropriately scaling both growing and shrinking sites. Website development help has arrived in the form of Scalable Internet Architectures.},
	language = {en},
	publisher = {Pearson Education},
	author = {Schlossnagle, Theo},
	month = jul,
	year = {2006}
}

@techreport{itu-1563:2009,
	type = {Pattern},
	title = {Y.1563: {Ethernet} frame transfer and availability performance},
	url = {http://www.itu.int/rec/T-REC-Y.1563-200901-I/en},
	number = {Y.1563},
	urldate = {2017-06-13},
	institution = {International Telecommunication Union},
	author = {{Norma~ITU-T~Y.1563}},
	year = {2009},
	pages = {48},
	file = {ITU-T Y.1563 - Y.1563  Ethernet frame transfer and availability .pdf:/home/dani/Insync/Zotero/storage/VJFCAD7S/ITU-T Y.1563 - Y.1563  Ethernet frame transfer and availability .pdf:application/pdf;Y.1563 \: Ethernet frame transfer and availability performance:/home/dani/Insync/Zotero/storage/4ZG3MWFQ/en.html:text/html}
}

@book{daimi-sam:2016,
	address = {Erscheinungsort nicht ermittelbar},
	title = {{SAM} 2016: proceedings of the 2016 {International} {Conference} on {Security} \& {Management}: {WORLDCOMP} '16, {July} 25-28, 2016, {Las} {Vegas}, {Nevada}, {USA}},
	isbn = {978-1-60132-445-0},
	shorttitle = {{SAM} 2016},
	language = {eng},
	publisher = {CSREA Press},
	author = {Daimi, Kevin and Arabnia, Hamid R. and Margaria-Steffen, Tiziana and Solo, Ashu M. G.},
	editor = {{International Conference on Security and Management}},
	year = {2016},
	keywords = {Computersicherheit, Kongress},
	file = {SAM9732.pdf:/home/dani/Insync/Zotero/storage/XKJ5U82X/SAM9732.pdf:application/pdf}
}

@phdthesis{dias-posicionamento:2013,
	address = {Rio de Janeiro},
	title = {Posicionamento online baseado no tr\'afego de m\'aquinas virtuais em redes de data center},
	url = {http://pee.ufrj.br/teses/textocompleto/2013032201.pdf},
	urldate = {2017-05-25},
	school = {Universidade Federal do Rio de Janeiro},
	author = {Dias, Daniel de Souza},
	year = {2013},
	file = {2013032201.pdf:/home/dani/Insync/Zotero/storage/PHHSZJV8/2013032201.pdf:application/pdf}
}

@inproceedings{guyon-energy-efficient:2015,
	title = {Energy-{Efficient} {User}-{Oriented} {Cloud} {Elasticity} for {Data}-{Driven} {Applications}},
	isbn = {978-1-5090-0214-6},
	url = {http://ieeexplore.ieee.org/document/7396529/},
	doi = {10.1109/DSDIS.2015.57},
	urldate = {2017-06-11},
	publisher = {IEEE},
	author = {Guyon, David and Orgerie, Anne-Cecile and Morin, Christine},
	month = dec,
	year = {2015},
	pages = {376--383},
	file = {07396529.pdf:/home/dani/Insync/Zotero/storage/KMB2EGCV/07396529.pdf:application/pdf}
}

@inproceedings{sedaghat-unifying:2011,
	title = {Unifying {Cloud} {Management}: {Towards} {Overall} {Governance} of {Business} {Level} {Objectives}},
	shorttitle = {Unifying {Cloud} {Management}},
	doi = {10.1109/CCGrid.2011.65},
	abstract = {We address the challenge of providing unified cloud resource management towards an overall business level objective, given the multitude of managerial tasks to be performed and the complexity of any architecture to support them. Resource level management tasks include elasticity control, virtual machine and data placement, autonomous fault management, etc, which are intrinsically difficult problems since services normally have unknown lifetime and capacity demands that varies largely over time. To unify the management of these problems, (for optimization with respect to some higher level business level objective, like optimizing revenue while breaking no more than a certain percentage of service level agreements)becomes even more challenging as the resource level managerial challenges are far from independent. After providing the general problem formulation, we review recent approaches taken by the research community, including mainly general autonomic computing technology for large-scale environments and resource level management tools equipped with some business oriented or otherwise qualitative features. We propose and illustrate a policy-driven approach where a high-level management system monitors overall system and services behavior and adjusts lower level policies (e.g., thresholds for admission control, elasticity control, server consolidation level, etc) for optimization towards the measurable business level objectives.},
	booktitle = {2011 11th {IEEE}/{ACM} {International} {Symposium} on {Cluster}, {Cloud} and {Grid} {Computing}},
	author = {Sedaghat, M. and Hern´ndez, F. and Elmroth, E.},
	month = may,
	year = {2011},
	keywords = {Adaptation models, architecture complexity, autonomic computing, autonomic computing technology, autonomous fault management, business data processing, business level objective, cloud computing, Cloud governance, data placement, elasticity, elasticity control, Engines, fault tolerant computing, high-level management system, large-scale environment, managerial tasks, Monitoring, Optimisation, Optimization, Policy-driven Management, qualitative feature, research community, resource allocation, resource level management tasks, resource level management tools, Resource management, services behavior, unified cloud resource management, virtual machine, virtual machines},
	pages = {591--597},
	file = {IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/WTDTJBDJ/5948652.html:text/html;IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/KPID8G38/5948652.html:text/html;IEEE Xplore Full Text PDF:/home/dani/Insync/Zotero/storage/QF943TPJ/Sedaghat et al. - 2011 - Unifying Cloud Management Towards Overall Governa.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/dani/Insync/Zotero/storage/FSIVKTIJ/Sedaghat et al. - 2011 - Unifying Cloud Management Towards Overall Governa.pdf:application/pdf}
}

@inproceedings{breitgand-sla-aware:2011,
	title = {{SLA}-aware placement of multi-virtual machine elastic services in compute clouds},
	isbn = {978-1-4244-9219-0},
	url = {http://ieeexplore.ieee.org/document/5990687/},
	doi = {10.1109/INM.2011.5990687},
	urldate = {2017-06-11},
	publisher = {IEEE},
	author = {Breitgand, David and Epstein, Amir},
	month = may,
	year = {2011},
	pages = {161--168},
	file = {SLA-aware-placement-of-multi-virtual-machine-elastic-services-in-compute-clouds.pdf:/home/dani/Insync/Zotero/storage/7FWI76ZC/SLA-aware-placement-of-multi-virtual-machine-elastic-services-in-compute-clouds.pdf:application/pdf}
}

@article{nanduri-energy:2014,
	title = {Energy and {SLA} aware {VM} {Scheduling}},
	url = {http://arxiv.org/abs/1411.6114},
	abstract = {With the advancement of Cloud Computing over the past few years, there has been a massive shift from traditional data centers to cloud enabled data centers. The enterprises with cloud data centers are focusing their attention on energy savings through effective utilization of resources. In this work, we propose algorithms which try to minimize the energy consumption in the data center duly maintaining the SLA guarantees. The algorithms try to utilize least number of physical machines in the data center by dynamically rebalancing the physical machines based on their resource utilization. The algorithms also perform an optimal consolidation of virtual machines on a physical machine, minimizing SLA violations. In extensive simulation, our algorithms achieve savings of about 21\% in terms of energy consumption and in terms of maintaining the SLAs, it performs 60\% better than Single Threshold algorithm.},
	urldate = {2017-06-12},
	journal = {arXiv:1411.6114 [cs]},
	author = {Nanduri, Radheshyam and Kakadia, Dharmesh and Varma, Vasudeva},
	month = nov,
	year = {2014},
	note = {arXiv: 1411.6114},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {arXiv\:1411.6114 PDF:/home/dani/Insync/Zotero/storage/JBSN556P/Nanduri et al. - 2014 - Energy and SLA aware VM Scheduling.pdf:application/pdf;arXiv.org Snapshot:/home/dani/Insync/Zotero/storage/U3EN87X3/1411.html:text/html}
}

@phdthesis{padoin-energy-aware:2016,
	address = {Porto Alegre RS},
	title = {Energy-aware load balancing approaches to improve energy efficiency on {HPC} systems},
	url = {http://www.lume.ufrgs.br/handle/10183/140401},
	urldate = {2017-06-13},
	school = {UFRGS},
	author = {Padoin, Edson Luiz},
	year = {2016},
	file = {000991179.pdf:/home/dani/Insync/Zotero/storage/M4WQEUSB/000991179.pdf:application/pdf}
}

@article{righi-elasticidade:2013,
	title = {Elasticidade em cloud computing: conceito, estado da arte e novos desafios},
	volume = {5},
	issn = {2176-6649},
	shorttitle = {Elasticidade em cloud computing},
	url = {http://www.upf.br/seer/index.php/rbca/article/view/3084},
	doi = {10.5335/rbca.2013.3084},
	number = {2},
	urldate = {2017-06-13},
	journal = {Revista Brasileira de Computa??o Aplicada},
	author = {Righi, Rodrigo Da Rosa},
	month = nov,
	year = {2013},
	file = {2370.pdf:/home/dani/Insync/Zotero/storage/Z794ECHV/2370.pdf:application/pdf}
}

@article{rohani-calculating:2014,
	title = {Calculating {Total} {System} {Availability}},
	author = {Rohani, Hoda and Roosta, Azad Kamali},
	journal = {Delaat Report, available in http://www.delaat.net/rp/2013-2014/p17/report.pdf},
	year = {2014}
}

@book{parziale-end-end:2014,
	title = {End-to-{End} {High} {Availability} {Solution} for {System} z from a {Linux} {Perspective}},
	isbn = {978-0-7384-4006-4},
	abstract = {As Linux on System z becomes more prevalent and mainstream in the industry, the need for it to deliver higher levels of availability is increasing. This IBM Redbooks publication starts with an explanation of high availability (HA) fundamentals such as HA concepts and terminology. It continues with a discussion of why a business needs to consider an HA solution and then explains how to determine your business single points of failure. We outline the components of a high availability solution and describe these components. Then we provide some architectural scenarios and demonstrate how to plan and decide an implementation of an end-to-end HA solution, from Linux on System z database scenarios to z/OS, and include storage, network, z/VM, Linux, and middleware. This implementation includes the IBM Tivoli System Automation for Multiplatforms (TSA MP), which monitors and automates applications distributed across Linux, AIX®, and z/OS® operating systems, as well as a GDPS based solution. It includes the planning for an end-to-end scenario, considering Linux on System z, z/VM, and z/OS operating environments, and the middleware used. The TSA MP implements HA for infrastructure, network, operating systems, and applications across multiple platforms and is compared to a Linux HA implementation based on open source Linux-HA, which is Linux only.},
	language = {en},
	publisher = {IBM Redbooks},
	author = {Parziale, Lydia and Lasmayous, Guillaume and Pattabhiraman, Manoj S. and Reed, Karen and Zhang, Jing Xin and Redbooks, I. B. M.},
	month = oct,
	year = {2014},
	keywords = {Computers / Hardware / Mainframes \& Minicomputers},
	file = {sg248233.pdf:/home/dani/Insync/Zotero/storage/X3VKEBJM/sg248233.pdf:application/pdf}
}

@techreport{mell-nist:2011,
	address = {Gaithersburg, MD, United States},
	title = {{SP} 800-145. {The} {NIST} {Definition} of {Cloud} {Computing}},
	abstract = {Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. This cloud model is composed of five essential characteristics, three service models, and four deployment models.},
	institution = {National Institute of Standards \& Technology},
	author = {Mell, Peter M. and Grance, Timothy},
	year = {2011}
}

@inproceedings{al-fares-scalable:2008,
	address = {New York, NY, USA},
	series = {{SIGCOMM} '08},
	title = {A {Scalable}, {Commodity} {Data} {Center} {Network} {Architecture}},
	isbn = {978-1-60558-175-0},
	url = {http://doi.acm.org/10.1145/1402958.1402967},
	doi = {10.1145/1402958.1402967},
	abstract = {Today's data centers may contain tens of thousands of computers with significant aggregate bandwidth requirements. The network architecture typically consists of a tree of routing and switching elements with progressively more specialized and expensive equipment moving up the network hierarchy. Unfortunately, even when deploying the highest-end IP switches/routers, resulting topologies may only support 50\% of the aggregate bandwidth available at the edge of the network, while still incurring tremendous cost. Non-uniform bandwidth among data center nodes complicates application design and limits overall system performance. In this paper, we show how to leverage largely commodity Ethernet switches to support the full aggregate bandwidth of clusters consisting of tens of thousands of elements. Similar to how clusters of commodity computers have largely replaced more specialized SMPs and MPPs, we argue that appropriately architected and interconnected commodity switches may deliver more performance at less cost than available from today's higher-end solutions. Our approach requires no modifications to the end host network interface, operating system, or applications; critically, it is fully backward compatible with Ethernet, IP, and TCP.},
	urldate = {2017-06-07},
	booktitle = {Proceedings of the {ACM} {SIGCOMM} 2008 {Conference} on {Data} {Communication}},
	publisher = {ACM},
	author = {Al-Fares, Mohammad and Loukissas, Alexander and Vahdat, Amin},
	year = {2008},
	keywords = {data center topology, equal-cost routing},
	pages = {63--74}
}

@article{medina-survey:2014,
	author   = {Medina, Violeta and Garc\'ia, Juan Manuel},
	title    = {A {Survey} of {Migration} {Mechanisms} of {Virtual} {Machines}},
	journal  = {ACM Comput. Surv.},
	year     = {2014},
	volume   = {46},
	number   = {3},
	pages    = {30:1-30:33},
	month    = jan,
	issn     = {0360-0300},
	abstract = {In the virtualization area, replication has been considered as a mechanism to provide high availability. A high-availability system should be active most of the time, and this is the reason that its design should consider almost zero downtime and a minimal human intervention if a recovery process is demanded. Several migration and replication mechanisms have been developed to provide high availability inside virtualized environments. In this article, a survey of migration mechanisms is reported. These approaches are classified in three main classes: process migration, memory migration, and suspend/resume migration.},
	doi      = {10.1145/2492705},
	file     = {Medina e Garc\'ia - 2014 - A Survey of Migration Mechanisms of Virtual Machin.pdf:/home/dani/Insync/Zotero/storage/Q4WRVMJ2/Medina e Garc\'ia - 2014 - A Survey of Migration Mechanisms of Virtual Machin.pdf:application/pdf},
	keywords = {High Availability, migration, replication, Virtualization, virtual machine},
	url      = {http://doi.acm.org/10.1145/2492705},
	urldate  = {2017-03-22}
}

@inproceedings{petersen-systematic:2008,
	title = {Systematic {Mapping} {Studies} in {Software} {Engineering}.},
	volume = {8},
	url = {http://robertfeldt.net/publications/petersen-ease08-sysmap-studies-in-se.pdf},
	urldate = {2017-06-05},
	booktitle = {{EASE}},
	author = {Petersen, Kai and Feldt, Robert and Mujtaba, Shahid and Mattsson, Michael},
	year = {2008},
	pages = {68--77},
	file = {petersen-ease08-sysmap-studies-in-se.pdf:/home/dani/Insync/Zotero/storage/RJ5FU88Z/petersen-ease08-sysmap-studies-in-se.pdf:application/pdf}
}
{conforto-roteiro:2011,
	title = {Roteiro para revis\~ao bibliogr\'afica sistem\'atica: aplica\{c}c\~ao no desenvolvimento de produtos e gerenciamento de projetos},
	shorttitle = {Roteiro para revis\~ao bibliogr\'afica sistem\'atica},
	url = {http://xa.yimg.com/kq/groups/18922045/1357081138/name/Conforto+roteiro+para+revis%C3%A3o+bibliogr%C3%A1fica+sistem%C3%A1tica.pdf},
	urldate = {2017-06-05},
	booktitle = {8º {Congresso} {Brasileiro} de {Gest\~ao} de {Desenvolvimento} de {Produto}-{CBGDP}},
	author = {Conforto, Edivandro Carlos and Amaral, Daniel Capaldo and Silva, S\'ergio Lu\'is},
	year = {2011},
	file = {Roteiro para revis\~ao bibliogr\'afica sistem\'atica.pdf:/home/dani/Insync/Zotero/storage/XP3I9NEC/Roteiro para revis\~ao bibliogr\'afica sistem\'atica.pdf:application/pdf}
}

@book{kitchenham-procedures:2004,
	title = {{Kitchenham}, 2004 {Procedures} for {Performing} {Systematic} {Reviews}},
	author = {Kitchenham, Barbara},
	year = {2004},
	issn = {ISSN:1353-7776},
	publisher = {Keele University Technical Report TR/SE-0401}
}

@inproceedings{petrovic-implementing:2012,
	address = {Washington, DC, USA},
	series = {{AINA} '12},
	title = {Implementing {Virtual} {Machine} {Replication}: {A} {Case} {Study} {Using} {Xen} and {KVM}},
	isbn = {978-0-7695-4651-3},
	shorttitle = {Implementing {Virtual} {Machine} {Replication}},
	url = {http://dx.doi.org/10.1109/AINA.2012.50},
	doi = {10.1109/AINA.2012.50},
	abstract = {Virtual machine (VM) replication has been recognized as an inexpensive way of providing high availability on commodity hardware. Unfortunately, its impact on system performance is far from negligible and strategies have been proposed to mitigate this problem. In this paper we take a look at VM replication from a different perspective: the choice of a hyper visor. Namely, the differences between hyper visors in terms of architecture and performance are well known and studied in the literature, but no analysis has been performed so far in the context of replication. Taking open-source hyper visors Xen and KVM as examples, we show what hyper visor services are necessary to implement a primary-backup replication scheme and how hyper visor design affects the development steps and the performance. Interestingly, our user space implementation on top of KVM achieves roughly the same performance as an already existing, more mature Xen implementation, which leads us to the conclusion that the inherent cost of the replication scheme dominates the differences between the chosen hyper visors.},
	urldate = {2017-03:22},
	booktitle = {Proceedings of the 2012 {IEEE} 26th {International} {Conference} on {Advanced} {Information} {Networking} and {Applications}},
	publisher = {IEEE Computer Society},
	author = {Petrovic, Darko and Schiper, Andre},
	year = {2012},
	keywords = {fault-tolerance, High Availability, replication, Virtualization},
	pages = {73--80}
}

@inproceedings{sun-research:2014,
	title = {Research on availability of virtual machine hot standby based on {Xen}},
	doi = {10.1049/cp.2014.1584},
	abstract = {As the important measure to ensure the high availability of campus virtual data center, virtual machine hot standby has got comprehensive attention. For low availability caused by intrinsic memory copying technology, this paper proposes pre-transfer based on memory selection algorithm and stoptransfer based on memory compression algorithm. A part of memory pages are pre-transferred during the primary virtual machine running, to reduce the number of transferred memory pages in downtime. Meanwhile, on the basis of program locality, predict the dirty pages rate and pre-transfer dirty pages whose rate are low to refrain from duplicate transmission at the stage of stop-transfer. To stoptransfer, improved memory compression algorithm is used to compress the memory pages on the purpose of enhancing the efficiency of stop transmission. The simulation result shows that the downtime of improved Remus system decreases obviously compared with the original Remus in Xen, especially in the situation of high dirty pages rate and long time interval.},
	booktitle = {International {Conference} on {Software} {Intelligence} {Technologies} and {Applications} {International} {Conference} on {Frontiers} of {Internet} of {Things} 2014},
	author = {Sun, Mingsong and Chen, Fang},
	year = {2014},
	keywords = {computer centres, duplicate transmission, intrinsic memory copying technology, memory compression algorithm, memory page, memory selection algorithm, pre-transfer, pretransfer dirty page, program locality, Remus system, stop-transfer, storage management, virtual data center, virtual machine hot standby, virtual machines, Xen},
	pages = {330--335},
	file = {IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/5VD8766S/7284268.html:text/html;Sun-Chen,2014-Research on availability of virtual machine hot standby based on Xen.pdf:/home/dani/Insync/Zotero/storage/892AJQ4B/Sun-Chen,2014-Research on availability of virtual machine hot standby based on Xen.pdf:application/pdf}
}

@inproceedings{yang-improvement:2011,
	title = {On {Improvement} of {Cloud} {Virtual} {Machine} {Availability} with {Virtualization} {Fault} {Tolerance} {Mechanism}},
	doi = {10.1109/CloudCom.2011.26},
	abstract = {Virtualization is a common strategy to improve the existing computing resources, particularly in cloud computing field. Hadoop, one of Apache projects, is designed to scale up from single servers to thousands of machines, and each offer local computation and storage. However, how to guarantee stability and reliability have become great study topics. In this article, we use current open-source based on software and platform to reach our goal. For instance, Xen-Hyper visor virtualization technology, Open Nebula virtual machines management tool, and so on. After extending component capabilities, we developed a mechanism to support our idea and reached Hadoop High Availability which called Virtualization Fault Tolerance (VFT). We consider a practical problem that occurs frequently in our system, and the results in this paper also confirm the downtime time can be shortened if failure occurred. In this case, it is not only for the Hadoop applications, but also extended to more areas of cluster-based systems.},
	booktitle = {2011 {IEEE} {Third} {International} {Conference} on {Cloud} {Computing} {Technology} and {Science}},
	author = {Yang, C. T. and Chou, W. L. and Hsu, C. H. and Cuzzocrea, A.},
	month = nov,
	year = {2011},
	keywords = {Apache projects, availability, cloud computing, cloud computing field, cloud virtual machine availability improvement, cluster-based systems, computing resource improvement, fault tolerance, Fault tolerant systems, Hadoop high availability, Heart beat, High Availability, IP networks, Open Nebula virtual machines management tool, reliability guarantee, Servers, software fault tolerance, stability guarantee, virtualisation, Virtualization, virtualization fault tolerance mechanism, Virtualization Fault Tolerance (VFT), virtual machines, Virtual machining, Xen-Hyper visor virtualization technology},
	pages = {122--129},
	file = {IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/3KJXW49P/6133135.html:text/html;Yang et al,2011-On Improvement of Cloud Virtual Machine Availability with Virtualization Fault.pdf:/home/dani/Insync/Zotero/storage/CIAU537I/Yang et al,2011-On Improvement of Cloud Virtual Machine Availability with Virtualization Fault.pdf:application/pdf}
}

@inproceedings{wang-availability-aware:2012,
	title = {An {Availability}-{Aware} {Virtual} {Machine} {Placement} {Approach} for {Dynamic} {Scaling} of {Cloud} {Applications}},
	doi = {10.1109/UIC-ATC.2012.31},
	abstract = {Cloud computing promises customers the on-demand ability to dynamically provision virtualization resources in face of workload variations. Most existing scaling approaches addressed this problem by allocating application to a certain amount of cloud resources. However, the problem of the availability of application influenced by VM-based physical locations during resource scaling process is a serious challenge due to dynamic complex workload and has not been widely discussed yet. In this paper, we present a novel availability-based computing model to describe availability attribute of one application in the hierarchical structured cloud. Moreover, we propose an availability-aware policy by performing both vertical and horizontal scaling to explore how and where to allocate computing resource. Simulation results indicate that our model captured the availability of cloud applications properly and proposed scaling approach achieves the objectives of meeting availability demands and minimizing the total communication cost.},
	booktitle = {2012 9th {International} {Conference} on {Ubiquitous} {Intelligence} and {Computing} and 9th {International} {Conference} on {Autonomic} and {Trusted} {Computing}},
	author = {Wang, W. and Chen, H. and Chen, X.},
	month = sep,
	year = {2012},
	keywords = {availability, availability-aware virtual machine placement approach, cloud computing, Cloud-computing, cloud resources, Computational modeling, computing resource allocation, dynamically provision virtualization resources, dynamic complex workload, dynamic scaling, Dynamic scheduling, hierarchical structured cloud, horizontal scaling, on-demand ability, Resizing, resource allocation, Resource management, Scaling up and down, Servers, Software, vertical scaling, virtual machines, Virtual machining, VM-based physical locations, VMs placement},
	pages = {509--516},
	file = {IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/B44XF5XM/6332041.html:text/html;Wang et al,2012-An Availability-Aware Virtual Machine Placement Approach for Dynamic Scaling of.pdf:/home/dani/Insync/Zotero/storage/Q8A4DVVR/Wang et al,2012-An Availability-Aware Virtual Machine Placement Approach for Dynamic Scaling of.pdf:application/pdf}
}

@inproceedings{he-reverse:2016,
	title = {Reverse {Replication} of {Virtual} {Machines} ({rRVM}) for {Low} {Latency} and {High} {Availability} {Services}},
	abstract = {Virtualization supplies a straightforward approach to high availability through iterative replications of virtual machine (VM) checkpoints that encapsulate the protected services. Unfortunately, traditional VM replication solutions suffer from deficiencies in either response latency or state recovery consistency, which constrains the adoption of VM replication in production. In this paper, we extend the function of the secondary host to be the primary recipient of network requests so that the state of the primary VM (PVM) is retained by the secondary host in the form of network packets. In doing this, we redesign the typical consistency model and network architecture for virtual machine replication. Specifically, the secondary host is set for network redirection and packets recording. Should the primary host fail, the recorded packets are used to recreate the state on the secondary host. Experiments in this research demonstrate simultaneously strong recovery consistency and low response latency in our real-time fault tolerance system. We name the system reverse replication of virtual machines (rRVM).},
	booktitle = {2016 {IEEE}/{ACM} 9th {International} {Conference} on {Utility} and {Cloud} {Computing} ({UCC})},
	author = {He, M. and Pang, S. and Lavrov, D. and Lu, D. and Zhang, Y. and Sarrafzadeh, A.},
	year = {2016},
	keywords = {asynchronous, Computer crashes, HA, Hardware, High Availability, latency, Local area networks, real-time systems, recovery consistency, Servers, Virtualization, virtual machine, Virtual machining, VM replications},
	pages = {118--127},
	file = {He et al,2016-Reverse Replication of Virtual Machines (rRVM) for Low Latency and High.pdf:/home/dani/Insync/Zotero/storage/U2SXJUX6/He et al,2016-Reverse Replication of Virtual Machines (rRVM) for Low Latency and High.pdf:application/pdf;IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/BE85N88X/7881623.html:text/html}
}

@article{nguyen-environment-aware:2015,
	title = {Environment-{Aware} {Virtual} {Slice} {Provisioning} in {Green} {Cloud} {Environment}},
	volume = {8},
	issn = {1939-1374},
	doi = {10.1109/TSC.2014.2362544},
	abstract = {Environmental footprint resulting from datacenters activities can be reduced by both energy efficiency and renewable energy in a complementary fashion thanks to cloud computing paradigms. In a cloud hosting multi-tenant applications, virtual service providers can be provided with real-time recommendation techniques to allocate their virtual resources in edge, core, or access layers in an optimal way to minimize costs and footprint. Such a dynamic technique requires a flexible and optimized networking scheme to enable elastic virtual tenants spanning multiple physical nodes. In this paper, we investigate an environment-aware paradigm for virtual slices that allows improving energy efficiency and dealing with intermittent renewable power sources. A virtual slice consists of optimal flows assigned to virtual machines (VMs) in a virtual data center taking into account traffic requirements, VM locations, physical network capacity, and renewable energy availability. Considering various cloud consolidation schemes, we formulate and then propose an optimal solution for virtual slice assignment problem. Simulations on the GSN showed that the proposed model achieves better performance than the existing methods with respect to network footprint reductions.},
	number = {3},
	journal = {IEEE Transactions on Services Computing},
	author = {Nguyen, K. K. and Cheriet, M.},
	year = {2015},
	keywords = {Bandwidth, cloud computing, cost minimization, dynamic programming, dynamic technique, Energy-aware cloud, Energy efficiency, environmental footprint, environment-aware virtual slice provisioning, green cloud environment, Green computing, Green products, Logic gates, minimisation, multitenant application, multi-tenant cloud, multi-tenant cloud,, power aware computing, Power demand, recommendation technique, renewable energy, renewable energy sources, resource allocation, Servers, virtual data center, virtualisation, virtual machine, virtual machines, virtual network embedding, virtual resource allocation, virtual service provider, virtual slice allocation, VM},
	pages = {507--519},
	file = {IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/M5I687XP/6919310.html:text/html;Nguyen-Cheriet,2015-Environment-Aware Virtual Slice Provisioning in Green Cloud Environment.pdf:/home/dani/Insync/Zotero/storage/C5CDN3F7/Nguyen-Cheriet,2015-Environment-Aware Virtual Slice Provisioning in Green Cloud Environment.pdf:application/pdf}
}

@inproceedings{caglar-iplace::2014,
	title = {{iPlace}: {An} {Intelligent} and {Tunable} {Power}- and {Performance}-{Aware} {Virtual} {Machine} {Placement} {Technique} for {Cloud}-{Based} {Real}-{Time} {Applications}},
	shorttitle = {{iPlace}},
	doi = {10.1109/ISORC.2014.35},
	abstract = {Power and performance tradeoffs are critical and challenging issues faced by cloud service providers (CSPs) while managing their data centers. On the one hand, CSPs strive to reduce power consumption of their data centers to not only decrease their energy costs but to also reduce adverse impact on the environment. On the other hand, CSPs must deliver performance expected by the applications hosted in their cloud in accordance with predefined Service Level Agreements (SLAs). Not doing so will lead to loss of customers and thereby major revenue losses for the CSPs. Addressing these dual set of challenges is hard for the CSPs because power management and performance assurance are conflicting objectives, particularly in the context of multi-tenant cloud systems where multiple virtual machines (VMs) may be hosted on a single physical server. The problem becomes even harder when real-time applications are hosted in these VMs. To address these challenges and make appropriate tradeoffs, we present iPlace, which is an intelligent and tunable power- and performance-aware VM placement middleware. The placement strategy is based on a two-level artificial neural network which predicts (1) CPU usage at the first level, and (2) power consumption and performance of a host machine at the second level that uses the predicted CPU usage. The efficacy of iPlace is evaluated in the context of a VM consolidation algorithm that is applied to running virtual machines and host machines in a private cloud.},
	booktitle = {2014 {IEEE} 17th {International} {Symposium} on {Object}/{Component}/{Service}-{Oriented} {Real}-{Time} {Distributed} {Computing}},
	author = {Caglar, F. and Shekhar, S. and Gokhale, A.},
	month = jun,
	year = {2014},
	keywords = {Artificial neural networks, availability, cloud-based real-time applications, cloud computing, cloud service providers, contracts, CSP, deployment algorithm, Energy consumption, host machines, iPlace, multitenant cloud systems, performance assurance, performance-aware virtual machine placement technique, performance tradeoffs, power and performance tradeoffs, power aware computing, power consumption, Power demand, Power management, private cloud, real-time systems, Servers, service level agreements, SLA, tunable power-aware virtual machine placement technique, virtual machine placement, virtual machines, Virtual machining, VM consolidation algorithm},
	pages = {48--55},
	file = {Caglar et al,2014-iPlace.pdf:/home/dani/Insync/Zotero/storage/PSBK77CX/Caglar et al,2014-iPlace.pdf:application/pdf;IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/CR4IAANJ/6899130.html:text/html}
}

@article{amoon-adaptive:2016,
	title = {Adaptive {Framework} for {Reliable} {Cloud} {Computing} {Environment}},
	volume = {4},
	issn = {2169-3536},
	url = {http://ieeexplore.ieee.org/document/7742909/},
	doi = {10.1109/ACCESS.2016.2623633},
	urldate = {2017-03:27},
	journal = {IEEE Access},
	author = {Amoon, Mohammed},
	year = {2016},
	pages = {9469--9478},
	file = {Amoon - 2016 - Adaptive Framework for Reliable Cloud Computing En.pdf:/home/dani/Insync/Zotero/storage/HXG964ZV/Amoon - 2016 - Adaptive Framework for Reliable Cloud Computing En.pdf:application/pdf}
}

@article{mondal-virtual:2016,
	title = {Virtual {Machine} {Replication} on {Achieving} {Energy}-{Efficiency} in a {Cloud}},
	volume = {5},
	issn = {2079-9292},
	url = {http://www.mdpi.com/2079-9292/5/3/37},
	doi = {10.3390/electronics5030037},
	language = {en},
	number = {3},
	urldate = {2017-03:27},
	journal = {Electronics},
	author = {Mondal, Subrota and Muppala, Jogesh and Machida, Fumio},
	month = jul,
	year = {2016},
	pages = {37},
	file = {Mondal et al. - 2016 - Virtual Machine Replication on Achieving Energy-Ef.pdf:/home/dani/Insync/Zotero/storage/9VHVPR3H/Mondal et al. - 2016 - Virtual Machine Replication on Achieving Energy-Ef.pdf:application/pdf}
}

@article{zahedifard-dynamic:2017,
	author   = {Zahedi Fard, Seyed Yahya and Ahmadi, Mohamad Reza and Adabi, Sahar},
	title    = {A dynamic {VM} consolidation technique for {QoS} and energy consumption in cloud environment},
	journal  = {The Journal of Supercomputing},
	year     = {2017},
	pages    = {1-22},
	month    = mar,
	issn     = {0920-8542, 1573-0484},
	abstract = {Cloud-based data centers consume a significant amount of energy which is a costly procedure. Virtualization technology, which can be regarded as the first step in the cloud by offering benefits like the virtual machine and live migration, is trying to overcome this problem. Virtual machines host workload, and because of the variability of workload, virtual machines consolidation is an effective technique to minimize the total number of active servers and unnecessary migrations and consequently improves energy consumption. Effective virtual machine placement and migration techniques act as a key issue to optimize the consolidation process. In this paper, we present a novel virtual machine consolidation technique to achieve energy–QoS–temperature balance in the cloud data center. We simulated our proposed technique in CloudSim simulation. Results of evaluation certify that physical machine temperature, SLA, and migration technique together control the energy consumption and QoS in a cloud data center.},
	doi      = {10.1007/s11227-017:2016-8},
	file     = {Snapshot:/home/dani/Insync/Zotero/storage/RIB5UJZR/s11227-017:2016-8.html:text/html},
	language = {en},
	url      = {https://link.springer.com/article/10.1007/s11227-017:2016-8},
	urldate  = {2017-04:21}
}

@article{kansal-energy-aware:2016,
	title = {Energy-aware {Virtual} {Machine} {Migration} for {Cloud} {Computing} - {A} {Firefly} {Optimization} {Approach}},
	volume = {14},
	issn = {1570-7873, 1572-9184},
	url = {https://link.springer.com/article/10.1007/s10723-016-9364-0},
	doi = {10.1007/s10723-016-9364-0},
	abstract = {Energy efficiency has grown into a latest exploration area of virtualized cloud computing paradigm. The increase in the number and the size of the cloud data centers has propagated the need for energy efficiency. An extensively practiced technology in cloud computing is live virtual machine migration and is thus focused in this work to save energy. This paper proposes an energy-aware virtual machine migration technique for cloud computing, which is based on the Firefly algorithm. The proposed technique migrates the maximally loaded virtual machine to the least loaded active node while maintaining the performance and energy efficiency of the data centers. The efficacy of the proposed technique is exhibited by comparing it with other techniques using the CloudSim simulator. An enhancement in the average energy consumption of about 44.39 \% has been attained by reducing an average of 72.34 \% of migrations and saving 34.36 \% of hosts, thereby, making the data center more energy-aware.},
	language = {en},
	number = {2},
	urldate = {2017-04:21},
	journal = {Journal of Grid Computing},
	author = {Kansal, Nidhi Jain and Chana, Inderveer},
	month = jun,
	year = {2016},
	pages = {327--345},
	file = {Snapshot:/home/dani/Insync/Zotero/storage/NPVCGQF4/s10723-016-9364-0.html:text/html}
}

@article{silva-topology-aware:2016,
	title = {Topology-{Aware} {Virtual} {Machine} {Placement} in {Data} {Centers}},
	volume = {14},
	issn = {1570-7873, 1572-9184},
	url = {https://link.springer.com/article/10.1007/s10723-015-9343-x},
	doi = {10.1007/s10723-015-9343-x},
	abstract = {This paper presents the Topology-aware Virtual Machine Placement algorithm, which aims at placing groups of virtual machines in data centers. It was designed to occupy small areas of the data center network in order to consolidate the network flows produced by the virtual machines. Extensive simulation is used to show that the proposed algorithm prevents the formation of network bottlenecks, therefore accepting more requests of allocation of virtual machines. Moreover, these advantages are obtained without compromising energy efficiency. The energy consumption of servers and switches are taken into account, and these are switched off whenever idle.},
	language = {en},
	number = {1},
	urldate = {2017-04:21},
	journal = {Journal of Grid Computing},
	author = {Silva, Rodrigo A. C. da and Fonseca, Nelson L. S. da},
	month = mar,
	year = {2016},
	pages = {75--90},
	file = {art%3A10.1007%2Fs10723-015-9343-x.pdf:/home/dani/Insync/Zotero/storage/VRZKRQE9/art%3A10.1007%2Fs10723-015-9343-x.pdf:application/pdf;Snapshot:/home/dani/Insync/Zotero/storage/49F3V58A/s10723-015-9343-x.html:text/html}
}

@incollection{bala-virtual:2016,
	title = {Virtual {Machine} {Migration}: {A} {Green} {Computing} {Approach} in {Cloud} {Data} {Centers}},
	shorttitle = {Virtual {Machine} {Migration}},
	url = {https://link.springer.com/chapter/10.1007/978-981-10-0755:2-18},
	abstract = {A recent fast growing development and demand in high performance computing has brought IT technocrats on forefeet to devise energy aware mechanisms so that CO2 emission can be reduced to a great extent. The resources in cloud data centers are always over provisioned in order to meet the peak workload. These resources consume a huge amount of energy, if used in their full capacity. By dynamically adopting the green computing policies as per current workload, the energy consumption of cloud data center can be reduced. In the present study, VM migration process has been discussed and the simulation driven results for evaluation of the proposed heuristic on the basis of static upper and lower limits allowed for CPU utilization have been presented. The comparative analysis of resource utilization and power consumption of a data center, with and without migration policy, reveals that a significant amount of power consumption can be reduced by VM migration and utilization of resources can be optimized.},
	language = {en},
	urldate = {2017-04:21},
	booktitle = {Proceedings of the {International} {Congress} on {Information} and {Communication} {Technology}},
	publisher = {Springer, Singapore},
	author = {Bala, Minu and Devanand},
	year = {2016},
	note = {DOI: 10.1007/978-981-10-0755:2\-18},
	pages = {161--168},
	file = {Snapshot:/home/dani/Insync/Zotero/storage/5VTM3RMB/978-981-10-0755:2-18.html:text/html}
}

@inproceedings{ali-energy:2016,
	title = {An {Energy} {Efficient} {Algorithm} for {Virtual} {Machine} {Allocation} in {Cloud} {Datacenters}},
	url = {https://link.springer.com/chapter/10.1007/978-981-10:2209-8-6},
	doi = {10.1007/978-981-10:2209-8-6},
	abstract = {In cloud datacenters, virtual machine (VM) allocation in a power efficient way remains a critical research problem. There are a number of algorithms for allocating the workload among different machines. However, existing works do not consider more than one energy efficient host, thus they are not efficient for large scale cloud datacenters. In this paper, we propose a VM allocation algorithm to achieve higher energy efficiency in large scale cloud datacenters. Simulation result shows that, compared with BRS, RR and MPD algorithms, our algorithms can achieve 23 \%, 23 \% and 9 \% more power efficiency in large scale cloud environment.},
	language = {en},
	urldate = {2017-04:21},
	booktitle = {Advanced {Computer} {Architecture}},
	publisher = {Springer, Singapore},
	author = {Ali, Ahmad and Lu, Li and Zhu, Yanmin and Yu, Jiadi},
	month = aug,
	year = {2016},
	pages = {61--72},
	file = {Ali et al. - 2016 - An Energy Efficient Algorithm for Virtual Machine .pdf:/home/dani/Insync/Zotero/storage/ET3S9T2D/Ali et al. - 2016 - An Energy Efficient Algorithm for Virtual Machine .pdf:application/pdf;Snapshot:/home/dani/Insync/Zotero/storage/C5B3DNRV/978-981-10:2209-8-6.html:text/html}
}

@article{teng-energy:2017,
	title = {Energy efficiency of {VM} consolidation in {IaaS} clouds},
	volume = {73},
	issn = {0920-8542, 1573-0484},
	url = {http://link.springer.com/10.1007/s11227-016-1797-5},
	doi = {10.1007/s11227-016-1797-5},
	language = {en},
	number = {2},
	urldate = {2017-04:21},
	journal = {The Journal of Supercomputing},
	author = {Teng, Fei and Yu, Lei and Li, Tianrui and Deng, Danting and Magoulès, Fr\'ed\'eric},
	month = feb,
	year = {2017},
	pages = {782--809},
	file = {Teng et al. - 2017 - Energy efficiency of VM consolidation in IaaS clou.pdf:/home/dani/Insync/Zotero/storage/B9JZ77S7/Teng et al. - 2017 - Energy efficiency of VM consolidation in IaaS clou.pdf:application/pdf;Teng et al. - 2017 - Energy efficiency of VM consolidation in IaaS clou.pdf:/home/dani/Insync/Zotero/storage/CX2X77JU/Teng et al. - 2017 - Energy efficiency of VM consolidation in IaaS clou.pdf:application/pdf}
}

@article{kommeri-energy:2016,
  author   = {Kommeri, Jukka and Niemi, Tapio and Nurminen, Jukka K.},
  title    = {Energy efficiency of dynamic management of virtual cluster with heterogeneous hardware},
  journal  = {The Journal of Supercomputing},
  year     = {2016},
  pages    = {1-23},
  issn     = {1573-0484},
  abstract = {Cloud computing is an essential part of today's computing world. Continuously increasing amount of computation with varying resource requirements is placed in large data centers. The variation among computing tasks, both in their resource requirements and time of processing, makes it possible to optimize the usage of physical hardware by applying cloud technologies. In this work, we develop a prototype system for load-based management of virtual machines in an OpenStack computing cluster. Our prototype is based on an idea of `packing' idle virtual machines into special park servers optimized for this purpose. We evaluate the method by running real high-energy physics analysis software in an OpenStack test cluster and by simulating the same principle using the Cloudsim simulator software. The results show a clear improvement, 9–48 \% , in the total energy efficiency when using our method together with resource overbooking and heterogeneous hardware.},
  doi      = {10.1007/s11227-016-1899-0},
  file     = {Kommeri et al. - 2016 - Energy efficiency of dynamic management of virtual.pdf:/home/dani/Insync/Zotero/storage/SXQDGSC3/Kommeri et al. - 2016 - Energy efficiency of dynamic management of virtual.pdf:application/pdf},
  language = {en},
  url      = {http://dx.doi.org/10.1007/s11227-016-1899-0}
}

@inproceedings{kong-multi-level:2016,
	title = {Multi-level image software assembly technology based on {OpenStack} and {Ceph}},
	doi = {10.1109/ITNEC.2016.7560371},
	abstract = {With the development of virtualization technology, it is a prevailing trend that users deploy highly reliable, scalable, high efficiency application services via virtual machines. OpenStack, the most fiery open-source virtual machines management platform, focuses on IaaS(Infrastructure as a Service), and now expands to PaaS(Platform as a Service) and SaaS(Software as a Service). As a Mature IaaS cloud computing product, it's no doubt that it should take data replication and storage mechanism into consideration as a precondition, in order to ensure the integrity and continuity of service provided for users. At the mention of storage, Ceph, a unified, high reliability, high performance and scalable distributed file system, comes to OpenStack's mind, providing block storage, object storage and file storage. To solve the problem that OpenStack only supported Single-level image management which wastes a fairly large number of storage space, we have studied Ceph storage cluster with OpenStack integration architecture and achieved the multi-level image software assembly technology. From the aspect of storage space, the technology eliminate duplication of shared operating system image data and shared application software image data. From the aspect of time, users don't have to install the required application softwares manually, providing the time-saving as well. Once you launched your virtual machine instances, the required softwares have been installed already.},
	booktitle = {2016 {IEEE} {Information} {Technology}, {Networking}, {Electronic} and {Automation} {Control} {Conference}},
	author = {Kong, W. and Luo, Y.},
	year = {2016},
	keywords = {Application software, block storage, Ceph, Ceph storage cluster, Cloning, cloud computing, Computer architecture, data duplication elimination, data storage, file storage, high efficiency application services, high performance distributed file system, high reliability distributed file system, IaaS cloud computing, infrastructure as a service, multilevel image software assembly technology, Mutil-level image, network operating systems, object storage, open-source virtual machines management platform, OpenStack, OpenStack integration architecture, Operating systems, PaaS, parallel databases, platform as a service, public domain software, SaaS, scalable distributed file system, service continuity, service integrity, shared application software image data, shared operating system image data, single-level image management, software architecture, Software as a service, software assembly, software reliability, storage management, virtualisation, virtualization technology, virtual machines, Virtual machining},
	pages = {307--310},
	file = {IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/SGWBFS84/7560371.html:text/html;Kong e Luo - 2016 - Multi-level image software assembly technology bas.pdf:/home/dani/Insync/Zotero/storage/IF9RN24A/Kong e Luo - 2016 - Multi-level image software assembly technology bas.pdf:application/pdf}
}
{detroz-uso:2015,
	title = {Uso de {Pesquisa} {Bibliogr\'afica} em {Inform\'atica} na {Educac\~ao}: um {Mapeamento} {Sistem\'atico}},
	volume = {23},
	issn = {1414-5685, 1414-5685},
	shorttitle = {Uso de {Pesquisa} {Bibliogr\'afica} em {Inform\'atica} na {Educac\~ao}},
	url = {http://www.br-ie.org/pub/index.php/rbie/article/view/2439},
	doi = {10.5753/rbie.2015.23.01.28},
	number = {01},
	urldate = {2017-05-03},
	journal = {Revista Brasileira de Inform\'atica na Educa\{c}c\~ao},
	author = {Detroz, Juliana Patr\'icia and Hinz, Mauro and Hounsell, Marcelo Da Silva},
	month = apr,
	year = {2015},
	pages = {28},
	file = {2845.pdf:/home/dani/Insync/Zotero/storage/VJH9NT8U/2845.pdf:application/pdf}
}

@inproceedings{nathuji-virtualpower:2007,
  author     = {Nathuji, Ripal and Schwan, Karsten},
  title      = {{VirtualPower}: {Coordinated} {Power} {Management} in {Virtualized} {Enterprise} {Systems}},
  booktitle  = {Proceedings of {Twenty}-first {ACM} {SIGOPS} {Symposium} on {Operating} {Systems} {Principles}},
  year       = {2007},
  series     = {{SOSP} '07},
  pages      = {265-278},
  address    = {New York--NY, USA},
  publisher  = {ACM},
  abstract   = {Power management has become increasingly necessary in large-scale datacenters to address costs and limitations in cooling or power delivery. This paper explores how to integrate power management mechanisms and policies with the virtualization technologies being actively deployed in these environments. The goals of the proposed VirtualPower approach to online power management are (i) to support the isolated and independent operation assumed by guest virtual machines (VMs) running on virtualized platforms and (ii) to make it possible to control and globally coordinate the effects of the diverse power management policies applied by these VMs to virtualized resources. To attain these goals, VirtualPower extends to guest VMs `soft' versions of the hardware power states for which their policies are designed. The resulting technical challenge is to appropriately map VM-level updates made to soft power states to actual changes in the states or in the allocation of underlying virtualized hardware. An implementation of VirtualPower Management (VPM) for the Xen hypervisor addresses this challenge by provision of multiple system-level abstractions including VPM states, channels, mechanisms, and rules. Experimental evaluations on modern multicore platforms highlight resulting improvements in online power management capabilities, including minimization of power consumption with little or no performance penalties and the ability to throttle power consumption while still meeting application requirements. Finally, coordination of online methods for server consolidation with VPM management techniques in heterogeneous server systems is shown to provide up to 34\% improvements in power consumption.},
  doi        = {10.1145/1294261.1294287},
  file       = {Nathuji e Schwan - 2007 - VirtualPower Coordinated Power Management in Virt.pdf:/home/dani/Insync/Zotero/storage/VZDUWCE4/Nathuji e Schwan - 2007 - VirtualPower Coordinated Power Management in Virt.pdf:application/pdf},
  isbn       = {978-1-59593-591-5},
  keywords   = {Power management, Virtualization},
  shorttitle = {{VirtualPower}},
  url        = {http://doi.acm.org/10.1145/1294261.1294287},
  urldate    = {2017-05-07}
}

@book{herring-energy:2008,
	title = {Energy {Efficiency} and {Sustainable} {Consumption}: {The} {Rebound} {Effect}},
	isbn = {978-0:230-58310-8},
	shorttitle = {Energy {Efficiency} and {Sustainable} {Consumption}},
	abstract = {This book challenges conventional wisdom by showing how, in some circumstances, improved energy efficiency may increase energy consumption. Relying upon energy efficiency to reduce carbon emissions could therefore be misguided. This book explores the broader implications for climate change and sustainable consumption.},
	language = {en},
	publisher = {Springer},
	author = {Herring, H. and Sorrell, S.},
	month = nov,
	year = {2008},
	keywords = {Business \& Economics / Development / Sustainable Development, Political Science / General, Political Science / History \& Theory, Political Science / Public Policy / Environmental Policy, Science / Energy, Science / Environmental Science, Science / Global Warming \& Climate Change, Technology \& Engineering / Power Resources / Alternative \& Renewable, Technology \& Engineering / Power Resources / General}
}

@article{mazumdar-power:2017,
	title = {Power efficient server consolidation for {Cloud} data center},
	volume = {70},
	issn = {0167-739X},
	url = {http://www.sciencedirect.com/science/article/pii/S0167739X16308093},
	doi = {10.1016/j.future.2016.12.022},
	abstract = {Cloud computing has become an essential part of the global digital economy due to its extensibility, flexibility and reduced costs of operations. Nowadays, data centers (DCs) contain thousands of different machines running a huge number of diverse applications over an extended period. Resource management in Cloud is an open issue since an efficient resource allocation can reduce the infrastructure running cost. In this paper, we propose a snapshot-based solution for server consolidation problem from Cloud infrastructure provider (CIP) perspective. Our proposed mathematical formulation aims at reducing power cost by employing efficient server consolidation, and also considering the issues such as (i) mapping incoming and failing virtual machines (VMs), (ii) reducing a total number of VM migrations and (iii) consolidating running server workloads. We also compare the performance of our proposed model to the well-known Best Fit heuristics and its extension to include server consolidation via VM migration denoted as Best Fit with Consolidation (BFC). Our proposed mathematical formulation allows us to measure the solution quality in absolute terms, and it can also be applicable in practice. In our simulations, we show that relevant improvements (from 6\% to 15\%) over the widely adopted Best Fit algorithm achieved in a reasonable computing time.},
	urldate = {2017-05-16},
	journal = {Future Generation Computer Systems},
	author = {Mazumdar, Somnath and Pranzo, Marco},
	year = {2017},
	keywords = {cloud, Integer linear programming, Optimisation, Server consolidation, Virtual Machine allocation},
	pages = {4--16},
	file = {ScienceDirect Full Text PDF:/home/dani/Insync/Zotero/storage/B34XA2JC/Mazumdar e Pranzo - 2017 - Power efficient server consolidation for Cloud dat.pdf:application/pdf;ScienceDirect Snapshot:/home/dani/Insync/Zotero/storage/HTNT8GZW/S0167739X16308093.html:text/html}
}

@article{tighe-topology:2017,
  author   = {Tighe, Michael and Bauer, Michael},
  title    = {Topology and {Application} {Aware} {Dynamic} {VM} {Management} in the {Cloud}},
  journal  = {Journal of Grid Computing},
  year     = {2017},
  pages    = {1-22},
  month    = may,
  issn     = {1570-7873, 1572-9184},
  abstract = {Cloud computing continues to mature and more applications continue to be deployed in public clouds. Client applications deployed in the cloud should automatically scale up and down to match changing workload demands, though they must be careful to ensure that sufficient resources are provisioned to achieve performance objectives. The cloud provider, on the other hand, attempts to reduce costs by reducing power consumption by consolidating load onto fewer, highly utilized machines. In this work, we introduce an algorithm that integrates both application autoscaling and dynamic virtual machine (VM) allocation into a single algorithm in order to achieve the goals of both cloud provider and client. Further, we consider multi-VM applications, such as multi-tiered web-based applications, and extend the integrated algorithm to take the network topology into account when placing or migrating applications. The goal is to reduce VM-to-VM communication latency; our focus is on trying to contain applications within the same racks. We evaluate our work through simulation, showing that the integrated algorithm can achieve better application performance with a significant reduction in virtual machine live migrations, and the topology-aware extension successfully places applications within a single rack.},
  doi      = {10.1007/s10723-017-9397-z},
  file     = {10.1007@s10723-017-9397-z.pdf:/home/dani/Insync/Zotero/storage/TFXIGU7P/10.1007@s10723-017-9397-z.pdf:application/pdf;Snapshot:/home/dani/Insync/Zotero/storage/B94BAXRR/10.html:text/html;Tighe e Bauer - 2017 - Topology and Application Aware Dynamic VM Manageme.pdf:/home/dani/Insync/Zotero/storage/HP3DSSFR/Tighe e Bauer - 2017 - Topology and Application Aware Dynamic VM Manageme.pdf:application/pdf},
  language = {en},
  url      = {https://link.springer.com/article/10.1007/s10723-017-9397-z},
  urldate  = {2017-05-16}
}

@article{marston-cloud:2011,
	title = {Cloud computing — {The} business perspective},
	volume = {51},
	issn = {0167-9236},
	url = {http://www.sciencedirect.com/science/article/pii/S0167923610002393},
	doi = {10.1016/j.dss.2010.12.006},
	abstract = {The evolution of cloud computing over the past few years is potentially one of the major advances in the history of computing. However, if cloud computing is to achieve its potential, there needs to be a clear understanding of the various issues involved, both from the perspectives of the providers and the consumers of the technology. While a lot of research is currently taking place in the technology itself, there is an equally urgent need for understanding the business-related issues surrounding cloud computing. In this article, we identify the strengths, weaknesses, opportunities and threats for the cloud computing industry. We then identify the various issues that will affect the different stakeholders of cloud computing. We also issue a set of recommendations for the practitioners who will provide and manage this technology. For IS researchers, we outline the different areas of research that need attention so that we are in a position to advice the industry in the years to come. Finally, we outline some of the key issues facing governmental agencies who, due to the unique nature of the technology, will have to become intimately involved in the regulation of cloud computing.},
	number = {1},
	urldate = {2017-05-16},
	journal = {Decision Support Systems},
	author = {Marston, Sean and Li, Zhi and Bandyopadhyay, Subhajyoti and Zhang, Juheng and Ghalsasi, Anand},
	year = {2011},
	keywords = {cloud computing, Cloud computing regulation, infrastructure as a service, On-demand computing, platform as a service, Software as a service, Virtualization},
	pages = {176--189},
	file = {ScienceDirect Full Text PDF:/home/dani/Insync/Zotero/storage/I7A5FNSI/Marston et al. - 2011 - Cloud computing — The business perspective.pdf:application/pdf;ScienceDirect Snapshot:/home/dani/Insync/Zotero/storage/PSA6422X/S0167923610002393.html:text/html}
}

@inproceedings{hieu-virtual:2015,
	title = {Virtual {Machine} {Consolidation} with {Usage} {Prediction} for {Energy}-{Efficient} {Cloud} {Data} {Centers}},
	isbn = {978-1-4673-7287-9},
	doi = {10.1109/CLOUD.2015.104},
	abstract = {Virtual machine consolidation aims at reducing the number of active physical servers in a data center, with the goal to reduce the total power consumption. In this context, most of the existing solutions rely on aggressive virtual machine migration, thus resulting in unnecessary overhead and energy wastage. This article presents a virtual machine consolidation algorithm with usage prediction (VMCUP) for improving the energy efficiency of cloud data centers. Our algorithm is executed during the virtual machine consolidation process to estimate the short-term future CPU utilization based on the local history of the considered servers. The joint use of current and predicted CPU utilization metrics allows a reliable characterization of overloaded and under loaded servers, thereby reducing both the load and the power consumption after consolidation. We evaluate our proposed solution through simulations on real workloads from the Planet Lab and the Google Cluster Data datasets. In comparison with the state of the art, the obtained results show that consolidation with usage prediction reduces the total migrations and the power consumption of the servers while complying with the service level agreement. © 2015 IEEE.},
	language = {English},
	author = {Hieu, N.T. and Di, Francesco and Yla-Jaaski, A.},
	year = {2015},
	note = {DOI: 10.1109/CLOUD.2015.104},
	keywords = {cloud computing, Data centers, Resource prediction, virtual machine consolidation, Virtual machine migration},
	pages = {750--757},
	file = {SCOPUS Snapshot:/home/dani/Insync/Zotero/storage/IN4NTFAD/display.html:text/html}
}

@article{zhao-online:2017,
  author   = {Zhao, L. and Lu, L. and Jin, Z. and Yu, C.},
  title    = {Online {Virtual} {Machine} {Placement} for {Increasing} {Cloud} {Provider}’s {Revenue}},
  journal  = {IEEE Transactions on Services Computing},
  year     = {2017},
  volume   = {10},
  number   = {2},
  pages    = {273-285},
  month    = mar,
  issn     = {1939-1374},
  abstract = {Cost savings have become a significant challenge in the management of data centers. In this paper, we show that, besides energy consumption, service level agreement(SLA) violations also severely degrade the cost-efficiency of data centers. We present online VM placement algorithms for increasing cloud provider's revenue. First, First-Fit and Harmonic algorithm are devised for VM placement without considering migrations. Both algorithms get the same performance in the worst-case analysis, and equal to the lower bound of the competitive ratio. However, Harmonic algorithm could create more revenue than First-Fit by more than 10 percent when job arriving rate is greater than 1.0. Second, we formulate an optimization problem of maximizing revenue from VM migration, and prove it as NP-Hard by a reduction from 3-Partition problem. Therefore, we propose two heuristics: Least-Reliable-First (LRF) and Decreased-Density-Greedy (DDG). Experiments demonstrate that DDG yields more revenue than LRF when migration cost is low, yet leads to losses when SLA penalty is low or job arriving rate is high, due to the large number of migrations. Finally, we compare the four algorithms above with algorithms adopted in Openstack using a real trace, and find that the results are consistent with the ones using synthetic data.},
  doi      = {10.1109/TSC.2015.2447550},
  file     = {:/home/daniel/Insync/Zotero/storage/NUQNP76K/Zhao et al. - 2017 - Online Virtual Machine Placement for Increasing Cl.pdf:PDF},
  keywords = {Algorithm design and analysis, cloud, cloud computing, cloud provider revenue, competitive ratio, cost savings, Data centers, DDG, decreased density greedy, Economics, Harmonic algorithm, Harmonic analysis, increasing cloud provider revenue, least reliable first, LRF, NP-Hard, Online algorithm, online virtual machine placement, online VM placement algorithms, operating systems (computers), Random access memory, Reliability, revenue, Schedules, Service Level Agreement, SLA violations, Upper bound, virtual machine placement, virtual machines, VM placement},
  url      = {http://ieeexplore.ieee.org/document/7128735/}
}

@article{koomey-new:2015,
	title = {New data supports finding that 30 percent of servers are ‘{Comatose}’, indicating that nearly a third of capital in enterprise data centers is wasted},
	volume = {3},
	url = {http://tsologic.com/wp-content/uploads/2015/06/AnthesisGroup-Case-Study-30PercentComatose-06032015.pdf},
	urldate = {2017-05-17},
	journal = {June},
	author = {Koomey, Jonathan and Taylor, Jon},
	year = {2015},
	pages = {2015},
	file = {Case-Study-DataSupports30PercentComatoseEstimate-FINAL-06032015.pdf:/home/dani/Insync/Zotero/storage/AZZEENNJ/Case-Study-DataSupports30PercentComatoseEstimate-FINAL-06032015.pdf:application/pdf}
}

@article{koomey-zombie/comatose:2017,
	title = {{ZOMBIE}/{COMATOSE} {SERVERS} {REDUX}},
	url = {http://anthesisgroup.com/wp-content/uploads/2017/03/Comatsoe-Servers-Redux:2017.pdf},
	urldate = {2017-05-18},
	author = {Koomey, Jonathan and Taylor, Jon},
	year = {2017},
	file = {Comatsoe-Servers-Redux:2017.pdf:/home/dani/Insync/Zotero/storage/CCKHPKGD/Comatsoe-Servers-Redux:2017.pdf:application/pdf;Comatsoe-Servers-Redux:2017.pdf:/home/dani/Insync/Zotero/storage/IGZ8QUEV/Comatsoe-Servers-Redux:2017.pdf:application/pdf}
}

@inproceedings{bijon-virtual:2015,
	title = {Virtual {Resource} {Orchestration} {Constraints} in {Cloud} {Infrastructure} as a {Service}},
	isbn = {978-1-4503-3191-3},
	url = {http://dl.acm.org/citation.cfm?doid=2699026.2699112},
	doi = {10.1145/2699026.2699112},
	language = {en},
	urldate = {2017-05:27},
	publisher = {ACM Press},
	author = {Bijon, Khalid and Krishnan, Ram and Sandhu, Ravi},
	year = {2015},
	pages = {183--194},
	file = {2015-codaspy.pdf:/home/dani/Insync/Zotero/storage/J53JPUI6/2015-codaspy.pdf:application/pdf}
}
{gomes-plataforma:2016,
	title = {Plataforma de \'areas de trabalho virtuais escal\'avel para nuvens privadas},
	number = {XIV WCGA/SBRC},
	author = {Gomes, Demis and Ver\{c}cosa, Nichene and Medeiros, Victor and Gon\{c}calves, Glauco},
	year = {2016},
	file = {154326-1.pdf:/home/dani/Insync/Zotero/storage/GPZ8HSJT/154326-1.pdf:application/pdf}
}

@article{sciammarella-uma:2016,
	title = {Uma {An\'alise} do {Tr\'afego} de {Controle} de uma {Nuvem} {IaaS} {Geodistribuıda}},
	author = {Sciammarella, Tatiana and Couto, Rodrigo S and Rubinstein, Marcelo G and Campista, Miguel Elias M and Costa, Luıs Henrique MK},
	year = {2016},
	file = {Uma-Analise-do-Trafego-de-Controle-de-uma-Nuvem-IaaS-Geodistribuida.pdf:/home/dani/Insync/Zotero/storage/XEESAHRV/Uma-Analise-do-Trafego-de-Controle-de-uma-Nuvem-IaaS-Geodistribuida.pdf:application/pdf}
}

@article{milani-load:2016,
	title = {Load balancing mechanisms and techniques in the cloud environments: {Systematic} literature review and future trends},
	volume = {71},
	issn = {10848045},
	shorttitle = {Load balancing mechanisms and techniques in the cloud environments},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1084804516301217},
	doi = {10.1016/j.jnca.2016.06.003},
	language = {en},
	urldate = {2017-06-05},
	journal = {Journal of Network and Computer Applications},
	author = {Milani, Alireza Sadeghi and Navimipour, Nima Jafari},
	month = aug,
	year = {2016},
	pages = {86--98},
	file = {milani2016.pdf:/home/dani/Insync/Zotero/storage/2JQ6PHS5/milani2016.pdf:application/pdf}
}

@inproceedings{alkawsi-factors:2015,
  author     = {Alkawsi, Gamal Abdulnaser and Mahmood, Ahmad Kamil and Baashar, Yahia Mohamed},
  title      = {Factors influencing the adoption of cloud computing in {SME}: {A} systematic review},
  booktitle  = {Mathematical {Sciences} and {Computing} {Research} ({iSMSC}), {International} {Symposium} on},
  year       = {2015},
  pages      = {220-225},
  publisher  = {IEEE},
  file       = {alkawsi2015.pdf:/home/dani/Insync/Zotero/storage/4E8NKM54/alkawsi2015.pdf:application/pdf},
  shorttitle = {Factors influencing the adoption of cloud computing in {SME}},
  url        = {http://ieeexplore.ieee.org/abstract/document/7594056/},
  urldate    = {2017-06-05}
}

@article{madni-recent:2016,
	title = {Recent advancements in resource allocation techniques for cloud computing environment: a systematic review},
	issn = {1386-7857, 1573-7543},
	shorttitle = {Recent advancements in resource allocation techniques for cloud computing environment},
	url = {http://link.springer.com/10.1007/s10586-016-0684-4},
	doi = {10.1007/s10586-016-0684-4},
	language = {en},
	urldate = {2017-06-05},
	journal = {Cluster Computing},
	author = {Madni, Syed Hamid Hussain and Latiff, Muhammad Shafie Abd and Coulibaly, Yahaya and Abdulhamid, Shafi’i Muhammad},
	month = dec,
	year = {2016},
	file = {madni2016.pdf:/home/dani/Insync/Zotero/storage/WGX7UIUX/madni2016.pdf:application/pdf}
}
{buchinger-mecanismos:2014,
	title = {Mecanismos de busca acad\^emica: uma an\'alise quantitativa},
	volume = {6},
	copyright = {Direitos autorais},
	issn = {2176-6649},
	shorttitle = {Mecanismos de busca acad\^emica},
	url = {http://seer.upf.br/index.php/rbca/article/view/3452},
	doi = {10.5335/rbca.2014.3452},
	language = {pt},
	number = {1},
	urldate = {2017-06-05},
	journal = {Revista Brasileira de Computa\{c}c\~ao Aplicada},
	author = {Buchinger, Diego and Cavalcanti, Gustavo Andriolli de Siqueira and Hounsell, Marcelo da Silva},
	month = apr,
	year = {2014},
	keywords = {Mecanismos de Busca Acad\^emica, Metodologia da Pesquisa, Pesquisa Cient\'ifica},
	pages = {108--120},
	file = {Full Text PDF:/home/dani/Insync/Zotero/storage/7XM5J5R6/Buchinger et al. - 2014 - Mecanismos de busca acad\^emica uma an\'alise quantit.pdf:application/pdf;Snapshot:/home/dani/Insync/Zotero/storage/FG57I576/3452.html:text/html}
}

@article{oppenheim-evaluation:2000,
  author  = {Oppenheim, C. and Morris, A. and McKnight, C. and Lowley, S.},
  title   = {The evaluation of {WWW} search engines},
  journal = {Journal of Documentation},
  year    = {2000},
  volume  = {56},
  number  = {2},
  pages   = {190-211},
  month   = apr,
  issn    = {0022-0418},
  doi     = {10.1108/00220410010803810},
  file    = {Snapshot:/home/dani/Insync/Zotero/storage/G7TDNUGM/00220410010803810.html:text/html},
  url     = {http://www.emeraldinsight.com/doi/abs/10.1108/00220410010803810},
  urldate = {2017-06-05}
}

@article{ladeira-gestao:2012,
	title = {Gest\~ao de processos, indicadores anal\'iticos e impactos sobre o desempenho competitivo em grandes e m\'edias empresas brasileiras dos setores da ind\'ustria e de servi\{c}cos},
	volume = {19},
	url = {http://www.scielo.br/pdf/gp/v19n2/v19n2a12},
	number = {2},
	urldate = {2017-01-08},
	journal = {Gest. Prod., S\~ao Carlos},
	author = {Ladeira, Marcelo Bronzo and de Resende, Paulo Tarso Vilela and de Oliveira, Marcos Paulo Valadares and McCormack, Kevin and de Sousa, Paulo Renato and Ferreira, Reinaldo Lopes},
	year = {2012},
	pages = {389--404},
	file = {v19n2a12.pdf:/home/dani/Dropbox/UDESC/Mestrado/Zotero/storage/8MRIFIEJ/v19n2a12.pdf:application/pdf}
}

@phdthesis{ono-indicadores:2014,
	address = {MBA/USP},
	type = {Monografia: {Gerenciamento} de {Facilidades}},
	title = {Indicadores de desempenho em  {Data} {Center}},
	url = {http://poli-integra.poli.usp.br/library/pdfs/e9dd84cde3229a14e0589d884f979772.pdf},
	urldate = {2017-01-08},
	school = {Escola Polit\'ecnica da Universidade de S\~ao Paulo},
	author = {Ono, Mario Yoshito},
	year = {2014},
	file = {e9dd84cde3229a14e0589d884f979772.pdf:/home/dani/Dropbox/UDESC/Mestrado/Zotero/storage/BCAFVUPB/e9dd84cde3229a14e0589d884f979772.pdf:application/pdf}
}

@article{remote:2016,
	series = {7th {EUSPN} 2016 / 6th {ICTH}-2016},
	title = {A {Remote} {System} for {Monitoring} {Auxiliary} {Data} {Center} from {Environmental} {Threats} with {Lower} {Hardware} {Cost}},
	volume = {98},
	issn = {1877-0509},
	doi = {10.1016/j.procs.2016.09.030},
	abstract = {There are some data centers that are located far from the main data center for ensuring continuity of company's Information Technology operations in case the main data center encounters a serious downtime especially for companies engaged to work in distributed manner to increase quality-of -service to their customers. Environmental downtime is a significant cost to organizations and makes them unable to do business because what happens in the data center affects everyone. In addition, the amount of electrical energy consumed by data center increases with the amount of computing power installed. One strategy of reducing energy consumption in data centers is to adjust the temperature and humidity data. Installation of physical Information Technology and facilities related to environment on monitoring temperature, humidity, power, flood, smoke, air flow, room entry is the most proactive way to reduce the unnecessary costs of expensive hardware replacement or unplanned downtime and decrease energy consumed by servers. In this paper, we present remote system for monitoring auxiliary data centers implemented using open-source hardware platforms, Arduino, Raspberry Pi, and the Gobetwino. The objective of collecting temperature and humidity data allows monitoring server's health and gets alerts if things start to go wrong. When the temperature hits 50oC., the supervisor at remote headquarters would get a SMS, then take appropriate actions that make sense to reduce electrical costs and preserve functionality of servers in auxiliary data centers. The data center environmental monitoring represents a step forward towards addressing awareness monitoring of energy efficiency and data centers located far with ability to receive a notification by email.},
	urldate = {2017-01-10},
	journal = {7th {EUSPN} 2016 / 6th {ICTH}-2016},
	author = {Nkenyereye, Lionel and Jang, Jong-wook},
	year = {2016},
	keywords = {arduino, auxiliary data center, Energy efficiency, environmental monitoring, Gobetwino, notification, raspberry Pi, secure copy},
	pages = {187--192},
	file = {ScienceDirect Full Text PDF:/home/dani/Dropbox/UDESC/Mestrado/Zotero/storage/3KS8DA5S/Nkenyereye e Jang - 2016 - A Remote System for Monitoring Auxiliary Data Cent.pdf:application/pdf;ScienceDirect Snapshot:/home/dani/Dropbox/UDESC/Mestrado/Zotero/storage/DMIMHG7F/S1877050916321597.html:text/html}
}

@inproceedings{kim-free:2012,
	title = {Free cooling-aware dynamic power management for green datacenters},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6266903},
	urldate = {2017-01-10},
	booktitle = {High {Performance} {Computing} and {Simulation} ({HPCS}), 2012 {International} {Conference} on},
	publisher = {IEEE},
	author = {Kim, Jungsoo and Ruggiero, Martino and Atienza, David},
	year = {2012},
	pages = {140--146},
	file = {7e70419a29f0506ef4789c491b1fbd706396.pdf:/home/dani/Dropbox/UDESC/Mestrado/Zotero/storage/4BW7VCFM/7e70419a29f0506ef4789c491b1fbd706396.pdf:application/pdf}
}

@inproceedings{brunelli-povomon:2014,
	title = {{POVOMON}: {An} {Ad}-hoc {Wireless} {Sensor} {Network} for indoor environmental monitoring},
	shorttitle = {{POVOMON}},
	doi = {10.1109/EESMS.2014.6923287},
	abstract = {Wireless Sensor Networks (WSN) are a versatile technology that offers the ability to monitor real-world phenomena in detail and at large scale in scenarios where wired infrastructures are inapplicable or expensive. In this paper we present an ad-hoc WSN deployment for indoor environmental quality monitoring in office buildings. The indoor environmental quality and balance between inhabitant comfort level and power demands are the main objectives of this network. The presented system consists of 19 sensor devices continuously measuring vibration, temperature, humidity, light, and carbon dioxide levels in working areas. The power load of the building is measured by dedicated current sensor devices. Preliminary laboratory tests and data sets collected during 4 months of real world operation show that our system provides an accurate monitoring of indoor environmental parameters delivering high data reliability with an estimated lifetime exceeding 1.5 years, without the gas sensors. The paper presents the HW/SW architecture, the network infrastructure of the deployment and analyzes real measurement data.},
	booktitle = {2014 {IEEE} {Workshop} on {Environmental}, {Energy}, and {Structural} {Monitoring} {Systems} {Proceedings}},
	author = {Brunelli, D. and Minakov, I. and Passerone, R. and Rossi, M.},
	month = sep,
	year = {2014},
	keywords = {ad hoc networks, ad-hoc wireless sensor network, ad-hoc WSN deployment, Buildings, current sensor devices, data reliability, data sets, environmental monitoring (geophysics), Humidity, HW architecture, indoor communication, indoor environment, indoor environmental quality monitoring, laboratory tests, Monitoring, office buildings, Packet loss, POVOMON, real-world phenomena, sensor placement, SW architecture, Temperature measurement, Temperature sensors, wireless sensor networks},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/home/dani/Dropbox/UDESC/Mestrado/Zotero/storage/3DT3FKSA/6923287.html:text/html;IEEE Xplore Full Text PDF:/home/dani/Dropbox/UDESC/Mestrado/Zotero/storage/UZH2QEWR/Brunelli et al. - 2014 - POVOMON An Ad-hoc Wireless Sensor Network for ind.pdf:application/pdf}
}

@article{mosa-optimizing:2016,
	title = {Optimizing {VM} placement for energy and {SLA} in clouds using utility functions},
	issn = {2192-113X},
	volume = {5},
	doi = {10.1186/s13677-016-0067-7},
	abstract = {Cloud computing provides on-demand access to a shared pool of computing resources, which enables organizations to outsource their IT infrastructure. Cloud providers are building data centers to handle the continuous increase in cloud users’ demands. Consequently, these cloud data centers consume, and have the potential to waste, substantial amounts of energy. This energy consumption increases the operational cost and the CO2 emissions. The goal of this paper is to develop an optimized energy and SLA-aware virtual machine (VM) placement strategy that dynamically assigns VMs to Physical Machines (PMs) in cloud data centers. This placement strategy co-optimizes energy consumption and service level agreement (SLA) violations. The proposed solution adopts utility functions to formulate the VM placement problem. A genetic algorithm searches the possible VMs-to-PMs assignments with a view to finding an assignment that maximizes utility. Simulation results using CloudSim show that the proposed utility-based approach reduced the average energy consumption by approximately 6 \% and the overall SLA violations by more than 38 \%, using fewer VM migrations and PM shutdowns, compared to a well-known heuristics-based approach.},
	journal = {Journal of Cloud Computing},
	author = {Mosa, Abdelkhalik and Paton, Norman W.},
	year = {2016}
}

@article{ahmad-survey:2015,
	title = {A Survey on Virtual Machine Migration and Server Consolidation Frameworks for Cloud Data Centers},
	volume = {52},
	issn = {1084-8045},
	url = {http://dx.doi.org/10.1016/j.jnca.2015.02.002},
	doi = {10.1016/j.jnca.2015.02.002},
	abstract = {Modern Cloud Data Centers exploit virtualization for efficient resource management to reduce cloud computational cost and energy budget. Virtualization empowered by virtual machine ({VM}) migration meets the ever increasing demands of dynamic workload by relocating {VMs} within Cloud Data Centers. {VM} migration helps successfully achieve various resource management objectives such as load balancing, power management, fault tolerance, and system maintenance. However, being resource-intensive, the {VM} migration process rigorously affects application performance unless attended by smart optimization methods. Furthermore, a Cloud Data Centre exploits server consolidation and {DVFS} methods to optimize energy consumption. This paper reviews state-of-the-art bandwidth optimization schemes, server consolidation frameworks, {DVFS}-enabled power optimization, and storage optimization methods over {WAN} links. Through a meticulous literature review of state-of-the-art live {VM} migration schemes, thematic taxonomies are proposed to categorize the reported literature. The critical aspects of virtual machine migration schemes are investigated through a comprehensive analysis of the existing schemes. The commonalties and differences among existing {VM} migration schemes are highlighted through a set of parameters derived from the literature. Finally, open research issues and trends in the {VM} migration domain that necessitate further consideration to develop optimal {VM} migration schemes are highlighted.},
	pages = {11--25},
	issue = {C},
	journal = {{JNCA}},
	author = {Ahmad, R. W. {et. al}}, 
	urldate = {2016-11-16},
	year = {2015},
	langid = {english},
	keywords = {Data center, {QoS}, Server consolidation, Virtualization, {VM} migration}
}author={and Gani, Abdullah and Hamid, Siti Hafizah Ab. and Shiraz, Muhammad and Yousafzai, Abdullah and Xia, Feng},

@article{forsman-algorithms:2015,
	title = {Algorithms for automated live migration of virtual machines},
	volume = {101},
	issn = {01641212},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121214002751},
	doi = {10.1016/j.jss.2014.11.044},
	pages = {110--126},
	journaltitle = {Journal of Systems and Software},
	author = {Forsman, Mattias and Glad, Andreas and Lundberg, Lars and Ilie, Dragos},
	urldate = {2016-11-16},
	year = {2015},
	langid = {english}
}

@article{ding-energy:2015,
	title = {Energy efficient scheduling of virtual machines in cloud with deadline constraint},
	volume = {50},
	issn = {0167739X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167739X15000369},
	doi = {10.1016/j.future.2015.02.001},
	pages = {62--74},
	journaltitle = {Future Generation Computer Systems},
	author = {Ding, Youwei and Qin, Xiaolin and Liu, Liang and Wang, Taochun},
	urldate = {2016-11-16},
	year = {2015},
	langid = {english}
}

@article{beloglazov-energy-aware:2012,
  author   = {Beloglazov, Anton And Abawajy, Jemal And Buyya, Rajkumar},
  title    = {Energy-aware Resource Allocation Heuristics For Efficient Management Of Data Centers For Cloud Computing},
  journal  = {Future Gener. Comput. Syst.},
  year     = {2012},
  volume   = {28},
  number   = {5},
  pages    = {755--768},
  abstract = {Cloud Computing Offers Utility-oriented It Services To Users Worldwide. Based On A Pay-as-you-go Model, It Enables Hosting Of Pervasive Applications From Consumer, Scientific, And Business Domains. However, Data Centers Hosting Cloud Applications Consume Huge Amounts Of Electrical Energy, Contributing To High Operational Costs And Carbon Footprints To The Environment. Therefore, We Need Green Cloud Computing Solutions That Can Not Only Minimize Operational Costs But Also Reduce The Environmental Impact. In This Paper, We Define An Architectural Framework And Principles For Energy-efficient Cloud Computing. Based On This Architecture, We Present Our Vision, Open Research Challenges, And Resource Provisioning And Allocation Algorithms For Energy-efficient Management Of Cloud Computing Environments. The Proposed Energy-aware Allocation Heuristics Provision Data Center Resources To Client Applications In A Way That Improves Energy Efficiency Of The Data Center, While Delivering The Negotiated Quality Of Service (qos). In Particular, In This Paper We Conduct A Survey Of Research In Energy-efficient Computing And Propose: (a) Architectural Principles For Energy-efficient Management Of Clouds; (b) Energy-efficient Resource Allocation Policies And Scheduling Algorithms Considering Qos Expectations And Power Usage Characteristics Of The Devices; And (c) A Number Of Open Research Challenges, Addressing Which Can Bring Substantial Benefits To Both Resource Providers And Consumers. We Have Validated Our Approach By Conducting A Performance Evaluation Study Using The Cloudsim Toolkit. The Results Demonstrate That Cloud Computing Model Has Immense Potential As It Offers Significant Cost Savings And Demonstrates High Potential For The Improvement Of Energy Efficiency Under Dynamic Workload Scenarios.},
  doi      = {10.1016/j.future.2011.04.017},
  issn     = {0167-739X},
  keywords = {Cloud Computing, Dynamic Consolidation, Energy Efficiency, Green It, Resource Management, Virtualization},
  urldate  = {2016-06-24}
}

@Online{iso50001:2016,
  author     = {Iso/iec},
  title      = {Iso 50001 - Energy Management},
  year       = {2016},
  editor     = {Iso/iec},
  titleaddon = {Iso},
  url        = {http://www.iso.org/iso/home/standards/management-standards/iso50001.htm},
  urldate    = {2016-09-19}
}

@book{antonopoulos-cloud:2010,
  title      = {Cloud Computing: Principles, Systems And Applications},
  publisher  = {Springer Science \& Business Media},
  year       = {2010},
  author     = {Antonopoulos, Nikos And Gillam, Lee},
  abstract   = {Cloud Computing Has Recently Emerged As A Subject Of Substantial Industrial And Academic Interest, Though Its Meaning And Scope Is Hotly Debated. For Some Researchers, Clouds Are A Natural Evolution Towards The Full Commercialisation Of Grid Systems, While Others Dismiss The Term As A Mere Re-branding Of Existing Pay-per-use Technologies. From Either Perspective, ''cloud'' Is Now The Label Of Choice For Accountable Pay-per-use Access To Third Party Applications And Computational Resources On A Massive Scale. Clouds Support Patterns Of Less Predictable Resource Use For Applications And Services Across The It Spectrum, From Online Office Applications To High-throughput Transactional Services And High-performance Computations Involving Substantial Quantities Of Processing Cycles And Storage. The Concept Of Clouds Seems To Blur The Distinctions Between A Variety Of Technologies That Encompass Grid Services, Web Services And Data Centres, And Leads To Considerations Of Lowered-cost Provisioning For Bursty Applications. This Book Provides Comprehensive Coverage Of The State Of The Art In Cloud Computing, Highlighting And Clarifying The Conceptual And Systemic Links With Other Distributed Computing Approaches.},
  isbn       = {978-1-84996-241-4},
  keywords   = {Computers / Hardware / General, Computers / Hardware / Mobile Devices, Computers / Information Technology, Computers / Software Development & Engineering / Systems Analysis & Design, Computers / Web / Web Services & Apis},
  langid     = {English},
  pagetotal  = {386},
  shorttitle = {Cloud Computing}
}

@Report{cenelec-50600-cenelec/cei:2015,
  author      = {Cenelec-50600},
  title       = {Cenelec/cei En 50600-2-3 : Information Technology - Data Centre Facilities And Infrastructures Part 2-3: Environmental Control},
  year        = {2015},
  abstract    = {This European Standard Addresses Environmental Control Within Data Centres Based Upon The Criteria And Classifications For {\textquotedblleft}availability{\textquotedblright}, {\textquotedblleft}security{\textquotedblright} And {\textquotedblleft}energy Efficiency Enablement{\textquotedblright} Within En 50600-1. This European Standard Specifies Requirements And Recommendations For The Following: A) Temperature Control, B) Fluid Movement Control, C) Relative Humidity Control, D) Particulate Control, E) Vibration, F) Floor Layout And Equipment Locations, G) Energy Saving Practices, H) Physical Security Of Environmental Control Systems.},
  institution = {European Committee For Electrotechnical Standardization (cenelec) And Comitato Elettrotecnico Italiano (cei)},
  langid      = {English},
  location    = {Italy},
  number      = {50600-2-3},
  pages       = {30},
  type        = {Standard},
  url         = {https://global.ihs.com/doc_detail.cfm?&item_s_key=00674444&item_key_date=840031&input_doc_number=50600&input_doc_title=},
  urldate     = {2016-09-07}
}

@inproceedings{florence-energy:2014,
  author     = {Florence, A. P. And Shanthi, V.},
  title      = {Energy Aware Load Balancing For Computational Cloud},
  booktitle  = {2014 IEEE International Conference On Computational Intelligence And Computing Research (iccic)},
  year       = {2014},
  pages      = {1--3},
  abstract   = {Cloud Computing Is Novel Technology, Which Enables Any Resource As Service On Demand. Cloud Environment Motivates Highly Dynamic Resource Provisioning. Hence Clients Can Scale Up Or Scale Down Their Requirements As Per Their Demand. Load Balancing Is Very Important And Complex Problem In Cloud Environment, Because Of Its Heterogeneity Of The Computing Nodes. In Order To Realize The Full Potential Of Cloud Computing It Is Vital To Minimize Energy Consumption Along With Effective Load Balancing. The Aim Of Energy Aware Load Balancing (ealb) Model Is To Minimize Energy Consumption With Load Balancing. Ealb Model Classifies The Incoming Job Request Either Cpu Bound Or I/o Bound According To Their Purpose And Behaviour. This Classification Details Are Maintained In A Table Named Pattern History Table (pht) And Organized As Hash Table. One Of The Virtual Machine (vm) Is Selected Dynamically Based On Best Fit Allocation Policy And The Job Is Assigned To The Victimized Vm. From The Pattern History Table Job's Nature Is Identified. Using Dynamic Voltage Frequency Scaling (dvfs) Scheme The Selected Vm's Processor Clock Frequency Is Increased If It Is Found Cpu Bound Else Decreased (i/o Bound). Thus, Ealb Algorithm Saves Considerable Amount Of Energy And Proves To Be More Efficient.},
  doi        = {10.1109/ICCIC.2014.7238489},
  eventtitle = {2014 IEEE International Conference On Computational Intelligence And Computing Research (iccic)},
  keywords   = {Algorithm Design And Analysis, Best Fit Allocation Policy, Cloud Computing, Computational Cloud, Computational Modeling, Dvfs, Dynamic Voltage, Dynamic Voltage Frequency Scaling, Ealb Model, Energy Aware Load Balancing, Energy Consumption, Energy Consumption Minimization, Frequency Scaling, Hash Table, Heterogeneity, Heuristic Algorithms, Load Balancing, Load Management, Pattern History Table, Pht, Power Aware Computing, Processor Clock Frequency, Resource Allocation, Resource Management, Virtual Machine, Virtual Machines, Vm}
}

@inproceedings{dhurandher-cluster-based:2014,
  author     = {Dhurandher, S. K. And Obaidat, M. S. And Woungang, I. And Agarwal, P. And Gupta, A. And Gupta, P.},
  title      = {A Cluster-based Load Balancing Algorithm In Cloud Computing},
  booktitle  = {2014 IEEE International Conference On Communications (icc)},
  year       = {2014},
  pages      = {2921--2925},
  abstract   = {Workload And Resource Management Are Two Essential Functions Provided At The Service Level Of The Distributed Systems Infrastructure. To Improve The Global Throughput Of These Software Environments, Workloads Have To Be Evenly Scheduled Among The Available Resources. To Realize This Goal, Several Load Balancing Strategies And Algorithms Have Been Proposed. Most O F T H E S E Strategies Were Developed Assuming Homogeneous Set Of Sites Linked With Homogeneous And Fast Networks. However, For Computational Grids, We Must Address Some New Issues, Namely: Heterogeneity, Scalability And Adaptability. In This Paper, We Propose A Decentralized Cluster-based Algorithm Which Achieves Dynamic Load Balancing In The Cloud Architecture. The Proposed Algorithm Presents The Following Main Features: (i) It Supports Heterogeneity, (ii) Scalability, (iii) Low Network Congestion And (iv) Absence Of Any Bottleneck Node Due To Its Decentralized Nature. Simulation Results Using Cloudsim Show The Performance Analysis Of The Algorithm For Patronizing Our Claims About The Load Balancing Achieved In The System.},
  doi        = {10.1109/ICC.2014.6883768},
  eventtitle = {2014 IEEE International Conference On Communications (icc)},
  keywords   = {Adaptability, Algorithm Design And Analysis, Cloud Architecture, Cloud Computing, Cloudsim, Cluster-based Load Balancing Algorithm, Clustering Algorithms, Computer Architecture, Distributed Systems Infrastructure, Heterogeneity, Load Management, Load Modeling, Network Congestion, Peer-to-peer Computing, Resource Allocation, Resource Management, Scalability, Telecommunication Traffic, Workload Management}
}


@article{ranjan-cloud:2015,
	title = {Cloud {Resource} {Orchestration} {Programming}: {Overview}, {Issues}, and {Directions}},
	volume = {19},
	issn = {1089-7801},
	shorttitle = {Cloud {Resource} {Orchestration} {Programming}},
	doi = {10.1109/MIC.2015.20},
	abstract = {Cloud computing provides on-demand access to affordable hardware (such as multicore CPUs, GPUs, disk drives, and networking equipment) and software (databases, application servers, load-balancers, data processors, and frameworks). The pervasiveness and power of cloud computing alleviates some of the problems that application administrators face in their existing hardware and locally managed software environments. However, the rapid increase in scale, dynamicity, heterogeneity, and diversity of cloud resources necessitates having expert knowledge about programming complex orchestration operations (for example, selection, deployment, monitoring, and runtime control) on those resources to achieve the desired quality of service. This article provides an overview of the key cloud resource types and resource orchestration operations, with special focus on research issues involved in programming those operations.},
	number = {5},
	journal = {IEEE Internet Computing},
	author = {Ranjan, R. and Benatallah, B. and Dustdar, S. and Papazoglou, M. P.},
	month = sep,
	year = {2015},
	keywords = {application servers, Big Data, cloud computing, cloud resource orchestration programming, cloud resources diversity, cloud resources dynamicity, cloud resources heterogeneity, complex orchestration operations programming, databases, data processors, disk drives, expert knowledge, GPU, hardware environments, Internet/Web technologies, load-balancers, Monitoring, multicore CPU, networking equipment, pervasiveness, Programming, quality of service, resource allocation, Resource management, resource orchestration, Servers, Software as a service, software environments, Web and internet services},
	pages = {46--56},
	file = {Ranjan et al. - 2015 - Cloud Resource Orchestration Programming Overview.pdf:/home/daniel/Insync/Zotero/storage/NTBTTHD2/Ranjan et al. - 2015 - Cloud Resource Orchestration Programming Overview.pdf:application/pdf}
}

@article{hameed-survey:2016,
  author   = {Hameed, Abdul And Khoshkbarforoushha, Alireza And Ranjan, Rajiv And Jayaraman, Prem Prakash And Kolodziej, Joanna And Balaji, Pavan And Zeadally, Sherali And Malluhi, Qutaibah Marwan And Tziritas, Nikos And Vishnu, Abhinav And Khan, Samee U. And Zomaya, Albert},
  title    = {A Survey And Taxonomy On Energy Efficient Resource Allocation Techniques For Cloud Computing Systems},
  journal  = {Computing},
  year     = {2016},
  volume   = {98},
  number   = {7},
  pages    = {751--774},
  abstract = {In A Cloud Computing Paradigm, Energy Efficient Allocation Of Different Virtualized Ict Resources (servers, Storage Disks, And Networks, And The Like) Is A Complex Problem Due To The Presence Of Heterogeneous Application (e.g., Content Delivery Networks, Mapreduce, Web Applications, And The Like) Workloads Having Contentious Allocation Requirements In Terms Of Ict Resource Capacities (e.g., Network Bandwidth, Processing Speed, Response Time, Etc.). Several Recent Papers Have Tried To Address The Issue Of Improving Energy Efficiency In Allocating Cloud Resources To Applications With Varying Degree Of Success. However, To The Best Of Our Knowledge There Is No Published Literature On This Subject That Clearly Articulates The Research Problem And Provides Research Taxonomy For Succinct Classification Of Existing Techniques. Hence, The Main Aim Of This Paper Is To Identify Open Challenges Associated With Energy Efficient Resource Allocation. In This Regard, The Study, First, Outlines The Problem And Existing Hardware And Software-based Techniques Available For This Purpose. Furthermore, Available Techniques Already Presented In The Literature Are Summarized Based On The Energy-efficient Research Dimension Taxonomy. The Advantages And Disadvantages Of The Existing Techniques Are Comprehensively Analyzed Against The Proposed Research Dimension Taxonomy Namely: Resource Adaption Policy, Objective Function, Allocation Method, Allocation Operation, And Interoperability.},
  doi      = {10.1007/s00607-014-0407-8},
  issn     = {0010-485X, 1436-5057},
  keywords = {68u01, Cloud Computing, Energy Consumption, Energy Efficiency, Energy Efficient Resource Allocation, Power Management},
  langid   = {English},
  urldate  = {2016-08-18}
}

@article{sun-energy-efficient:2014,
  author     = {Sun, Hongyang And Stolf, Patricia And Pierson, Jean-marc And Da Costa, Georges},
  title      = {Energy-efficient And Thermal-aware Resource Management For Heterogeneous Datacenters},
  journal    = {Sustainable Computing: Informatics And Systems},
  year       = {2014},
  volume     = {4},
  number     = {4},
  pages      = {292--306},
  abstract   = {We Propose In This Paper To Study The Energy-, Thermal- And Performance-aware Resource Management In Heterogeneous Datacenters. Witnessing The Continuous Development Of Heterogeneity In Datacenters, We Are Confronted With Their Different Behaviors In Terms Of Performance, Power Consumption And Thermal Dissipation: Indeed, Heterogeneity At Server Level Lies Both In The Computing Infrastructure (computing Power, Electrical Power Consumption) And In The Heat Removal Systems (different Enclosure, Fans, Thermal Sinks). Also The Physical Locations Of The Servers Become Important With Heterogeneity Since Some Servers Can (over)heat Others. While Many Studies Address Independently These Parameters (most Of The Time Performance And Power Or Energy), We Show In This Paper The Necessity To Tackle All These Aspects For An Optimal Resource Management Of The Computing Resources. This Leads To Improved Energy Usage In A Heterogeneous Datacenter Including The Cooling Of The Computer Rooms. We Build Our Approach On The Concept Of Heat Distribution Matrix To Handle The Mutual Influence Of The Servers, In Heterogeneous Environments, Which Is Novel In This Context. We Propose A Heuristic To Solve The Server Placement Problem And We Design A Generic Greedy Framework For The Online Scheduling Problem. We Derive Several Single-objective Heuristics (for Performance, Energy, Cooling) And A Novel Fuzzy-based Priority Mechanism To Handle Their Tradeoffs. Finally, We Show Results Using Extensive Simulations Fed With Actual Measurements On Heterogeneous Servers.},
  doi        = {10.1016/j.suscom.2014.08.005},
  eprint     = {1410.3104},
  eprinttype = {Arxiv},
  issn       = {2210-5379},
  keywords   = {Computer Science - Distributed, Parallel, And Cluster Computing},
  url        = {http://arxiv.org/abs/1410.3104},
  urldate    = {2016-09-21}
}

@inproceedings{crago-heterogeneous:2011,
  author     = {Crago, S. And Dunn, K. And Eads, P. And Hochstein, L. And Kang, D. I. And Kang, M. And Modium, D. And Singh, K. And Suh, J. And Walters, J. P.},
  title      = {Heterogeneous Cloud Computing},
  booktitle  = {2011 IEEE International Conference On Cluster Computing},
  year       = {2011},
  pages      = {378--385},
  abstract   = {Current Cloud Computing Infrastructure Typically Assumes A Homogeneous Collection Of Commodity Hardware, With Details About Hardware Variation Intentionally Hidden From Users. In This Paper, We Present Our Approach For Extending The Traditional Notions Of Cloud Computing To Provide A Cloud-based Access Model To Clusters That Contain A Heterogeneous Architectures And Accelerators. We Describe Our Ongoing Work Extending The Open Stack Cloud Computing Stack To Support Heterogeneous Architectures And Accelerators, And Our Experiences Running Open Stack On Our Local Heterogeneous Cluster Testbed.},
  doi        = {10.1109/CLUSTER.2011.49},
  eventtitle = {2011 IEEE International Conference On Cluster Computing},
  keywords   = {Accelerators, Cloud-based Access Model, Cloud Computing, Commodity Hardware, Computer Architecture, Graphics Processing Unit, Hardware, Heterogeneous Architectures, Heterogeneous Cloud Computing, Heterogeneous Cluster, High-performance Computing, Homogeneous Collection, Libraries, Open Stack Cloud Computing Stack, Servers, Virtual Machining}
}

@book{salam-deploying:2015,
  title      = {Deploying And Managing A Cloud Infrastructure: Real-world Skills For The Comptia Cloud+ Certification And Beyond: Exam Cv0-001},
  publisher  = {John Wiley \& Sons},
  year       = {2015},
  author     = {Salam, Abdul And Gilani, Zafar And Haq, Salman Ul},
  abstract   = {Learn In-demand Cloud Computing Skills From Industry Experts Deploying And Managing A Cloud Infrastructure Is An Excellent Resource For It Professionals Seeking To Tap Into The Demand For Cloud Administrators. This Book Helps Prepare Candidates For The Comptia Cloud+ Certification (cv0-001) Cloud Computing Certification Exam. Designed For It Professionals With 2-3 Years Of Networking Experience, This Certification Provides Validation Of Your Cloud Infrastructure Knowledge. With Over 30 Years Of Combined Experience In Cloud Computing, The Author Team Provides The Latest Expert Perspectives On Enterprise-level Mobile Computing, And Covers The Most Essential Topics For Building And Maintaining Cloud-based Systems, Including: Understanding Basic Cloud-related Computing Concepts, Terminology, And Characteristics Identifying Cloud Delivery Solutions And Deploying New Infrastructure Managing Cloud Technologies, Services, And Networks Monitoring Hardware And Software Performance Featuring Real-world Examples And Interactive Exercises, Deploying And Managing Cloud Infrastructure Delivers Practical Knowledge You Can Apply Immediately. And, In Addition, You Also Get Access To A Full Set Of Electronic Study Tools Including: Interactive Test Environment Electronic Flashcards Glossary Of Key Terms Now Is The Time To Learn The Cloud Computing Skills You Need To Take That Next Step In Your It Career.},
  isbn       = {978-1-118-87529-2},
  keywords   = {Computers / Certification Guides / General, Computers / Networking / General},
  langid     = {English},
  pagetotal  = {458},
  shorttitle = {Deploying And Managing A Cloud Infrastructure}
}

@article{jiang-survey:2016,
  author   = {Jiang, Y.},
  title    = {A Survey Of Task Allocation And Load Balancing In Distributed Systems},
  journal  = {IEEE Transactions On Parallel And Distributed Systems},
  year     = {2016},
  volume   = {27},
  number   = {2},
  pages    = {585--599},
  abstract = {In Past Decades, Significant Attention Has Been Devoted To The Task Allocation And Load Balancing In Distributed Systems. Although There Have Been Some Related Surveys About This Subject, Each Of Which Only Made A Very Preliminary Review On The State Of Art Of One Single Type Of Distributed Systems. To Correlate The Studies In Varying Types Of Distributed Systems And Make A Comprehensive Taxonomy On Them, This Survey Mainly Categorizes And Reviews The Representative Studies On Task Allocation And Load Balancing According To The General Characteristics Of Varying Distributed Systems. First, This Survey Summarizes The General Characteristics Of Distributed Systems. Based On These General Characteristics, This Survey Reviews The Studies On Task Allocation And Load Balancing With Respect To The Following Aspects: 1) Typical Control Models; 2) Typical Resource Optimization Methods; 3) Typical Methods For Achieving Reliability; 4) Typical Coordination Mechanisms Among Heterogeneous Nodes; And 5) Typical Models Considering Network Structures. For Each Aspect, We Summarize The Existing Studies And Discuss The Future Research Directions. Through The Survey, The Related Studies In This Area Can Be Well Understood Based On How They Can Satisfy The General Characteristics Of Distributed Systems.},
  doi      = {10.1109/TPDS.2015.2407900},
  issn     = {1045-9219},
  keywords = {Computational Modeling, Control Models, Coordination Mechanisms, Distributed Processing, Distributed Systems, Heterogeneous Nodes, Load Balancing, Load Management, Load Modeling, Network, Networks, Peer-to-peer Computing, Reliability, Resource Allocation, Resource Management, Resource Optimization Methods, Survey, Task Allocation, Task Analysis, Taxonomy, Time Factors}
}

@article{maier-resource:1998,
  author   = {Maier, Ursula And Stellner, Georg And Zoraja, Ivan},
  title    = {Resource Allocation, Scheduling And Load Balancing Based On The Pvm Resource Manager},
  journal  = {Advances In Parallel Computing},
  year     = {1998},
  volume   = {12},
  pages    = {711--718},
  abstract = {This Work Describes Some Concepts How To Use The Pvm Resource Manager Interface To Implement A Resource Management System For Pvm Applications In A Network Of Workstations (now). The Basic Implementation Of A Pvm Resource Manager Has Been Extended By A Variety Of Functions To Define Strategies For Resource Allocation And Scheduling Of Pvm Applications. The Users Of Pvm Applications Benefit From The Improved User-friendliness And Efficiency In Resource Utilization.11 This Work Has Been Funded By The German Federal Department Of Education, Science, Research And Technology, Bmbp (bundesministerium F{\"{u}}r Bildung, Wissenschaft, Forschung Und Technologie) Within The Research Project Sempa (software Engineering Methods For Parallel Applications In Scientific Computing).},
  series   = {Parallel Computingfundamentals, Applications And New Directions},
  url      = {http://www.sciencedirect.com/science/article/pii/S0927545298800932},
  urldate  = {2016-08-28}
}

@Report{ashrae-90-ashrae:2016,
  author      = {Ashrae-90},
  title       = {Ashrae Std 90.4 - Energy Standard For Data Centers Textbar Engineering360},
  year        = {2016},
  abstract    = {Scope: This Standard Applies To: A. New Data Centers, Or Portions Thereof, And Their Systems; B. New Additions To Data Centers, Or Portions Thereof, And Their Systems; C. And Modifications To Systems And Equipment In Existing Data Centers Or Portions Thereof. The Provisions Of This Standard Do Not Apply To A. Telephone Exchanges, B. Essential Facilities, And C. Information Technology Equipment (ite). Where Specifically Noted In This Standard, Certain Other Buildings Or Elements Of Buildings Shall Be Exempt. This Standard Shall Not Be Used To Circumvent Any Safety, Health, Or Environmental Requirements. Purpose: The Purpose Of This Standard Is To Establish The Minimum Energy Efficiency Requirements Of Data Centers For A. Design, Construction, And A Plan For Operation And Maintenance; And B. Utilization Of On-site Or Off-site Renewable Energy Resources.},
  institution = {American Society Of Heating, Refrigerating And Air-conditioning Engineers - ({ASHRAE}\)},
  langid      = {English},
  location    = {Usa},
  number      = {90.4},
  pages       = {62},
  type        = {Standard},
  url         = {http://standards.globalspec.com/standards/detail?docid=10037704&familyid=YMFERFAAAAAAAAAA},
  urldate     = {2016-09-07}
}

@Report{ansi-bicsi:2014,
  author      = {Ansi/bicsi-002},
  title       = {Ansi/bicsi 002-2014, Data Center Design And Implementation Best Practices},
  year        = {2014},
  abstract    = {Considered The Foundation Standard For Data Center Design Around The World, Ansi/bicsi 002-2014 Continues Its Mission To Provide Requirements, Guidelines And Best Practices Applicable To Any Data Center. Now Featuring 500 Pages Of Content, The 2014 Edition Of Bicsi 002 Focused On Adding Or Expanding Information On: The Bicsi Availability Class Structure For All Major Aspects Of Data Centers; Modular And Container Data Centers; Dcim And Building Systems; Dc Power Hot And Cold Aisles; Multi-data Center Architecture And Data Center Service Outsourcing; Energy Efficiency. While A Focus Was Made On These And Other Recent Developments, The International Team Of Over 50 Experts From All Disciplines Within Data Centers Also Reviewed The Existing Content To Reflect Changes And Developments In The Major Data Center Markets.},
  institution = {Bicsi},
  langid      = {English},
  location    = {Usa},
  number      = {002-2014},
  pages       = {500},
  type        = {Standard},
  url         = {https://www.bicsi.org/book_details.aspx?Book=BICSI-002-CM-14-v5&d=0},
  urldate     = {2016-09-07}
}

@Online{sgs-group-sgs:2016,
  author     = {Sgs Group},
  title      = {Sgs Group},
  year       = {2016},
  abstract   = {A Sgs {\'{e}} L{\'{i}}der Mundial Em Inspe{\c{c}}{\~{a}}o, Verifica{\c{c}}{\~{a}}o, Testes E Certifica{\c{c}}{\~{a}}o. Somos Reconhecidos Como Refer{\^{e}}ncia Mundial Em Qualidade E Integridade.},
  titleaddon = {Sgs Group},
  type       = {Corporativo},
  url        = {http://www.sgsgroup.com.br/},
  urldate    = {2016-09-20}
}

@inproceedings{rizzon-decision:2015,
  author    = {Rizzon, Bastien And Clivill{\'{e}}, Vincent And Galichet, Sylvie And Ochalek, Pascal And Ratajczak, Elodie},
  title     = {Decision Problem Of Instrumentation In A Company Involved In Iso 50001},
  booktitle = {Industrial Engineering And Systems Management (iesm), 2015},
  year      = {2015},
  pages     = {409--416},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7380190},
  urldate   = {2016-09-22}
}

@Online{jason-green:2014,
  author     = {Verge , Jason},
  title      = {The Green Grid Unveils Energy Productivity Metric For Data Centers},
  year       = {2014},
  abstract   = {The Green Grid Has Finally Reached Consensus On A Metric More Than Five Years In The Making: Data Center Energy Productivity, Or Dcep, Is Computed As Useful Work Produced Divided By Total Energy Consumed By The Data Center. Dcep Allows Each User To Define Useful Work As Applicable To The User{\textquoteright}s Business. Read More},
  year       = {2014-03-20},
  titleaddon = {Data Center Knowledge},
  url        = {http://www.datacenterknowledge.com/archives/2014/03/20/green-grid-unveils-energy-productivity-metric-data-centers/},
  urldate    = {2016-06-24}
}

@Report{shehabi-united:2016,
  author      = {Shehabi, Arman},
  title       = {United States Data Center Energy Usage Report},
  year        = {2016},
  abstract    = {Textlessptextgreaterthis Report Estimates Historical Data Center Electricity Consumption Back To 2000, Relying On Previous Studies And Historical Shipment Data, And Forecasts Consumption Out To 2020 Based On New Trends And The Most Recent Data Available. In 2014, Data Centers In The U.s. Consumed An Estimated 70 Billion Kwh, Representing About 1.8% Of Total U.s. Electricity Consumption. This Report Shows That Data Center Electricity Consumption Increased By About 4% From 2010-2014, A Large Shift From The 24% Percent Increase Estimated From 2005-2010 And The Nearly 90% Increase Estimated From 2000-2005. Energy Use Is Expected To Continue Slightly Increasing In The Near Future, Increasing 4% From 2014-2020, The Same Rate As The Past Five Years. Based On Current Trend Estimates, U.s. Data Centers Are Projected To Consume Approximately 73 Billion Kwh In 2020. A Combination Of Efficiency Trends Has Resulted In A Relatively Steady U.s Data Center Electricity Demand Over The Past 5 Years, With Little Growth Expected For The Remainder Of This Decade. Along With The Energy Efficiency Resource Already Achieved, There Are Additional Energy Efficiency Strategies And Technologies That Could Significantly Reduce Data Center Electricity Use Below The Approximately 73 Billion Kwh Demand Projected In 2020. Many Of These Efficiency Strategies Are Already Successfully Employed In Some Data Centers While Others Are Emerging Technologies That Will Be Commercially Available In The Near Future. The Potential Impact From An Adoption Of Additional Energy Efficiency Strategies Is Explored, Which Estimate An Annual Saving In 2020 Up To 33 Billion Kwh, Representing A 45% Reduction In Electricity Demand When Compared To Current Efficiency Trends.textless/ptextgreater},
  year        = {2016-06},
  institution = {United States Departament Of Energy},
  keywords    = {Data Center, Energy Efficiency, Information Technology},
  type        = {Techreport}
}

@book{ahmad-handbook:2016,
  title     = {Handbook Of Energy-aware And Green Computing - Two Volume Set},
  publisher = {Crc Press},
  year      = {2016},
  author    = {Ahmad, Ishfaq And Ranka, Sanjay},
  abstract  = {Implementing Energy-efficient Cpus And Peripherals As Well As Reducing Resource Consumption Have Become Emerging Trends In Computing. As Computers Increase In Speed And Power, Their Energy Issues Become More And More Prevalent. The Need To Develop And Promote Environmentally Friendly Computer Technologies And Systems Has Also Come To The Forefront In Computing Research. A Pioneering Publication For Researchers In Computer Science And Engineering, Handbook Of Energy-aware And Green Computing, Two-volume Set Is One Of The First To Present A Comprehensive Account Of Recent Research In Energy-aware And Green Computing. Edited By The Co-chairs Of The International Green Computing Conference, This Handbook Incorporates Fundamental Knowledge From All Related Areas, Including Circuit And Component Design, Software, Operating Systems, Networking, Mobile Computing, And Data Centers. It Also Discusses Up-to-date Research On Many Aspects Of Power-aware Computing At The Component, Software, And System Levels.},
  isbn      = {978-1-4822-5444-0},
  keywords  = {Computers / Computer Engineering, Computers / General, Mathematics / General, Technology & Engineering / Environmental / General, Technology & Engineering / Power Resources / Alternative & Renewable},
  langid    = {English},
  pagetotal = {1216}
}

@article{cherrafi-integration:2016,
  author     = {Cherrafi, Anass And Elfezazi, Said And Chiarini, Andrea And Mokhlis, Ahmed And Benhida, Khalid},
  title      = {The Integration Of Lean Manufacturing, Six Sigma And Sustainability: A Literature Review And Future Research Directions For Developing A Specific Model},
  journal    = {Journal Of Cleaner Production},
  year       = {2016},
  volume     = {139},
  pages      = {828--846},
  abstract   = {The Purpose Of This Paper Is To Present A Review And An Analysis Of The Literature Concerning A Possible Model For Integrating Three Management Systems: Lean Manufacturing, Six Sigma And Sustainability. In Particular, We Analyzed Current Proposals And Identified At The Same Time Gaps In The Existing Literature From Which We Suggested Future Research Directions For Developing A Specific Integrated Model, Suggesting New Opportunities And Challenges That Should Be Addressed By Future Studies. Both Academicians And Practitioners Will Find Our Review Useful Because It Outlines The Major Lines Of Research In The Field And Their Limitations.},
  doi        = {10.1016/j.jclepro.2016.08.101},
  issn       = {0959-6526},
  keywords   = {Integrated Model, Lean, Literature Review, Six Sigma, Sustainability},
  shorttitle = {The Integration Of Lean Manufacturing, Six Sigma And Sustainability},
  url        = {http://www.sciencedirect.com/science/article/pii/S0959652616312495},
  urldate    = {2016-09-21}
}

@article{patel-survey:2016,
  author  = {Patel, Suruchi Dilipbhai And Vaghela, Dinesh},
  title   = {A Survey Paper On Load Balancing Algorithms For Resource Management In Virtualization},
  journal = {International Journal For Innovative Research In Science And Technology},
  year    = {2016},
  volume  = {2},
  number  = {11},
  pages   = {68--70},
  url     = {http://www.ijirst.org/Article.php?manuscript=IJIRSTV2I11013},
  urldate = {2016-08-15}
}

@article{ullman-np-complete:1975,
  author   = {Ullman, J. D.},
  title    = {Np-complete Scheduling Problems},
  journal  = {J. Comput. Syst. Sci.},
  year     = {1975},
  volume   = {10},
  number   = {3},
  pages    = {384--393},
  abstract = {We Show That The Problem Of Finding An Optimal Schedule For A Set Of Jobs Is Np-complete Even In The Following Two Restricted Cases.o(1)all Jobs Require One Time Unit. (2)all Jobs Require One Or Two Time Units, And There Are Only Two Processor Resolving (in The Negative A Conjecture Of R. L. Graham, Proc. Sjcc, 1972, Pp. 205-218). As A Consequence, The General Preemptive Scheduling Problem Is Also Np-complete. These Results Are Tantamount To Showing That The Scheduling Problems Mentioned Are Intractable.},
  doi      = {10.1016/S0022-0000(75)80008-0},
  issn     = {0022-0000},
  urldate  = {2016-08-28}
}

@Report{iso/iec-24764-iso/iec:2015,
  author      = {Iso/iec-24764},
  title       = {Iso/iec 24764:2010 - Information Technology -- Generic Cabling Systems For Data Centres},
  year        = {2015},
  abstract    = {Iso/iec 24764:2010(e) Specifies Generic Cabling That Supports A Wide Range Of Communications Services For Use Within A Data Centre. It Covers Balanced Cabling And Optical Fibre Cabling. It Is Based Upon And References The Requirements Of Iso/iec 11801 And Contains Additional Requirements That Are Appropriate To Data Centres In Which The Maximum Distance Over Which Communications Services Have To Be Distributed Is 2 000 M.},
  institution = {Ansi/bicsi},
  langid      = {English},
  location    = {Usa},
  number      = {Iso/iec Jtc 1/sc 25},
  pages       = {37},
  shorttitle  = {Iso/iec 24764},
  type        = {Standard},
  url         = {http://www.iso.org/iso/home/store/catalogue_tc/catalogue_detail.htm?csnumber=43520},
  urldate     = {2016-09-07}
}

@inproceedings{cascella-energy:2016,
  author     = {Cascella, G. L. And Cupertino, F. And Davide, C.},
  title      = {Energy Metering Optimization In Flour Mill Plants For Iso 50001 Implementation},
  booktitle  = {2016 IEEE Workshop On Environmental, Energy, And Structural Monitoring Systems (eesms)},
  year       = {2016},
  pages      = {1--5},
  publisher  = {IEEE},
  abstract   = {This Paper Proposes An Innovative Strategy To Optimize The Energy Metering In Large And Energy-consuming Plants Such As Industrial Flour Mills. The Proposed Solution Deals With Iso 50001 Implementation Which Represents A Critical Challenge For Many Companies Because The Benefits Due To Improvements In Energy Management Could Be Potentially Canceled By The Costs Of An Energy Management System (enms). In Particular, The Key Performance Indexes (kpis) Monitoring Is A Crucial Activity For Several Reasons: It Is One Of The Early Activities, It Affects The Measurement Quality Of Kpis And It Deeply Impacts The Enms Requirements And, Consequently, The Investment Valuations. The Proposed Strategy Supports The Energy Managers In The Design Of The Energy Monitoring System Suggesting The Points Of The Electrical Network To Be Equipped With Sensors And Monitored. Moreover, The Paper Describes The Results Carried Out In A Real-world Application: The Energy Sensor Network Of A 1.2mw Flour Mill Plant Sited In Italy Has Been Designed And Implemented With The Proposed Innovative Solution.},
  doi        = {10.1109/EESMS.2016.7504810},
  eventtitle = {2016 IEEE Workshop On Environmental, Energy, And Structural Monitoring Systems (eesms)},
  keywords   = {Energy-consuming Plants, Energy Consumption, Energy Efficiency, Energy Management, Energy Management System, Energy Management Systems, Energy Metering Optimization, Energy Sensor Network, Flour Mill Plants, Food Processing Industry, Industrial Flour Mills, Industrial Plants, Innovative, Iso 50001, Iso Standards, Key Performance Indexes, Monitoring, Optimization, Power 1.2 Mw, Power Measurement, Power Meters, Production, Sensors},
  url        = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7504810}
}

@inproceedings{samarakoon-enablers:2013,
  author     = {Samarakoon, S.b.r.g.k. And Rajini, P.a.d.},
  title      = {Enablers And Barriers Of Implementing Iso 50001- Energy Management Systems (enms) In Sri Lankan Context.},
  booktitle  = {Socio-economic Sustainability In Construction: Practice, Policy And Research},
  year       = {2013},
  volume     = {2},
  pages      = {208--217},
  eventtitle = {The Second World Construction Symposium},
  langid     = {American},
  location   = {Colombo, Sri Lanka},
  url        = {http://www.irbnet.de/daten/iconda/CIB_DC26715.pdf},
  urldate    = {2016-09-20}
}

@article{tang-energy-efficient:2008,
  author     = {Tang, Q. And Gupta, S. K. S. And Varsamopoulos, G.},
  title      = {Energy-efficient Thermal-aware Task Scheduling For Homogeneous High-performance Computing Data Centers: A Cyber-physical Approach},
  journal    = {IEEE Transactions On Parallel And Distributed Systems},
  year       = {2008},
  volume     = {19},
  number     = {11},
  pages      = {1458--1472},
  abstract   = {High-performance Computing Data Centers Have Been Rapidly Growing, Both In Number And Size. Thermal Management Of Data Centers Can Address Dominant Problems Associated With Cooling Such As The Recirculation Of Hot Air From The Equipment Outlets To Their Inlets And The Appearance Of Hot Spots. In This Paper, We Show Through Formalization That Minimizing The Peak Inlet Temperature Allows For The Lowest Cooling Power Needs. Using A Low-complexity Linear Heat Recirculation Model, We Define The Problem Of Minimizing The Peak Inlet Temperature Within A Data Center Through Task Assignment (mpit-ta), Consequently Leading To Minimal Cooling-requirement. We Also Provide Two Methods To Solve The Formulation: Xlnt-ga, Which Uses A Genetic Algorithm, And Xlnt-sqp, Which Uses Sequential Quadratic Programming. Results From Small-scale Data Center Simulations Show That Solving The Formulation Leads To An Inlet Temperature Distribution That, Compared To Other Approaches, Is 2 Degc To 5 Degc Lower And Achieves About 20 To 30 Percent Cooling Energy Savings At Common Data Center Utilization Rates. Moreover, Our Algorithms Consistently Outperform The Minimize Heat Recirculation Algorithm, A Recirculation-reducing Task Placement Algorithm In The Literature.},
  doi        = {10.1109/TPDS.2008.111},
  issn       = {1045-9219},
  keywords   = {Air Conditioning, Computer Centres, Cooling, Cyber-physical Approach, Energy-efficient Thermal-aware Task Scheduling, Evaluation, Genetic Algorithm, Genetic Algorithms, Homogeneous High-performance Computing Data Centers, Measurement, Modeling, Modeling Techniques, Quadratic Programming, Recirculation-reducing Task Placement Algorithm, Scheduling, Sequential Quadratic Programming, Simulation Of Multiple-processor Systems},
  shorttitle = {Energy-efficient Thermal-aware Task Scheduling For Homogeneous High-performance Computing Data Centers}
}

@article{chugani-investigating:2016,
  author     = {Chugani, Nashmi And Kumar, Vikas And Garza-reyes, Jose Arturo And Rocha-lona, Luis And Upadhyay, Arvind},
  title      = {Investigating The Green Impact Of Lean, Six Sigma, And Lean Six Sigma: A Systematic Literature Review},
  journal    = {International Journal Of Lean Six Sigma},
  year       = {2016},
  shorttitle = {Investigating The Green Impact Of Lean, Six Sigma, And Lean Six Sigma},
  url        = {http://derby.openrepository.com/derby/handle/10545/605693},
  urldate    = {2016-09-21}
}

@book{stallings-foundations:2015,
  title      = {Foundations Of Modern Networking: Sdn, Nfv, Qoe, Iot, And Cloud},
  publisher  = {Addison-wesley Professional},
  year       = {2015},
  author     = {Stallings, William},
  abstract   = {Foundations Of Modern Networking Is A Comprehensive, Unified Survey Of Modern Networking Technology And Applications For Today{\textquoteright}s Professionals, Managers, And Students. Dr. William Stallings Offers Clear And Well-organized Coverage Of Five Key Technologies That Are Transforming Networks: Software-defined Networks (sdn), Network Functions Virtualization (nfv), Quality Of Experience (qoe), The Internet Of Things (iot), And Cloudbased Services. {~} Dr. Stallings Reviews Current Network Ecosystems And The Challenges They Face--from Big Data And Mobility To Security And Complexity. Next, He Offers Complete, Self-contained Coverage Of Each New Set Of Technologies: How They Work, How They Are Architected, And How They Can Be Applied To Solve Real Problems. Dr. Stallings Presents A Chapter-length Analysis Of Emerging Security Issues In Modern Networks. He Concludes With An Up-to Date Discussion Of Networking Careers, Including Important Recent Changes In Roles And Skill Requirements. {~} Coverage: {~} Elements Of The Modern Networking Ecosystem: Technologies, Architecture, Services, And Applications Evolving Requirements Of Current Network Environments Sdn: Concepts, Rationale, Applications, And Standards Across Data, Control, And Application Planes Openflow, Opendaylight, And Other Key Sdn Technologies Network Functions Virtualization: Concepts, Technology, Applications, And Software Defined Infrastructure Ensuring Customer Quality Of Experience (qoe) With Interactive Video And Multimedia Network Traffic Cloud Networking: Services, Deployment Models, Architecture, And Linkages To Sdn And Nfv Iot And Fog Computing In Depth: Key Components Of Iot-enabled Devices, Model Architectures, And Example Implementations Securing Sdn, Nfv, Cloud, And Iot Environments Career Preparation And Ongoing Education For Tomorrow{\textquoteright}s Networking Careers {~} Key Features: {~} Strong Coverage Of Unifying Principles And Practical Techniques More Than A Hundred Figures That Clarify Key Concepts Web Support At Williamstallings.com/network/ Qr Codes Throughout, Linking To The Website And Other Resources Keyword/acronym Lists, Recommended Readings, And Glossary Margin Note Definitions Of Key Words Throughout The Text},
  isbn       = {978-0-13-417602-4},
  keywords   = {Computers / Client-server Computing, Computers / Networking / General},
  langid     = {English},
  pagetotal  = {886},
  shorttitle = {Foundations Of Modern Networking}
}

@Report{apc-calculating:2016,
  author      = {{ APC Schneider Electric}},
  title       = {Calculating Total Cooling Requirement For Data Centers - Enterprise Control Systems},
  year        = {2016},
  institution = {{APC Schneider Electric}},
  type        = {Techreport},
  url         = {http://www.datacenterexperts.com/resources/white-papers/cooling-containment-airflow-management/126-calculating-total-cooling-requirement-for-data-centers.html}
}

@Online{bureau-veritas-certificacao-bureau:2016,
  author     = {{Bureau Veritas Certifica{\c{c}}{\~{a}}o}},
  title      = {Bureau Veritas Certifica{\c{c}}{\~{a}}o},
  year       = {2016},
  titleaddon = {Bureau Veritas Certifica{\c{c}}{\~{a}}o},
  type       = {Corporativo},
  url        = {http://www.bureauveritascertification.com.br/},
  urldate    = {2016-09-20}
}

@inproceedings{nuaimi-survey:2012,
  author     = {Nuaimi, K. A. And Mohamed, N. And Nuaimi, M. A. And Al-jaroodi, J.},
  title      = {A Survey Of Load Balancing In Cloud Computing: Challenges And Algorithms},
  booktitle  = {2012 Second Symposium On Network Cloud Computing And Applications (ncca)},
  year       = {2012},
  pages      = {137--142},
  abstract   = {Load Balancing Is Essential For Efficient Operations Indistributed Environments. As Cloud Computing Is Growingrapidly And Clients Are Demanding More Services And Betterresults, Load Balancing For The Cloud Has Become A Veryinteresting And Important Research Area. Many Algorithms Weresuggested To Provide Efficient Mechanisms And Algorithms Forassigning The Client's Requests To Available Cloud Nodes. Theseapproaches Aim To Enhance The Overall Performance Of The Cloudand Provide The User More Satisfying And Efficient Services. Inthis Paper, We Investigate The Different Algorithms Proposed Toresolve The Issue Of Load Balancing And Task Scheduling In Cloudcomputing. We Discuss And Compare These Algorithms To Providean Overview Of The Latest Approaches In The Field.},
  doi        = {10.1109/NCCA.2012.29},
  eventtitle = {2012 Second Symposium On Network Cloud Computing And Applications (ncca)},
  keywords   = {Algorithm Design And Analysis, Classification Algorithms, Client Request, Cloud Computing, Cloud Nodes, Cloud Performance, Cloud Storage, Heuristic Algorithms, Indistributed Environment, Load Balancing, Load Management, Monitoring, Replications, Resource Allocation, Scheduling, Servers, Task Scheduling},
  shorttitle = {A Survey Of Load Balancing In Cloud Computing}
}

@inproceedings{santos-xpbl::2014,
  author     = {Santos, S. C. Dos And Furtado, F. And Lins, W.},
  title      = {Xpbl: A Methodology For Managing Pbl When Teaching Computing},
  booktitle  = {2014 IEEE Frontiers In Education Conference (fie) Proceedings},
  year       = {2014},
  pages      = {1--8},
  publisher  = {IEEE},
  abstract   = {In Order To Exploit The Benefits Of Pbl And Mitigate The Risk Of Failure When Implementing It, The Next (innovative Educational Experience In Technology) Research Group Has Been Working On Methods And Tools Focused On Managing The Pbl Approach As Applied To Computing. In This Context, This Article Proposes A Teaching And Learning Methodology Based On Pbl, Called Xpbl, Consisting Of Elements That Reinforce Pbl Principles, Namely: Real And Relevant Problems; A Practical Environment; An Innovative And Flexible Curriculum; An Authentic Assessment Process; Close Monitoring By Technical Tutors And Process Tutors, And Finally, Professional Practitioners As Teachers And Tutors. Based On These Elements, The Paper Describes The Design Of A Pbl Approach For A Design Course, Grounded On Acquired Knowledge Of Design Content And Past Pbl Experiences In Software Engineering Courses. This Approach Provides An Insightful Guide To Implementing Pbl From Xpbl Methodology, And Provides Instruments Based On Management Techniques Such As 5w2h (what, Why, Who, When, Where, How And How Much) And The Production Of Artifacts To Support The Conception Process Of Courses Based On Pbl.},
  doi        = {10.1109/FIE.2014.7044178},
  eventtitle = {2014 IEEE Frontiers In Education Conference (fie) Proceedings},
  keywords   = {Authentic Assessment Process, Computer Science Education, Context, Design Course, Educational Courses, Flexible Curriculum, Guidelines, Innovative Educational Experience, Learning Methodology, Management Processes, Next, Pbl, Pbl Experiences, Pbl Principles, Planning, Problem-solving, Process Tutors, Research Group, Software, Software Engineering, Software Engineering Courses, Teaching, Teaching And Learning Methodology, Teaching Computing, Technical Tutors, Training, Xpbl Methodology},
  shorttitle = {Xpbl},
  url        = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7044178}
}

@inproceedings{fiedler-energy:2012,
  author     = {Fiedler, T. And Mircea, P. M.},
  title      = {Energy Management Systems According To The Iso 50001 Standard: Challenges And Benefits},
  booktitle  = {2012 International Conference On Applied And Theoretical Electricity (icate)},
  year       = {2012},
  pages      = {1--4},
  publisher  = {IEEE},
  abstract   = {The Transition To Renewable Energy Sources And Energy Efficiency Have Become A Central Topic, Also For The Producing Industry In Romania And All Over Europe. Saving Energy Is On The Agenda For Companies As Well As Facilities And Public Institutions. Energy Efficiency In Companies Can Be Controlled And Systematized In An Energy Management System. The Iso Standard 50001:2011 Enables Companies And Other Institutions To Achieve A Sustainable Energy Reduction By Systematic Energy Controlling, Documentation And Raising The Awareness Of All Personnel Involved. This Paper Presents The Challenges And Benefits Of An Iso 50001 Implementation In An Industrial Environment As Well As The Methodology And Systematic Approach, But Also Tools Such As Energy Controlling Systems And Measurement Equipment Which Are Helpful To Achieve Energetic Transparency.},
  doi        = {10.1109/ICATE.2012.6403411},
  eventtitle = {2012 International Conference On Applied And Theoretical Electricity (icate)},
  keywords   = {Companies, Electricity Supply Industry, Energetic Transparency, Energy Conservation, Energy Controlling System, Energy Efficiency, Energy Management System, Energy Management Systems, Energy Saving, Europe, Industrial Environment, Iso 50001:2011 Standard, Iso Standards, Measurement Equipment, Power Control, Power System Measurement, Public Institution, Renewable Energy Source, Renewable Energy Sources, Romania, Standards Organizations, Sustainable Development, Sustainable Energy Reduction},
  url        = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6403411}
}

@Online{energy-nrel:2016,
  author  = {{National Renewable Energy Laboratory}},
  title   = {Nrel: Energy Analysis - Life Cycle Assessment Harmonization},
  year    = {2016},
  editor  = {National Renewable Energy Laboratory},
  url     = {http://www.nrel.gov/analysis/sustain_lcah.html},
  urldate = {2016-09-08}
}

@inproceedings{liu-line:2010,
  author     = {Liu, S. And Quan, G. And Ren, S.},
  title      = {On-line Scheduling Of Real-time Services For Cloud Computing},
  booktitle  = {2010 6\textsuperscript{th} World Congress On Services},
  year       = {2010},
  pages      = {459--464},
  abstract   = {In This Paper, We Introduce A Novel Utility Accrual Scheduling Algorithm For Real-time Cloud Computing Services. The Real-time Tasks Are Scheduled Non-preemptively With The Objective To Maximize The Total Utility. The Most Unique Characteristic Of Our Approach Is That, Different From The Traditional Utility Accrual Approach That Works Under One Single Time Utility Function (tuf), We Have Two Different Tufs-a Profit Tuf And A Penalty Tuf-associated With Each Task At The Same Time, To Model The Real-time Applications For Cloud Computing That Need Not Only To Reward The Early Completions But Also To Penalize The Abortions Or Deadline Misses Of Real-time Tasks. Our Experimental Results Show That Our Proposed Algorithm Can Significantly Outperform The Traditional Scheduling Algorithms Such As The Earliest Deadline First (edf), The Traditional Utility Accrual Scheduling Algorithm And An Early Scheduling Approach Based On The Similar Model.},
  doi        = {10.1109/SERVICES.2010.109},
  eventtitle = {2010 6\textsuperscript{th} World Congress On Services},
  keywords   = {Biological System Modeling, Cloud Computing, Clouds, Earliest Deadline First, Internet, On-line Scheduling, Online Scheduling, Processor Scheduling, Real-time Service, Real Time Systems, Real-time Systems, Scheduling, Scheduling Algorithm, Single Time Utility Function, Time Utility Functions}
}

@Report{newcombe-2016:2016,
  author      = {Newcombe, Liam And Acton, Mark And Bertoldi, Paolo And Booth, John And Flucker, Sophia And Rouyer, Andre},
  title       = {2016 Best Practice Guidelines For The Eu Code Of Conduct On Data Centre Energy Efficiency},
  year        = {2016},
  abstract    = {This Code Of Conduct Is A Voluntary Initiative Aimed To Bring Interested Stakeholders Together, Including The Coordination Of Other Similar Activities By Manufacturers, Vendors, Consultants And Utilities. Parties Signing Up Will Be Expected To Follow The Intent Of This Code Of Conduct And Abide By A Set Of Agreed Commitments.},
  institution = {European Commission},
  langid      = {American},
  location    = {Joint Research Centre},
  number      = {Version 7.1.2},
  pages       = {50},
  type        = {Policies Master List},
  url         = {http://iet.jrc.ec.europa.eu/energyefficiency/ict-codes-conduct/data-centres-energy-efficiency},
  urldate     = {2016-09-07}
}

@inproceedings{mesbahi-performance:2016,
  author     = {Mesbahi, M. R. And Hashemi, M. And Rahmani, A. M.},
  title      = {Performance Evaluation And Analysis Of Load Balancing Algorithms In Cloud Computing Environments},
  booktitle  = {2016 Second International Conference On Web Research (icwr)},
  year       = {2016},
  pages      = {145--151},
  abstract   = {Distributing The System Workload And Balancing All Incoming Requests Among All Processing Nodes In Cloud Computing Environments Is One Of The Important Challenges In Today Cloud Computing World. Many Load Balancing Algorithms And Approaches Have Been Proposed For Distributed And Cloud Computing Systems. In Addition The Broker Policy For Distributing The Workload Among Different Datacenters In A Cloud Environment Is One Of The Important Factors For Improving The System Performance. In This Paper We Present An Analytical Comparison For The Combinations Of Vm Load Balancing Algorithms And Different Broker Policies. We Evaluate These Approaches By Simulating On Cloudanalyst Simulator And The Final Results Are Presented Based On Different Parameters. The Results Of This Research Specify The Best Possible Combinations.},
  doi        = {10.1109/ICWR.2016.7498459},
  eventtitle = {2016 Second International Conference On Web Research (icwr)},
  keywords   = {Broker Policy, Cloudanalyst Simulator, Cloud Computing, Cloud Computing Environments, Computer Centres, Datacenters, Load Balancing, Load Management, Load Modeling, Performance Analysis, Performance Evaluation, Resource Allocation, Round Robin, Simulation, System Performance Improvement, System Workload Distribution, Time Factors, Virtual Machines, Virtual Machining, Vm Load Balancing Algorithms}
}

@book{denton-learning:2015,
  title     = {Learning Openstack Networking (neutron)},
  publisher = {Packt Publishing Ltd},
  year      = {2015},
  author    = {Denton, James},
  abstract  = {Wield The Power Of Openstack Neutron Networking To Bring Network Infrastructure And Capabilities To Your Cloudabout This Bookthis Completely Up-to-date Edition Will Show You How To Deploy A Cloud On Openstack Using Community-driven Processes. It Includes Rich Examples That Will Help You Understand Complex Networking Topics With Easeunderstand Every Aspect Of Designing, Creating, Customizing, And Maintaining The Core Network Foundation Of An Openstack Cloud Using Openstack Neutron All In One Bookwritten By Best-selling Author James Denton, Who Has More Than 15 Years Of Experience In System Administration And Networking. James Has Experience Of Deploying, Operating, And Maintaining Openstack Clouds And Has Worked With Top Enterprises And Organizationswho This Book Is Forif You Are An Openstack-based Cloud Operator And Administrator Who Is New To Neutron Networking And Wants To Build Your Very Own Openstack Cloud, Then This Book Is For You.prior Networking Experience And A Physical Server And Network Infrastructure Is Recommended To Follow Along With Concepts Demonstrated In The Book.what You Will Learnarchitect And Install The Latest Release Of Openstack On Ubuntu Linux 14.04 Ltsreview The Components Of Openstack Networking, Including Plugins, Agents, And Services, And Learn How They Work Together To Coordinate Network Operationsbuild A Virtual Switching Infrastructure Using Reference Architectures Based On Ml2 + Open Vswitch Or Ml2 + Linuxbridgecreate Networks, Subnets, And Routers That Connect Virtual Machine Instances To The Networkdeploy Highly Available Routers Using Dvr Or Vrrp-based Methodsscale Your Application With Haproxy And Load Balancing As-a-serviceimplement Port And Router-level Security Using Security Groups And Firewall As-a-serviceprovide Connectivity To Tenant Networks With Virtual Private Networking As-a-service (vpnaas)find Out How To Manage Openstack Networking Resources Using Cli And Gui-driven Methodsin Detailopenstack Neutron Is An Openstack Component That Provides Networking As A Service For Other Openstack Services To Architect Networks And Create Virtual Machines Through Its Api. This Api Lets You Define Network Connectivity In Order To Leverage Network Capabilities To Cloud Deployments.through This Practical Book, You Will Build A Strong Foundational Knowledge Of Neutron, And Will Architect And Build An Openstack Cloud Using Advanced Networking Features.we Start With An Introduction To Openstack Neutron And Its Various Components, Including Virtual Switching, Routing, Fwaas, Vpnaas, And Lbaas. You'll Also Get Hands-on By Installing Openstack And Neutron And Its Components, And Use Agents And Plugins To Orchestrate Network Connectivity And Build A Virtual Switching Infrastructure.moving On, You'll Get To Grips With The Ha Routing Capabilities Utilizing Vrrp And Distributed Virtual Routers In Neutron. You'll Also Discover Load Balancing Fundamentals, Including The Difference Between Nodes, Pools, Pool Members, And Virtual Ips. You'll Discover The Purpose Of Security Groups And Learn How To Apply The Security Concept To Your Cloud/tenant/instance.finally, You'll Configure Virtual Private Networks That Will Allow You To Avoid The Use Of Snat And Floating Ips When Connecting To Remote Networks.style And Approachthis Easy-to-follow Guide On Networking In Openstack Follows A Step-by-step Process To Installing Openstack And Configuring The Base Networking Components. Each Major Networking Component Has A Dedicated Chapter That Will Build On Your Experience Gained From Prior Chapters.},
  isbn      = {978-1-78528-079-5},
  keywords  = {Computers / Cloud Computing, Computers / Networking / General, Computers / System Administration / General},
  langid    = {English},
  pagetotal = {462}
}

@article{aruna-survey:2013,
  author  = {Aruna, M. And Bhanu, D. And Punithagowri, R.},
  title   = {A Survey On Load Balancing Algorithms In Cloud Environment},
  journal = {International Journal Of Computer Applications},
  year    = {2013},
  volume  = {82},
  number  = {16},
  pages   = {39--43},
  doi     = {10.5120/14251-2472},
  issn    = {0975-8887},
  url     = {http://research.ijcaonline.org/volume82/number16/pxc3892472.pdf},
  urldate = {2016-08-18}
}

@inproceedings{enokido-energy-efficient:2016,
  author     = {Enokido, T. And Takizawa, M.},
  title      = {An Energy-efficient Load Balancing Algorithm For Virtual Machine Environments To Perform Communication Type Application Processes},
  booktitle  = {2016 IEEE 30\textsuperscript{th} International Conference On Advanced Information Networking And Applications (aina)},
  year       = {2016},
  pages      = {392--399},
  abstract   = {Scalable, High Performance, And Fault-tolerant Distributed Applications Are Realized With Virtual Machines In Server Cluster Systems. Application Processes Are Performed On Virtual Machines In Each Server. Processing Load Of Virtual Machines To Perform Application Processes Has To Be Balanced In A Server Cluster System To Satisfy The Application Requirements Like Response Time. On The Other Hand, A Server Cluster System Consumes A Large Amount Of Electric Energy Since Multiple Servers Consume Electric Energy To Perform Application Processes. It Is Critical To Discuss How To Reduce The Total Electric Energy Consumption Of A Server Cluster To Perform Application Processes On Virtual Machines. In Our Previous Studies, The Transmission Model And Power Consumption Model Of A Server To Perform Communication Processes On Multiple Virtual Machines Are Proposed. In This Paper, We Newly Propose The Transmission Energy Consumption Laxity Based (teclb) Algorithm To Allocate Communication Processes To Virtual Machines In A Server Cluster Based On The Proposed Transmission Model And Power Consumption Model Of A Server So That The Total Energy Consumption Of A Server Cluster Can Be Reduced. We Evaluate The Teclb Algorithm In Terms Of The Total Energy Consumption Of A Server Cluster And Transmission Time Of Each Process Compared With The Basic Round-robin (rr) Algorithm. The Evaluation Results Show The Average Total Energy Consumption Of A Server Cluster Is Maximumly Reduced To 9% Of The Rr Algorithm.},
  doi        = {10.1109/AINA.2016.78},
  eventtitle = {2016 IEEE 30\textsuperscript{th} International Conference On Advanced Information Networking And Applications (aina)},
  keywords   = {Basic Round-robin Algorithm, Clustering Algorithms, Communication Process Allocation, Communication Type Application Processes, Distributed Processing, Energy Conservation, Energy Consumption, Energy-efficient Load Balancing Algorithm, Energy-efficient Server Cluster Systems, Fault Tolerance, Fault-tolerant Distributed Applications, Green Computing, Power Consumption, Power Consumption Model, Power Consumption Models, Power Demand, Resource Allocation, Rr Algorithm, Server Cluster Systems, Servers, Teclb Algorithm, Time Factors, Total Electric Energy Consumption, Transmission Energy Consumption Laxity Based Algorithm, Transmission Model, Virtual Machine Environments, Virtual Machines, Virtual Machining}
}

@inproceedings{aslam-load:2015,
  author     = {Aslam, S. And Shah, M. A.},
  title      = {Load Balancing Algorithms In Cloud Computing: A Survey Of Modern Techniques},
  booktitle  = {2015 National Software Engineering Conference (nsec)},
  year       = {2015},
  pages      = {30--35},
  abstract   = {Cloud Computing Has Become Popular Due To Its Attractive Features. The Load On The Cloud Is Increasing Tremendously With The Development Of New Applications. Load Balancing Is An Important Part Of Cloud Computing Environment Which Ensures That All Devices Or Processors Perform Same Amount Of Work In Equal Amount Of Time. Different Models And Algorithms For Load Balancing In Cloud Computing Has Been Developed With The Aim To Make Cloud Resources Accessible To The End Users With Ease And Convenience. In This Paper, We Aim To Provide A Structured And Comprehensive Overview Of The Research On Load Balancing Algorithms In Cloud Computing. This Paper Surveys The State Of The Art Load Balancing Tools And Techniques Over The Period Of 2004-2015. We Group Existing Approaches Aimed At Providing Load Balancing In A Fair Manner. With This Categorization We Provide An Easy And Concise View Of The Underlying Model Adopted By Each Approach.},
  doi        = {10.1109/NSEC.2015.7396341},
  eventtitle = {2015 National Software Engineering Conference (nsec)},
  keywords   = {Algorithms, Classification Algorithms, Cloud Computing, Cloud Computing Environment, Cloud Resource Accessibility, Heuristic Algorithms, Load Balancers, Load Balancing, Load Balancing Algorithm, Load Balancing Techniques, Load Balancing Tools, Load Management, Resource Allocation, Round Robin, Servers, Time Factors},
  shorttitle = {Load Balancing Algorithms In Cloud Computing}
}

@article{cupertino-energy-efficient:2015,
  author     = {Cupertino, Leandro And Da Costa, Georges And Oleksiak, Ariel And Pia{\c{}}tek, Wojciech And Pierson, Jean-marc And Salom, Jaume And Sis{\'{o}}, Laura And Stolf, Patricia And Sun, Hongyang And Zilio, Thomas},
  title      = {Energy-efficient, Thermal-aware Modeling And Simulation Of Data Centers: The Coolemall Approach And Evaluation Results},
  journal    = {Ad Hoc Networks},
  year       = {2015},
  volume     = {25, Part B},
  pages      = {535--553},
  abstract   = {This Paper Describes The Coolemall Project And Its Approach For Modeling And Simulating Energy-efficient And Thermal-aware Data Centers. The Aim Of The Project Was To Address Energy-thermal Efficiency Of Data Centers By Combining The Optimization Of It, Cooling And Workload Management. This Paper Provides A Complete Data Center Model Considering The Workload Profiles, The Applications Profiling, The Power Model And A Cooling Model. Different Energy Efficiency Metrics Are Proposed And Various Resource Management And Scheduling Policies Are Presented. The Proposed Strategies Are Validated Through Simulation At Different Levels Of A Data Center.},
  doi        = {10.1016/j.adhoc.2014.11.002},
  issn       = {1570-8705},
  keywords   = {Data Centers, Energy Efficiency, Metrics, Resource Management Policies, Scheduling},
  langid     = {English},
  series     = {New Research Challenges In Mobile, Opportunistic And Delay-tolerant Networksenergy-aware Data Centers: Architecture, Infrastructure, And Communication},
  shorttitle = {Energy-efficient, Thermal-aware Modeling And Simulation Of Data Centers},
  url        = {http://www.sciencedirect.com/science/article/pii/S1570870514002364},
  urldate    = {2016-08-26}
}

@inproceedings{chen-user-priority:2013,
  author     = {Chen, Huankai And Wang, F. And Helian, N. And Akanmu, G.},
  title      = {User-priority Guided Min-min Scheduling Algorithm For Load Balancing In Cloud Computing},
  booktitle  = {2013 National Conference On Parallel Computing Technologies (parcomptech)},
  year       = {2013},
  pages      = {1--8},
  abstract   = {Cloud Computing Is Emerging As A New Paradigm Of Large-scale Distributed Computing. In Order To Utilize The Power Of Cloud Computing Completely, We Need An Efficient Task Scheduling Algorithm. The Traditional Min-min Algorithm Is A Simple, Efficient Algorithm That Produces A Better Schedule That Minimizes The Total Completion Time Of Tasks Than Other Algorithms In The Literature [7]. However The Biggest Drawback Of It Is Load Imbalanced, Which Is One Of The Central Issues For Cloud Providers. In This Paper, An Improved Load Balanced Algorithm Is Introduced On The Ground Of Min-min Algorithm In Order To Reduce The Makespan And Increase The Resource Utilization (lbimm). At The Same Time, Cloud Providers Offer Computer Resources To Users On A Pay-per-use Base. In Order To Accommodate The Demands Of Different Users, They May Offer Different Levels Of Quality For Services. Then The Cost Per Resource Unit Depends On The Services Selected By The User. In Return, The User Receives Guarantees Regarding The Provided Resources. To Observe The Promised Guarantees, User-priority Was Considered In Our Proposed Pa-lbimm So That User's Demand Could Be Satisfied More Completely. At Last, The Introduced Algorithm Is Simulated Using Matlab Toolbox. The Simulation Results Show That The Improved Algorithm Can Lead To Significant Performance Gain And Achieve Over 20% Improvement On Both Vip User Satisfaction And Resource Utilization Ratio.},
  doi        = {10.1109/ParCompTech.2013.6621389},
  eventtitle = {2013 National Conference On Parallel Computing Technologies (parcomptech)},
  keywords   = {Algorithm Design And Analysis, Cloud Computing, Cloud Task Scheduling, Computer Resources, Large-scale Distributed Computing, Load Balance, Load Balancing, Load Management, Makespan, Mathematics Computing, Matlab Toolbox, Min-min Algorithm, Pa-lbimm, Quality For Services, Quality Of Service, Resource Allocation, Resource Utilization Ratio, Schedules, Scheduling, Scheduling Algorithms, Task Scheduling Algorithm, User-priority Aware, User-priority Guided Min-min Scheduling Algorithm, Vip User Satisfaction}
}

@inproceedings{kroll-software:2013,
  author     = {Kroll, B. And Schriegel, S. And Niggemann, O. And Schramm, S.},
  title      = {A Software Architecture For The Analysis Of Energy And Process-data},
  booktitle  = {2013 IEEE 18\textsuperscript{th} Conference On Emerging Technologies Factory Automation (etfa)},
  year       = {2013},
  pages      = {1--4},
  publisher  = {IEEE},
  abstract   = {This Paper Contributes A Framework That Helps To Fulfill The Requirements Of The Standards Din En 16247 And Iso 50001 By Combining (i) A Synchronized Data Acquisition, (ii) Data Integration, (iii) Learning Of Normal Behavior Models And (iv) A Implementation Of An Anomaly Detection As Prototype. Both Standards Require A Reliable Data Acquisition And Energy Consumption Analysis For Implementing A Certified Energy Management System. It Shows That This Framework Meets The Specifications Of The Standards By Implementing A Combined Data Acquisition And Anomaly Detection Approach.},
  doi        = {10.1109/ETFA.2013.6648146},
  eventtitle = {2013 IEEE 18\textsuperscript{th} Conference On Emerging Technologies Factory Automation (etfa)},
  keywords   = {Anomaly Detection, Automata, Certified Energy Management System, Data Acquisition, Data Integration, Data Models, Din En 16247 Standard, Energy Consumption, Energy Consumption Analysis, Energy Data, Energy Management Systems, Factory Automation, Industries, Iso 50001standard, Iso Standards, Learning Automata, Normal Behavior Model Learning, Process Data, Reliable Data Acquisition, Software Architecture, Synchronisation, Synchronization, Synchronized Data Acquisition},
  url        = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6648146}
}

@article{xu-survey:2016,
  author     = {Xu, Minxian And Tian, Wenhong And Buyya, Rajkumar},
  title      = {A Survey On Load Balancing Algorithms For Vm Placement In Cloud Computing},
  journal    = {Distributed, Parallel, And Cluster Computing (cs.dc)},
  year       = {2016},
  abstract   = {The Emergence Of Cloud Computing Based On Virtualization Technologies Brings Huge Opportunities To Host Virtual Resource At Low Cost Without The Need Of Owning Any Infrastructure. Virtualization Technologies Enable Users To Acquire, Configure And Be Charged On Pay-per-use Basis. However, Cloud Data Centers Mostly Comprise Heterogeneous Commodity Servers Hosting Multiple Virtual Machines (vms) With Potential Various Specifications And Fluctuating Resource Usages, Which May Cause Imbalanced Resource Utilization Within Servers That May Lead To Performance Degradation And Service Level Agreements (slas) Violations. To Achieve Efficient Scheduling, These Challenges Should Be Addressed And Solved By Using Load Balancing Strategies, Which Have Been Proved To Be Np-hard Problem. From Multiple Perspectives, This Work Identifies The Challenges And Analyzes Existing Algorithms For Allocating Vms To Pms In Infrastructure Clouds, Especially Focuses On Load Balancing. A Detailed Classification Targeting Load Balancing Algorithms For Vm Placement In Cloud Data Centers Is Investigated And The Surveyed Algorithms Are Classified According To The Classification. The Goal Of This Paper Is To Provide A Comprehensive And Comparative Understanding Of Existing Literature And Aid Researchers By Providing An Insight For Potential Future Enhancements.},
  eprint     = {1607.06269},
  eprinttype = {Arxiv},
  keywords   = {Computer Science - Distributed, Parallel, And Cluster Computing},
  url        = {http://arxiv.org/abs/1607.06269},
  urldate    = {2016-08-16}
}

@article{ganek-dawning:2003,
  author   = {Ganek, A. G. And Corbi, T. A.},
  title    = {The Dawning Of The Autonomic Computing Era},
  journal  = {Ibm Systems Journal},
  year     = {2003},
  volume   = {42},
  number   = {1},
  pages    = {5--18},
  abstract = {This Issue Of The Ibm Systems Journal Explores A Broad Set Of Ideas And Approaches To Autonomic Computing--some First Steps In What We See As A Journey To Create More Self-managing Computing Systems. Autonomic Computing Represents A Collection And Integration Of Technologies That Enable The Creation Of An Information Technology Computing Infrastructure For Ibm's Agenda For The Next Era Of Computing--e-business On Demand. This Paper Presents An Overview Of Ibm's Autonomic Computing Initiative. It Examines The Genesis Of Autonomic Computing, The Industry And Marketplace Drivers, The Fundamental Characteristics Of Autonomic Systems, A Framework For How Systems Will Evolve To Become More Self-managing, And The Key Role For Open Industry Standards Needed To Support Autonomic Behavior In Heterogeneous System Environments. Technologies Explored In Each Of The Papers Presented In This Issue Are Introduced For The Reader.},
  doi      = {10.1147/sj.421.0005},
  issn     = {0018-8670},
  urldate  = {2016-09-13}
}

@book{marinescu-cloud:2013,
  title      = {Cloud Computing: Theory And Practice},
  publisher  = {Newnes},
  year       = {2013},
  author     = {Marinescu, Dan C.},
  abstract   = {Cloud Computing: Theory And Practice Provides Students And It Professionals With An In-depth Analysis Of The Cloud From The Ground Up. Beginning With A Discussion Of Parallel Computing And Architectures And Distributed Systems, The Book Turns To Contemporary Cloud Infrastructures, How They Are Being Deployed At Leading Companies Such As Amazon, Google And Apple, And How They Can Be Applied In Fields Such As Healthcare, Banking And Science. The Volume Also Examines How To Successfully Deploy A Cloud Application Across The Enterprise Using Virtualization, Resource Management And The Right Amount Of Networking Support, Including Content Delivery Networks And Storage Area Networks. Developers Will Find A Complete Introduction To Application Development Provided On A Variety Of Platforms.learn About Recent Trends In Cloud Computing In Critical Areas Such As: Resource Management, Security, Energy Consumption, Ethics, And Complex Systems Get A Detailed Hands-on Set Of Practical Recipes That Help Simplify The Deployment Of A Cloud Based System For Practical Use Of Computing Clouds Along With An In-depth Discussion Of Several Projectsunderstand The Evolution Of Cloud Computing And Why The Cloud Computing Paradigm Has A Better Chance To Succeed Than Previous Efforts In Large-scale Distributed Computing},
  isbn       = {978-0-12-404641-2},
  keywords   = {Computers / General, Computers / Internet / General, Computers / Networking / General, Computers / Operating Systems / Virtualization, Computers / Systems Architecture / Distributed Systems & Computing, Computers / Systems Architecture / General},
  langid     = {English},
  pagetotal  = {415},
  shorttitle = {Cloud Computing}
}

@article{doyle-strategic:1994,
  author     = {Doyle, John And Green, Rodney},
  title      = {Strategic Choice And Data Envelopment Analysis: Comparing Computers Across Many Attributes},
  journal    = {J Inf Technol},
  year       = {1994},
  volume     = {9},
  number     = {1},
  pages      = {61--69},
  abstract   = {A Linear Programming Approach (data Envelopment Analysis) Is Described To Determine The Relative Merits Of A Set Of Multi-input, Multi-output Systems, In Which More Output For Less Input Is Considered Good. The Method Is Applied To Benchmarks Of Microcomputers, And Is Contrasted With A Multiple Regression Analysis Of The Same Data. It Is Also Argued That The Essence Of Two Opposing Strategic Outlooks Can Be Captured Within The Method.},
  doi        = {10.1057/jit.1994.7},
  issn       = {0268-3962, 1466-4437},
  langid     = {English},
  shorttitle = {Strategic Choice And Data Envelopment Analysis},
  urldate    = {2016-09-27}
}

@article{liu-green:2016,
  author   = {Liu, Qiang And Ma, Yujun And Alhussein, Musaed And Zhang, Yin And Peng, Limei},
  title    = {Green Data Center With Iot Sensing And Cloud-assisted Smart Temperature Control System},
  journal  = {Computer Networks},
  year     = {2016},
  volume   = {101},
  pages    = {104--112},
  abstract = {With The Growing Shortage Of Energy Around The World, Energy Efficiency Is One Of The Most Important Considerations For A Data Center. In This Paper, We Propose A Green Data Center Air Conditioning System Assisted By Cloud Techniques, Which Consists Of Two Subsystems: A Data Center Air Conditioning System And A Cloud Management Platform. The Data Center Air Conditioning System Includes Environment Monitoring, Air Conditioning, Ventilation And Temperature Control, Whereas The Cloud Platform Provides Data Storage And Analysis To Support Upper-layer Applications. Moreover, The Detailed Design And Implementation Are Presented, Including The Dispatch Algorithm For The Temperature Control, Topological Structure Of The Sensor Network, And Framework For The Environment Monitoring Node. A Feasibility Evaluation Is Used To Verify That The Proposed System Can Significantly Reduce The Data Center Energy Consumption Without Degradation In The Cooling Performance.},
  doi      = {10.1016/j.comnet.2015.11.024},
  issn     = {1389-1286},
  keywords = {Air Conditioning, Cloud Computing, Green Data Center, Internet Of Things},
  langid   = {English},
  series   = {Industrial Technologies And Applications For The Internet Of Things},
  url      = {http://linkinghub.elsevier.com/retrieve/pii/S1389128615004739},
  urldate  = {2016-09-30}
}

@article{lee-energy:2010,
  author   = {Lee, Young Choon And Zomaya, Albert Y.},
  title    = {Energy Efficient Utilization Of Resources In Cloud Computing Systems},
  journal  = {J Supercomput},
  year     = {2010},
  volume   = {60},
  number   = {2},
  pages    = {268--280},
  abstract = {The Energy Consumption Of Under-utilized Resources, Particularly In A Cloud Environment, Accounts For A Substantial Amount Of The Actual Energy Use. Inherently, A Resource Allocation Strategy That Takes Into Account Resource Utilization Would Lead To A Better Energy Efficiency; This, In Clouds, Extends Further With Virtualization Technologies In That Tasks Can Be Easily Consolidated. Task Consolidation Is An Effective Method To Increase Resource Utilization And In Turn Reduces Energy Consumption. Recent Studies Identified That Server Energy Consumption Scales Linearly With (processor) Resource Utilization. This Encouraging Fact Further Highlights The Significant Contribution Of Task Consolidation To The Reduction In Energy Consumption. However, Task Consolidation Can Also Lead To The Freeing Up Of Resources That Can Sit Idling Yet Still Drawing Power. There Have Been Some Notable Efforts To Reduce Idle Power Draw, Typically By Putting Computer Resources Into Some Form Of Sleep/power-saving Mode. In This Paper, We Present Two Energy-conscious Task Consolidation Heuristics, Which Aim To Maximize Resource Utilization And Explicitly Take Into Account Both Active And Idle Energy Consumption. Our Heuristics Assign Each Task To The Resource On Which The Energy Consumption For Executing The Task Is Explicitly Or Implicitly Minimized Without The Performance Degradation Of That Task. Based On Our Experimental Results, Our Heuristics Demonstrate Their Promising Energy-saving Capability.},
  doi      = {10.1007/s11227-010-0421-3},
  issn     = {0920-8542, 1573-0484},
  langid   = {English},
  urldate  = {2016-09-30}
}

@article{lunardi-green:2014,
  author     = {Lunardi, Guilherme Lerch And Sim{\~{o}}es, Renata And Frio, Ricardo Saraiva},
  title      = {Green It: An Analysis Of The Main Benefits And Practices Used By Organizations},
  journal    = {Read. Revista Eletr{\^{o}}nica De Administra{\c{c}}{\~{a}}o (porto Alegre)},
  year       = {2014},
  volume     = {20},
  number     = {1},
  pages      = {1--30},
  doi        = {10.1590/S1413-23112014000100001},
  issn       = {1413-2311},
  shorttitle = {Green It},
  url        = {http://www.scielo.br/scielo.php?script=sci_abstract&pid=S1413-23112014000100001&lng=en&nrm=iso&tlng=pt},
  urldate    = {2016-10-04}
}

@article{kumar-heterogeneity:2016,
  author   = {Kumar, Mohan Raj Velayudhan And Raghunathan, Shriram},
  title    = {Heterogeneity And Thermal Aware Adaptive Heuristics For Energy Efficient Consolidation Of Virtual Machines In Infrastructure Clouds},
  journal  = {Journal Of Computer And System Sciences},
  year     = {2016},
  volume   = {82},
  number   = {2},
  pages    = {191--212},
  abstract = {Holistic Datacenter Energy Minimization Operation Should Consider Interactions Between Computing And Cooling Source Specific Usage Patterns. Decisions Like Workload Type, Server Configuration, Load, Utilization Etc., Contributes To Power Consumption And Influences Datacenter's Thermal Profile And Impacts The Energy Required To Control Temperature Within Operational Thresholds. In This Paper, We Present An Adaptive Virtual Machine Placement And Consolidation Approach To Improve Energy Efficiency Of A Cloud Datacenter; Accounting For Server Heterogeneity, Server Processor Low-power Sleep State, State Transition Latency And Integrated Thermal Controls To Maintain Datacenter Within Operational Temperature. Our Proposed Heuristic Approach Reduces Energy Consumption With Acceptable Level Of Performance.},
  doi      = {10.1016/j.jcss.2015.07.005},
  issn     = {0022-0000},
  keywords = {Data Center Energy Efficiency, Iaas Cloud, Processor Sleep States, Processor Sleep State Transition Latency},
  langid   = {English},
  url      = {http://www.sciencedirect.com/science/article/pii/S002200001500080X},
  urldate  = {2016-10-05}
}

@article{beloglazov-taxonomy:2010,
  author     = {Beloglazov, Anton And Buyya, Rajkumar And Lee, Young Choon And Zomaya, Albert},
  title      = {A taxonomy and survey of energy-efficient data centers and cloud computing systems},
  journal    = {Arxiv:1007.0066 [cs]},
  year       = {2010},
  abstract   = {Traditionally, The Development Of Computing Systems Has Been Focused On Performance Improvements Driven By The Demand Of Applications From Consumer, Scientific And Business Domains. However, The Ever Increasing Energy Consumption Of Computing Systems Has Started To Limit Further Performance Growth Due To Overwhelming Electricity Bills And Carbon Dioxide Footprints. Therefore, The Goal Of The Computer System Design Has Been Shifted To Power And Energy Efficiency. To Identify Open Challenges In The Area And Facilitate Future Advancements It Is Essential To Synthesize And Classify The Research On Power And Energy-efficient Design Conducted To Date. In This Work We Discuss Causes And Problems Of High Power / Energy Consumption, And Present A Taxonomy Of Energy-efficient Design Of Computing Systems Covering The Hardware, Operating System, Virtualization And Data Center Levels. We Survey Various Key Works In The Area And Map Them To Our Taxonomy To Guide Future Design And Development Efforts. This Chapter Is Concluded With A Discussion Of Advancements Identified In Energy-efficient Computing And Our Vision On Future Research Directions.},
  eprint     = {1007.0066},
  eprinttype = {Arxiv},
  keywords   = {C.2.4, Computer Science - Distributed, Parallel, And Cluster Computing},
  url        = {http://arxiv.org/abs/1007.0066},
  urldate    = {2016-10-06}
}

@article{akhter-energy:2016,
  author     = {Akhter, Nasrin And Othman, Mohamed},
  title      = {Energy Aware Resource Allocation Of Cloud Data Center: Review And Open Issues},
  journal    = {Cluster Comput},
  year       = {2016},
  volume     = {19},
  number     = {3},
  pages      = {1163--1182},
  abstract   = {The Demand For Cloud Computing Is Increasing Dramatically Due To The High Computational Requirements Of Business, Social, Web And Scientific Applications. Nowadays, Applications And Services Are Hosted On The Cloud In Order To Reduce The Costs Of Hardware, Software And Maintenance. To Satisfy This High Demand, The Number Of Large-scale Data Centers Has Increased, Which Consumes A High Volume Of Electrical Power, Has A Negative Impact On The Environment, And Comes With High Operational Costs. In This Paper, We Discuss Many Ongoing Or Implemented Energy Aware Resource Allocation Techniques For Cloud Environments. We Also Present A Comprehensive Review On The Different Energy Aware Resource Allocation And Selection Algorithms For Virtual Machines In The Cloud. Finally, We Come Up With Further Research Issues And Challenges For Future Cloud Environments.},
  doi        = {10.1007/s10586-016-0579-4},
  issn       = {1386-7857, 1573-7543},
  langid     = {English},
  shorttitle = {Energy Aware Resource Allocation Of Cloud Data Center},
  urldate    = {2016-10-06}
}

@inproceedings{duy-performance:2010,
  author    = {Duy, Truong Vinh Truong And Sato, Yukinori And Inoguchi, Yasushi},
  title     = {Performance Evaluation Of A Green Scheduling Algorithm For Energy Savings In Cloud Computing},
  booktitle = {Parallel \& Distributed Processing, Workshops And Phd Forum (ipdpsw), 2010 IEEE International Symposium On},
  year      = {2010},
  pages     = {1--8},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5470908},
  urldate   = {2016-10-19}
}

@thesis{eun-proactive:2015,
  author      = {Eun, Kyung Lee},
  title       = {Proactive Thermal-aware Management In Cloud Datacenters},
  year        = {2015},
  institution = {Rutgers University-graduate School-new Brunswick},
  type        = {Phdthesis},
  url         = {https://rucore.libraries.rutgers.edu/rutgers-lib/46378/},
  urldate     = {2016-10-19}
}

@inproceedings{guzek-heros:2015,
  author     = {Guzek, Mateusz And Kliazovich, Dzmitry And Bouvry, Pascal},
  title      = {Heros: Energy-efficient Load Balancing For Heterogeneous Data Centers},
  booktitle  = {8\textsuperscript{th} IEEE-CLOUD 2015},
  year       = {2015},
  shorttitle = {Heros},
  url        = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7214113},
  urldate    = {2016-10-20}
}

@book{shirazi-scheduling:1995,
  title     = {Scheduling And Load Balancing In Parallel And Distributed Systems},
  publisher = {Wiley},
  year      = {1995},
  author    = {Shirazi, Behrooz A. And Hurson, Ali R. And Kavi, Krishna M.},
  abstract  = {Advances In Hardware And Software Technologies Have Led To An Increased Interest In The Use Of Large-scale Parallel And Distributed Systems For Database, Real-time, Defense, And Large-scale Commercial Applications. One Of The Biggest System Issues Is Developing Effective Techniques For The Distribution Of Multiple Program Processes On Multiple Processors. This Book Discusses How To Schedule The Processes Among Processing Elements To Achieve The Expected Performance Goals, Such As Minimizing Execution Time, Minimizing Communication Delays, Or Maximizing Resource Utilization. This Book Focuses On The Future Directions Of The Static Scheduling And Dynamic Load Balancing Methods In Parallel And Distributed Systems. It Provides An Overview And A Detailed Discussion On A Wide Range Of Topics From Theoretical Background To Practical, State-of-the-art Scheduling And Load Balancing Techniques. The Book Will Be A Useful Guide To Industry Professionals, Academic Professors, And Students Who Are Interested In These Important Aspects Of Parallel And Distributed Systems. Also, It Will Be Helpful To Those Working On Research And Development In Parallel Processing Applications, Compilers And Operating Systems, System Design, And Software Tools For Parallel Program Development.},
  isbn      = {978-0-8186-6587-5},
  keywords  = {Computers / Computer Engineering, Computers / Networking / General},
  langid    = {English},
  pagetotal = {520}
}

@article{riekstin-orchestration_resumed:2016,
  author       = {Riekstin, A. C. {et. al}},
  title        = {Orchestration of Energy Efficiency Capabilities in Networks},
  journal      = {59th {JNCA} 2015},
  year         = {2016}
}

@article{riekstin-orchestration:2016,
  author       = {Riekstin, Ana C. And Janu{\'{a}}rio, Guilherme C. And Rodrigues, Bruno B. And Nascimento, Viviane T. And Carvalho, Tereza C.m.b. And Meirosu, Catalin},
  title        = {Orchestration Of Energy Efficiency Capabilities In Networks},
  journal      = {Journal Of Network And Computer Applications},
  year         = {2016},
  volume       = {59},
  pages        = {74--87},
  abstract     = {The Energy Demand For Operating Information And Communication Technology (ict) Systems Has Been Growing, Implying In High Operational Costs And Consequent Increase Of Carbon Emissions. Both In Datacenters And Telecom Infrastructures, The Networks Represent A Significant Amount Of Energy Spending. Given That, There Is An Increased Demand For Energy Efficiency Solutions, And Several Capabilities To Save Energy Have Been Proposed. However, It Is Very Difficult To Orchestrate Such Energy Efficiency Capabilities, That Is, Coordinate Or Combine Them In The Same Network, Ensuring A Conflict-free Operation And Choosing The Best One For A Given Scenario, Ensuring That A Capability Not Suited To The Current Bandwidth Utilization Will Not Be Applied And Lead To Congestion Or Packet Loss. There Is Neither A Way To Do This Taking Business Directives Into Account. In This Regard, A Method Able To Orchestrate Different Energy Efficiency Capabilities Is Proposed Considering The Possible Combinations And Conflicts Among Them, As Well As The Best Option For A Given Workload And Network Characteristics. The Business Policies Are Refined Down To The Network Level In Order To Bring High-level Directives Into The Operation, And A Utility Function Is Used To Combine Energy Efficiency And Performance Requirements. A Decision Tree Able To Determine What To Do In Each Scenario Is Deployed In A Software Defined Network Environment. The Proposed Method Was Validated With Different Experiments, Testing The Utility Function, Checking The Extra Savings When Combining Several Capabilities, The Decision Tree Interpolation And Dynamicity Aspects. The Orchestration Proved Valid To Solve The Problem Of Finding The Best Combination For A Given Scenario, Achieving Additional Savings Due To The Combination, Besides Ensuring A Conflict-free Operation. Highlightsa Method Able To Orchestrate Different Energy Efficiency Capabilities Is Proposed.it Considers The Possible Combinations And Conflicts Among The Capabilities.it Refines Business Policies To Bring High-level Directives Into The Operation.the Method Solves The Problem Of Finding The Best Combination For A Given Scenario.and Achieved Additional Savings, Besides Ensuring A Conflict-free Operation.},
  date         = {2016},
  doi          = {10.1016/j.jnca.2015.06.015},
  issn         = {1084-8045},
  issue        = {C},
  journaltitle = {Journal Of Network And Computer Applications},
  keywords     = {Energy Efficiency, Network Management, Networks, Policy Refinement, Sustainability},
  langid       = {English},
  urldate      = {2016-10-24}
}

@article{rodero-energy-efficient:2012,
  author   = {Rodero, Ivan And Viswanathan, Hariharasudhan And Lee, Eun Kyung And Gamell, Marc And Pompili, Dario And Parashar, Manish},
  title    = {Energy-efficient Thermal-aware Autonomic Management Of Virtualized Hpc Cloud Infrastructure},
  journal  = {J Grid Computing},
  year     = {2012},
  volume   = {10},
  number   = {3},
  pages    = {447--473},
  abstract = {Virtualized Datacenters And Clouds Are Being Increasingly Considered For Traditional High-performance Computing (hpc) Workloads That Have Typically Targeted Grids And Conventional Hpc Platforms. However, Maximizing Energy Efficiency And Utilization Of Datacenter Resources, And Minimizing Undesired Thermal Behavior While Ensuring Application Performance And Other Quality Of Service (qos) Guarantees For Hpc Applications Requires Careful Consideration Of Important And Extremely Challenging Tradeoffs. Virtual Machine (vm) Migration Is One Of The Most Common Techniques Used To Alleviate Thermal Anomalies (i.e., Hotspots) In Cloud Datacenter Servers As It Reduces Load And, Hence, The Server Utilization. In This Article, The Benefits Of Using Other Techniques Such As Voltage Scaling And Pinning (traditionally Used For Reducing Energy Consumption) For Thermal Management Over Vm Migrations Are Studied In Detail. As No Single Technique Is The Most Efficient To Meet Temperature/performance Optimization Goals In All Situations, An Autonomic Approach That Performs Energy-efficient Thermal Management While Ensuring The Qos Delivered To The Users Is Proposed. To Address The Problem Of Vm Allocation That Arises During Vm Migrations, An Innovative Application-centric Energy-aware Strategy For Virtual Machine (vm) Allocation Is Proposed. The Proposed Strategy Ensures High Resource Utilization And Energy Efficiency Through Vm Consolidation While Satisfying Application Qos By Exploiting Knowledge Obtained Through Application Profiling Along Multiple Dimensions (cpu, Memory, And Network Bandwidth Utilization). To Support Our Arguments, We Present The Results Obtained From An Experimental Evaluation On Real Hardware Using Hpc Workloads Under Different Scenarios.},
  doi      = {10.1007/s10723-012-9219-2},
  issn     = {1570-7873},
  keywords = {Cloud Infrastructure, Energy-efficiency, Thermal Management, Virtualization},
  langid   = {English},
  urldate  = {2016-10-24}
}

@article{zhang-rescue:2014,
  author     = {Zhang, Quan And Metri, Grace And Raghavan, Sudharsan And Shi, Weisong},
  title      = {Rescue: An Energy-aware Scheduler For Cloud Environments},
  journal    = {Sustainable Computing: Informatics And Systems},
  year       = {2014},
  volume     = {4},
  number     = {4},
  pages      = {215--224},
  doi        = {10.1016/j.suscom.2014.08.008},
  issn       = {2210-5379},
  langid     = {English},
  shorttitle = {Rescue},
  url        = {http://linkinghub.elsevier.com/retrieve/pii/S2210537914000493},
  urldate    = {2016-10-24}
}

@inproceedings{wang-power:2015,
  author    = {Wang, Jing V. And Cheng, Chi-tsun And Chi, K. Tse},
  title     = {A Power And Thermal-aware Virtual Machine Allocation Mechanism For Cloud Data Centers},
  booktitle = {2015 IEEE International Conference On Communication Workshop (iccw)},
  year      = {2015},
  pages     = {2850--2855},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7247611},
  urldate   = {2016-10-24}
}

@mastersThesis{beloglazov-energy-efficient:2013,
  author      = {Beloglazov, Anton},
  title       = {Energy-efficient Management Of Virtual Machines In Data Centers For Cloud Computing},
  year        = {2013},
  institution = {The University Of Melbourne},
  school = {The University Of Melbourne},
  langid      = {English},
  location    = {Melbourne, AU},
  pagetotal   = {236},
  type        = {PHD Thesis},
  url         = {https://minerva-access.unimelb.edu.au/handle/11343/38198},
  urldate     = {2016-10-24}
}

@article{qavami-dynamic:2013,
  author     = {Qavami, Hamid R. And Jamali, Shahram And Akbari, Mohammad K. And Javadi, Bahman},
  title      = {Dynamic Resource Provisioning In Cloud Computing : A Heuristic Markovian Approach},
  journal    = {Proceedings Of The 4{th} International Conference On Cloud Computing (cloudcomp 2013), October 17 -- 19, 2013, Wuhan, China},
  year       = {2013},
  shorttitle = {Dynamic Resource Provisioning In Cloud Computing},
  url        = {http://researchdirect.uws.edu.au/islandora/object/uws%3A19911/},
  urldate    = {2016-10-25}
}

@inCollection{mhedheb-load:2013,
  author    = {Mhedheb, Yousri And Jrad, Foued And Tao, Jie And Zhao, Jiaqi And Kolodziej, Joanna And Streit, Achim},
  title     = {Load And Thermal-aware Vm Scheduling On The Cloud},
  booktitle = {Algorithms And Architectures For Parallel Processing},
  publisher = {Springer International Publishing},
  year      = {2013},
  editor    = {Kolodziej, Joanna And Martino, Beniamino Di And Talia, Domenico And Xiong, Kaiqi},
  number    = {8285},
  series    = {Lecture Notes In Computer Science},
  pages     = {101--114},
  note      = {Doi: 10.1007/978-3-319-03859-98},
  abstract  = {Virtualization Is One Of The Key Technologies That Enable Cloud Computing, A Novel Computing Paradigm Aiming At Provisioning On-demand Computing Capacities As Services. With The Special Features Of Self-service And Pay-as-you-use, Cloud Computing Is Attracting Not Only Personal Users But Also Small And Middle Enterprises. By Running Applications On The Cloud, Users Need Not Maintain Their Own Servers Thus To Save Administration Cost. Cloud Computing Uses A Business Model Meaning That The Operation Overhead Must Be A Major Concern Of The Cloud Providers. Today, The Payment Of A Data Centre On Energy May Be Larger Than The Overall Investment On The Computing, Storage And Network Facilities. Therefore, Saving Energy Consumption Is A Hot Topic Not Only In Cloud Computing But Also For Other Domains. This Work Proposes And Implements A Virtual Machine (vm) Scheduling Mechanism That Targets On Both Load-balancing And Temperature-balancing With A Final Goal Of Reducing The Energy Consumption In A Cloud Centre. Using The Strategy Of Vm Migration It Is Ensured That None Of The Physical Hosts Suffers From Either High Temperature Or Over-utilization. The Proposed Scheduling Mechanism Has Been Evaluated On Cloudsim, A Well-known Simulator For Cloud Computing. Initial Experimental Results Show A Significant Benefit In Terms Of Energy Consumption.},
  doi       = {10.1007/978-3-319-03859-9_8},
  isbn      = {978-3-319-03858-2 978-3-319-03859-9},
  keywords  = {Algorithm Analysis And Problem Complexity, Cloud Computing, Computer Communication Networks, Database Management, Green Computing, Load Balancing, Software Engineering, Thermal-aware Scheduler, Virtualization, Vm Scheduling},
  langid    = {English},
  rights    = {{\copyright}2013 Springer International Publishing Switzerland},
  urldate   = {2016-10-25}
}

@article{song-adaptive:2014,
  author   = {Song, Weijia And Xiao, Zhen And Chen, Qi And Luo, Haipeng},
  title    = {Adaptive Resource Provisioning For The Cloud Using Online Bin Packing},
  journal  = {IEEE Trans. Comput.},
  year     = {2014},
  volume   = {63},
  number   = {11},
  pages    = {2647--2660},
  abstract = {Data Center Applications Present Significant Opportunities For Multiplexing Server Resources. Virtualization Technology Makes It Easy To Move Running Application Across Physical Machines. In This Paper, We Present An Approach That Uses Virtualization Technology To Allocate Data Center Resources Dynamically Based On Application Demands And Support Green Computing By Optimizing The Number Of Servers Actively Used. We Abstract This As A Variant Of The Relaxed On-line Bin Packing Problem And Develop A Practical, Efficient Algorithm That Works Well In A Real System. We Adjust The Resources Available To Each Vm Both Within And Across Physical Servers. Extensive Simulation And Experiment Results Demonstrate That Our System Achieves Good Performance Compared To The Existing Work.},
  doi      = {10.1109/TC.2013.148},
  issn     = {0018-9340},
  url      = {http://ieeexplore.ieee.org/document/6565979/},
  urldate  = {2016-10-25}
}

@article{corradi-vm:2012,
  author     = {Corradi, Antonio And Fanelli, Mario And Foschini, Luca},
  title      = {Vm Consolidation: A Real Case Based On Openstack Cloud},
  journal    = {Future Generation Computer Systems},
  year       = {2012},
  volume     = {32},
  pages      = {118--127},
  abstract   = {In recent years, cloud computing has been emerging as the next big revolution in both computer networks and web provisioning. because of raised expectations, several vendors, such as amazon and ibm, started designing, developing, and deploying cloud solutions to optimize the usage of their own data centers, and some open-source solutions are also underway, such as eucalyptus and openstack. cloud architectures exploit virtualization techniques to provision multiple virtual machines (vms) on the same physical host, so as to efficiently use available resources, for instance, to consolidate vms in the minimal number of physical servers to reduce the runtime power consumption. vm consolidation has to carefully consider the aggregated resource consumption of co-located vms, in order to avoid performance reductions and service level agreement (sla) violations. while various works have already treated the vm consolidation problem from a theoretical perspective, this paper focuses on it from a more practical viewpoint, with specific attention on the consolidation aspects related to power, cpu, and networking resource sharing. moreover, the paper proposes a cloud management platform to optimize vm consolidation along three main dimensions, namely power consumption, host resources, and networking. reported experimental results point out that interferences between co-located vms have to be carefully considered to avoid placement solutions that, although being feasible from a more theoretical viewpoint, cannot ensure vm provisioning with sla guarantees.},
  doi        = {10.1016/j.future.2012.05.012},
  issn       = {0167-739X},
  keywords   = {Cloud Computing, Openstack, Vm Consolidation},
  series     = {Special Section: The Management Of Cloud Systems, Special Section: Cyber-physical Society And Special Section: Special Issue On Exploiting Semantic Technologies With Particularization On Linked Data Over Grid And Cloud Architectures},
  shorttitle = {Vm Consolidation},
  url        = {http://www.sciencedirect.com/science/article/pii/S0167739X12001082},
  urldate    = {2016-10-26}
}

@article{beloglazov-optimal:2012,
  author     = {Beloglazov, Anton And Buyya, Rajkumar},
  title      = {Optimal Online Deterministic Algorithms And Adaptive Heuristics For Energy And Performance Efficient Dynamic Consolidation Of Virtual Machines In Cloud Data Centers},
  journal    = {Concurrency Computat.: Pract. Exper.},
  year       = {2012},
  volume     = {24},
  number     = {13},
  pages      = {1397--1420},
  abstract   = {The Rapid Growth In Demand For Computational Power Driven By Modern Service Applications Combined With The Shift To The Cloud Computing Model Have Led To The Establishment Of Large-scale Virtualized Data Centers. Such Data Centers Consume Enormous Amounts Of Electrical Energy Resulting In High Operating Costs And Carbon Dioxide Emissions. Dynamic Consolidation Of Virtual Machines (vms) Using Live Migration And Switching Idle Nodes To The Sleep Mode Allows Cloud Providers To Optimize Resource Usage And Reduce Energy Consumption. However, The Obligation Of Providing High Quality Of Service To Customers Leads To The Necessity In Dealing With The Energy-performance Trade-off, As Aggressive Consolidation May Lead To Performance Degradation. Because Of The Variability Of Workloads Experienced By Modern Applications, The Vm Placement Should Be Optimized Continuously In An Online Manner. To Understand The Implications Of The Online Nature Of The Problem, We Conduct A Competitive Analysis And Prove Competitive Ratios Of Optimal Online Deterministic Algorithms For The Single Vm Migration And Dynamic Vm Consolidation Problems. Furthermore, We Propose Novel Adaptive Heuristics For Dynamic Consolidation Of Vms Based On An Analysis Of Historical Data From The Resource Usage By Vms. The Proposed Algorithms Significantly Reduce Energy Consumption, While Ensuring A High Level Of Adherence To The Service Level Agreement. We Validate The High Efficiency Of The Proposed Algorithms By Extensive Simulations Using Real-world Workload Traces From More Than A Thousand Planetlab Vms. Copyright {\copyright} 2011 John Wiley & Sons, Ltd.},
  doi        = {10.1002/cpe.1867},
  issn       = {1532-0634},
  keywords   = {Cloud Computing, Dynamic Consolidation, Green It, Resource Management, Virtualization},
  langid     = {English},
  shorttitle = {Optimal Online Deterministic Algorithms And Adaptive Heuristics For Energy And Performance Efficient Dynamic Consolidation Of Virtual Machines In Cloud Data Centers},
  urldate    = {2016-10-26}
}

@inCollection{monil-fuzzy:2015,
  author    = {Monil, Mohammad Alaul Haque And Rahman, Rashedur M.},
  title     = {Fuzzy Logic Based Energy Aware Vm Consolidation},
  booktitle = {Internet And Distributed Computing Systems},
  publisher = {Springer International Publishing},
  year      = {2015},
  editor    = {Fatta, Giuseppe Di And Fortino, Giancarlo And Li, Wenfeng And Pathan, Mukaddim And Stahl, Frederic And Guerrieri, Antonio},
  number    = {9258},
  series    = {Lecture Notes In Computer Science},
  pages     = {31--38},
  note      = {Doi: 10.1007/978-3-319-23237-94},
  abstract  = {Global Need Of Computing Is Growing Day By Day And As A Result Cloud Based Services Are Getting More Prominent For Its Pay-as-you-go Modality. However, Cloud Based Datacenters Consume Considerable Amount Of Energy Which Draws Negative Attention. To Sustain The Growth Of Cloud Computing, Energy Consumption Is Now A Major Concern For Cloud Based Datacenters. To Overcome This Problem, Cloud Computing Algorithm Should Be Efficient Enough To Keep Energy Consumption Low And At The Same Time Provide Desired Qos. Virtual Machine Consolidation Is One Such Technique To Ensure Energy-qos Balance. In This Research, We Explored Fuzzy Logic And Heuristic Based Virtual Machine Consolidation Approach To Achieve Energy-qos Balance. Fuzzy Vm Selection Method Has Been Proposed To Select Vm From An Overloaded Host. Additionally, We Incorporated Migration Control In Fuzzy Vm Selection Method. We Have Used Cloudsim Toolkit To Simulate Our Experiment And Evaluate The Performance Of The Proposed Algorithm On Real-world Work Load Traces Of Planetlab Vms. Simulation Results Demonstrate That The Proposed Method Provides Best Performance In All Performance Metrics While Consuming Least Energy.},
  doi       = {10.1007/978-3-319-23237-9_4},
  isbn      = {978-3-319-23236-2 978-3-319-23237-9},
  keywords  = {Algorithm Analysis And Problem Complexity, Computer Communication Networks, Information Storage And Retrieval, Information Systems Applications (incl. Internet), Software Engineering, Systems And Data Security},
  langid    = {English},
  rights    = {{\copyright}2015 Springer International Publishing Switzerland},
  urldate   = {2016-10-26}
}

@article{chowdhury-implementation:2015,
  author   = {Chowdhury, Mohammed Rashid And Mahmud, Mohammad Raihan And Rahman, Rashedur M.},
  title    = {Implementation And Performance Analysis Of Various Vm Placement Strategies In Cloudsim},
  journal  = {Journal Of Cloud Computing},
  year     = {2015},
  volume   = {4},
  number   = {1},
  pages    = {20},
  abstract = {Infrastructure As A Service (iaas) Has Become One Of The Most Dominant Features That Cloud Computing Offers Nowadays. Iaas Enables Datacenter{\textquoteright}s Hardware To Get Virtualized Which Allows Cloud Providers To Create Multiple Virtual Machine (vm) Instances On A Single Physical Machine, Thus Improving Resource Utilization And Increasing The Return On Investment (roi). Vm Consolidation Includes Issues Like Choosing Appropriate Algorithm For Selection Of Vms For Migration And Placement Of Vms To Suitable Hosts. Vms Need To Be Migrated From Overutilized Host To Guarantee That Demand For Computer Resources And Performance Requirements Are Accomplished. Besides, They Need To Be Migrated{~}from Underutilized Host To Deactivate That Host For Saving Power Consumption. In Order To Solve The Problem Of Energy And Performance, Efficient Dynamic Vm Consolidation Approach Is Introduced In Literature. In This Work, We Have Proposed Multiple Redesigned Vm Placement Algorithms And Introduced A Technique By Clustering Vms To Migrate By Taking Account Both Cpu Utilization And Allocated Ram. We Implement And Study The Performance Of Our Algorithms On A Cloud Computing Simulation Toolkit Known As Cloudsim Using Planetlab Workload Data. Simulation Results Demonstrate That Our Proposed Techniques Outperform The Default Vm Placement Algorithm Designed In Cloudsim.},
  doi      = {10.1186/s13677-015-0045-5},
  issn     = {2192-113X},
  rights   = {2015 Chowdhury Et Al.},
  urldate  = {2016-11-07}
}

@article{malik-cloudnetsim:2015,
  author     = {Malik, Asad And Bilal, Kashif And Malik, Saif And Anwar, Zahid And Aziz, Khurram And Kliazovich, Dzmitry And Ghani, Nasir And Khan, Samee And Buyya, Rajkumar},
  title      = {Cloudnetsim++: A Gui Based Framework For Modeling And Simulation Of Data Centers In Omnet++},
  journal    = {IEEE Transactions On Services Computing},
  year       = {2015},
  number     = {1},
  pages      = {1--1},
  abstract   = {State-of-the-art Cloud Simulators In Use Today Are Limited In The Number Of Features They Provide, Lack Real Network Communication Models, And Do Not Provide Extensive Graphical User Interface (gui) To Support Developers And Researchers To Extend The Behavior Of The Cloud Environment. We Propose Cloudnetsim++, A Comprehensive Packet Level Simulator That Enables Simulation Of Cloud Environments. Cloudnetsim++ Can Be Used To Evaluate A Wide Spectrum Of Cloud Components, Such As Processing Elements, Storage, Networking, Service Level Agreement (sla), Scheduling Algorithms, Fine Grained Energy Consumption, And Vm Consolidation Algorithms. Cloudnetsim++ Offers Extendibility, Which Means That The Developers And Researchers Can Easily Incorporate Own Algorithms For Scheduling, Workload Consolidation, Vm Migration, And Sla Agreement. The Simulation Environment Of Cloudnetsim++ Offers A Rich Gui That Provides A High Level View Of Distributed Data Centers Connected With Various Network Topologies. The Package Also Includes An Energy Computation Module That Provides A Fine Grained Analysis Of Energy Consumed By Each Component. This Paper Shows The Flexibility And Effectiveness Of Cloudnetsim++ Through Experimental Results Demonstrated Using Real-world Data Center Workloads. Moreover, To Demonstrate The Correctness Of Cloudnetsim++, We Performed Formal Modeling, Analysis, And Verification Using High-level Petri Nets, Satisfiability Modulo Theories (smt), And Z3 Solver.},
  doi        = {10.1109/TSC.2015.2496164},
  issn       = {1939-1374},
  shorttitle = {Cloudnetsim++},
  urldate    = {2016-11-08}
}

@inproceedings{vigliotti-green:2014,
  author     = {Vigliotti, A. P. M. De La Fuente And Batista, D. M.},
  title      = {A Green Network-aware Vms Placement Mechanism},
  booktitle  = {2014 IEEE Global Communications Conference},
  year       = {2014},
  pages      = {2530--2535},
  abstract   = {Data Centers Power Consumption Corresponds To Near 2% Of The Total World Wide Power Consumption, With Constantly Increasing Greenhouse Effect And Co2 Footprints. Virtualization Techniques Improve The Efficiency Of Data Centers Infrastructure Sharing A Same Physical Hardware Among Several Virtual Machines (vms). An Efficient Vm Placement Can Minimize Even Further The Hardware And Energy Needs. In Contrast To Existing Vm Placement Algorithms That Usually Focus On A Single Resource Or Assumes That Resources Demands Are Deterministic, This Paper Proposes And Compares Four Energy-aware Algorithms That Consider Multiple Stochastic Resources, Including Network Bandwidth. We First Formulate The Problem As A Multi Objective Optimization Problem With Stochastic Resources And We Present Two Algorithms Based On This Approach. We Also Formulate The Problem As An Evolutionary Computation Problem And We Present Two Algorithms Based On This Approach. The Objective Is A Joint Strategy: Minimize The Required Hardware To Maximize The Allocated Vms Satisfying The Resource Requirements. Through Simulations, We Compare Our Algorithms Using Real Vms Workloads From The Planetlab Project And Showed The Significant Improvements On Power Consumption And Network Utilization. In Average, The Algorithms Reduce Power Consumption By 87.90% And The Network Utilization By 9.94%.},
  doi        = {10.1109/GLOCOM.2014.7037188},
  eventtitle = {2014 IEEE Global Communications Conference},
  keywords   = {Air Pollution, Bandwidth, Carbon Dioxide Footprints, Computational Modeling, Computer Centres, Data Center Power Consumption, Energy-aware Algorithms, Evolutionary Computation, Evolutionary Computation Problem, Green Computing, Greenhouse Effect, Green Network-aware Vm Placement Mechanism, Joints, Minimisation, Multiobjective Optimization Problem, Network Utilization, Planetlab Project, Power Aware Computing, Power Demand, Random Access Memory, Resource Allocation, Resource Requirements, Stochastic Resources, Virtualisation, Virtual Machines, Virtual Machining, Vm Placement Algorithms}
}

@inproceedings{xiang-li-dartcsim::2013,
  author     = {Xiang Li And Xiaohong Jiang And Kejiang Ye And Peng Huang},
  title      = {Dartcsim+: Enhanced Cloudsim With The Power And Network Models Integrated},
  booktitle  = {2013 IEEE Sixth International Conference On Cloud Computing},
  year       = {2013},
  pages      = {644--651},
  publisher  = {IEEE},
  abstract   = {Cloudsim Is One Of The Most Powerful Simulation Platforms For Cloud Computing. It Supports The Energy-conscious Scheduling And Network Simulation In The Latest Version. However, It Still Faces Several Limitations: 1) Current Cloudsim Cannot Support Both The Power Model And The Network Model At The Same Time. 2) The Network Components In Current Cloudsim Do Not Support Power-aware Simulation. 3) The Simulation Of Migration Does Not Take Into Account The Network Overheads. To Overcome These Limitations, We Design And Implement An Enhanced Cloud Simulation Platform Called Dartcsim+ That Supports The Energy-aware Network Simulation And Network-aware Live Migration. Further, We Also Implement A Resubmit Mechanism For Packets Transmission To Provide A More Real Network Behavior To Solve Transmission Failure Which Is Caused By Migration Or Network Failure. Finally, Three Groups Of Experiments Are Performed To Demonstrate The Effectiveness Of Dartcsim+.},
  doi        = {10.1109/CLOUD.2013.53},
  eventtitle = {2013 IEEE Sixth International Conference On Cloud Computing},
  isbn       = {978-0-7695-5028-2},
  keywords   = {Cloud Computing, Cloudsim, Computational Modeling, Dartcsim+, Delays, Energy-aware Network Simulation, Energy-conscious Scheduling, Mathematical Model, Modeling And Simulation, Network, Network-aware Live Migration, Network Models Integrated, Network Simulation, Packets Transmission, Power, Power-aware Simulation, Power Demand, Schedules, Scheduling, Virtual Machining},
  shorttitle = {Dartcsim+},
  url        = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6676752},
  urldate    = {2016-11-08}
}

@article{mishra-dynamic:2012,
  author  = {Mishra, Mayank And Das, Anwesha And Kulkarni, Purushottam And Sahoo, Anirudha},
  title   = {Dynamic Resource Management Using Virtual Machine Migrations},
  journal = {IEEE Communications Magazine},
  year    = {2012},
  volume  = {50},
  number  = {9},
  pages   = {34--40},
  doi     = {10.1109/MCOM.2012.6295709},
  issn    = {0163-6804},
  url     = {http://ieeexplore.ieee.org/document/6295709/},
  urldate = {2016-11-08}
}

@article{jiankang-virtual:2014,
  author  = {Jiankang, Dong And Hongbo, Wang And Yangyang, Li And Shiduan, Cheng},
  title   = {Virtual Machine Scheduling For Improving Energy Efciency In Iaas Cloud},
  journal = {China Communications},
  year    = {2014},
  volume  = {11},
  number  = {3},
  pages   = {1--12},
  doi     = {10.1109/CC.2014.6825253},
  issn    = {1673-5447},
  url     = {http://ieeexplore.ieee.org/document/6825253/},
  urldate = {2016-11-08}
}

@article{ghobaei-arani-autonomic:2016,
  author   = {Ghobaei-arani, Mostafa And Jabbehdari, Sam And Pourmina, Mohammad Ali},
  title    = {An Autonomic Approach For Resource Provisioning Of Cloud Services},
  journal  = {Cluster Comput},
  year     = {2016},
  volume   = {19},
  number   = {3},
  pages    = {1017--1036},
  abstract = {Recently, There Has Been A Significant Increase In The Use Of Cloud-based Services That Are Offered In Software As A Service (saas) Models By Saas Providers, And Irregular Access Of Different Users To These Cloud Services Leads To Fluctuations In The Demand Workload. It Is Difficult To Determine The Suitable Amount Of Resources Required To Run Cloud Services In Response To The Varying Workloads, And This May Lead To Undesirable States Of Over-provisioning And Under-provisioning. In This Paper, We Address Improvements To Resource Provisioning For Cloud Services By Proposing An Autonomic Resource Provisioning Approach That Is Based On The Concept Of The Control Monitor-analyze-plan-execute (mape) Loop, And We Design A Resource Provisioning Framework For Cloud Environments. The Experimental Results Show That The Proposed Approach Reduces The Total Cost By Up To 35 The Number Of Service Level Agreement (sla) Violations By Up To 40 And Increases The Resource Utilization By Up To 25 % Compared With The Other Approaches.},
  doi      = {10.1007/s10586-016-0574-9},
  issn     = {1386-7857, 1573-7543},
  langid   = {English},
  urldate  = {2016-11-08}
}

@inproceedings{lee-vmap::2012,
  author     = {Lee, Eun Kyung And Viswanathan, Hariharasudhan And Pompili, Dario},
  title      = {Vmap: Proactive Thermal-aware Virtual Machine Allocation In Hpc Cloud Datacenters},
  booktitle  = {International Conference On High Performance Computing (hipc), 2012 19{th}},
  year       = {2012},
  pages      = {1--10},
  publisher  = {IEEE},
  shorttitle = {Vmap},
  url        = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6507478},
  urldate    = {2016-11-08}
}

@article{monil-vm:2016,
  author   = {Monil, Mohammad Alaul Haque And Rahman, Rashedur M.},
  title    = {Vm Consolidation Approach Based On Heuristics, Fuzzy Logic, And Migration Control},
  journal  = {Journal Of Cloud Computing},
  year     = {2016},
  volume   = {5},
  number   = {1},
  pages    = {8},
  abstract = {To Meet The Increasing Demand Of Computational Power, At Present It Service Providers{\textquoteright} Should Choose Cloud Based Services For Its Flexibility, Reliability And Scalability. More And More Datacenters Are Being Built To Cater Customers{\textquoteright} Need. However, The Datacenters Consume Large Amounts Of Energy, And This Draws Negative Attention. To Address Those Issues, Researchers Propose Energy Efficient Algorithms That Can Minimize Energy Consumption While Keeping The Quality Of Service (qos) At A Satisfactory Level. Virtual Machine Consolidation Is One Such Technique To Ensure Energy-qos Balance. In This Research, We Explore Fuzzy Logic And Heuristic Based Virtual Machine Consolidation Approach To Achieve Energy-qos Balance. A Fuzzy Vm Selection Method Is Proposed In This Research. It Selects Vm From An Overloaded Host. Additionally, We Incorporate Migration Control In Fuzzy Vm Selection Method That Will Enhance The Performance Of The Selection Strategy. A New Overload Detection Algorithm Has Also Been Proposed Based On Mean, Median And Standard Deviation Of Utilization Of Vms. We Have Used Cloudsim Toolkit To Simulate Our Experiment And Evaluate The Performance Of The Proposed Algorithm On Real-world Work Load Traces Of Planet Lab Vms. Simulation Results Demonstrate That The Proposed Method Is Most Energy Efficient Compared To Others.},
  doi      = {10.1186/s13677-016-0059-7},
  issn     = {2192-113X},
  rights   = {2016 The Author(s).},
  urldate  = {2016-11-09}
}

@inproceedings{reviriego-energy:2012,
  author    = {Reviriego, Pedro And Sivaraman, Vijay And Zhao, Zhi And Maestro, Juan Antonio And Vishwanath, Arun And S{\'{a}}nchez-macian, Alfonso And Russell, Craig},
  title     = {An Energy Consumption Model For Energy Efficient Ethernet Switches},
  booktitle = {International Conference On High Performance Computing And Simulation (hpcs), 2012},
  year      = {2012},
  pages     = {98--104},
  publisher = {IEEE},
  url       = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6266897},
  urldate   = {2016-11-10}
}

@Online{cisco-calculating:2016,
  author     = {Cisco},
  title      = {Calculating Power For Cisco Stackpower And The Cisco Catalyst 3750-x Series Switches White Paper},
  year       = {2016},
  abstract   = {Thought Leadership Document Designed To Convince Or Influence Customers To Do Business With Cisco Based On Particular Solution.},
  keywords   = {Gs},
  titleaddon = {Cisco},
  url        = {http://www.cisco.com/c/en/us/products/collateral/switches/catalyst-3750-x-series-switches/white_paper_c11-663717.html},
  urldate    = {2016-11-10}
}

### OLD TCC

@misc{tiaonline.org-tia:2013,
  author  = {Tiaonline.org, Press Release},
  title   = {Tia Issues New Telecommunications Infrastructure Standard On Data Center Switch Fabrics In Order To Support Cloud Computing Growth},
  year    = {2013},
  journal = {Telecommunications Industry Association (tia)},
  type    = {Standard},
  url     = {http://www.tiaonline.org/news-media/press-releases/tia-issues-new-telecommunications-infrastructure-standard-data-center},
  urldate = {2016-06-09}
}

@article{chen-operational:2015,
  author   = {Chen, S. And Irving, S. And Peng, L.},
  title    = {Operational Cost Optimization For Cloud Computing Data Centers Using Renewable Energy},
  journal  = {IEEE Systems Journal},
  year     = {2015},
  volume   = {Pp},
  number   = {99},
  pages    = {1--12},
  abstract = {The Electricity Cost Of Cloud Computing Data Centers, Dominated By Server Power And Cooling Power, Is Growing Rapidly. To Tackle This Problem, Inlet Air With Moderate Temperature And Server Consolidation Are Widely Adopted. However, The Benefit Of These Two Methods Is Limited Due To Conventional Air Cooling System Ineffectiveness Caused By Recirculation And Low Heat Capacity. To Address This Problem, Hybrid Air And Liquid Cooling, As A Practical And Inexpensive Approach, Has Been Introduced. In This Paper, We Quantitatively Analyze The Impact Of Server Consolidation And Temperature Of Cooling Water On The Total Electricity And Server Maintenance Costs In Hybrid Cooling Data Centers. To Minimize The Total Costs, We Proposed To Maintain Sweet Temperature And Available Sleeping Time Threshold (astt) By Which A Joint Cost Optimization Can Be Satisfied. By Using Real-world Traces, The Potential Savings Of Sweet Temperature And Astt Are Estimated To Be Average 23% Of The Total Cost, While 96% Requests Are Satisfied Compared To A Strategy Which Only Reduces Electricity Cost. The Co-optimization Is Extended To Increase The Benefit Of The Renewable Energy, And Its Profit Grows As More Wind Power Is Supplied.},
  doi      = {10.1109/JSYST.2015.2462714},
  issn     = {1932-8184},
  keywords = {Cooling, Cost Optimization, Data Center, Hardware, Hybrid Cooling, Maintenance Engineering, Optimization, Program Processors, Renewable Energy, Servers, Wind Speed}
}

@book{singh-hand:2011,
  title     = {Hand Book Of Mechanical Engineering},
  publisher = {S. Chand},
  year      = {2011},
  author    = {Singh, Sadhu},
  month     = dec,
  abstract  = {Handbook Of Mechanical Engineering Is A Comprehensive Text For The Students Of B.e./b.tech. And The Candidates Preparing For Various Competitive Examination Like Ies/ifs/ Gate State Services And Competitive Tests Conducted By Public And Private Sector Organization For Selecting Apprentice Engineers.},
  isbn      = {978-81-219-3587-6},
  keywords  = {Technology & Engineering / Mechanical},
  language  = {English}
}

@techreport{bell-use:2005,
  author      = {Bell, Michael A.},
  title       = {Use Best Practices To Design Data Center Facilities},
  institution = {Gartner Inc},
  year        = {2005},
  type        = {White Paper},
  number      = {G00127434},
  month       = apr,
  abstract    = {Data Centers Seldom Meet The Operational And Capacity Requirements Of Their Initial Designs. The Principal Goals In Data Center Design Are Flexibility And Scalability, Which Involve Site Location, Building Selection, Floor Layout, Electrical System Design, Mechanical Design And Modularity.},
  language    = {En-us},
  pages       = {26},
  url         = {https://www.gartner.com/doc/476880/use-best-practices-design-data},
  urldate     = {2016-06-08}
}

@book{patrick-electrical:2008,
  title     = {Electrical Distribution Systems},
  publisher = {The Fairmont Press, Inc.},
  year      = {2008},
  author    = {Patrick, Dale R. And Fardo, Stephen W.},
  isbn      = {978-0-88173-600-7},
  keywords  = {Technology & Engineering / Power Resources / Electrical},
  language  = {En}
}

@article{masanet-estimating:2011,
  author   = {Masanet, E. R. And Brown, R. E. And Shehabi, A. And Koomey, J. G. And Nordman, B.},
  title    = {Estimating The Energy Use And Efficiency Potential Of U.s. Data Centers},
  journal  = {Proceedings Of The IEEE},
  year     = {2011},
  volume   = {99},
  number   = {8},
  pages    = {1440--1453},
  abstract = {Data Centers Are A Significant And Growing Component Of Electricity Demand In The United States. This Paper Presents A Bottom-up Model That Can Be Used To Estimate Total Data Center Electricity Demand Within A Region As Well As The Potential Electricity Savings Associated With Energy Efficiency Improvements. The Model Is Applied To Estimate 2008 U.s. Data Center Electricity Demand And The Technical Potential For Electricity Savings Associated With Major Measures For It Devices And Infrastructure Equipment. Results Suggest That 2008 Demand Was Approximately 69 Billion Kilowatt Hours (1.8% Of 2008 Total U.s. Electricity Sales) And That It May Be Technically Feasible To Reduce This Demand By Up To 80% (to 13 Billion Kilowatt Hours) Through Aggressive Pursuit Of Energy Efficiency Measures. Measure-level Savings Estimates Are Provided, Which Shed Light On The Relative Importance Of Different Measures At The National Level. Measures Applied To Servers Are Found To Have The Greatest Contribution To Potential Savings.},
  doi      = {10.1109/JPROC.2011.2155610},
  issn     = {0018-9219},
  keywords = {Bottom-up Model, Computer Centres, Data Centers, Data Models, Data Systems, Electricity Demand, Electricity Savings, Electric Variables Measurement, Energy Conservation, Energy Demand Modeling, Energy Efficiency, Energy Management, Information Technology, It Devices, Load Forecasting, Mathematical Model, Power Aware Computing, Power Systems Planning, Program Processors, Supply And Demand}
}

@inproceedings{sujatha-energy:2011,
  author    = {Sujatha, C. And Abimannan, S.},
  title     = {Energy Efficient Free Cooling System For Data Centers},
  booktitle = {2011 IEEE Third International Conference On Cloud Computing Technology And Science (cloudcom)},
  year      = {2011},
  pages     = {646--651},
  month     = nov,
  abstract  = {A Data Center Is A Facility Used To Keep Computer Related Equipments. It Is Estimated That Heat Production Rate Of The Data Center Is Doubled In Every Two Years And Hence The Inevitability Of The Cooling System Gets Increased. In Due Course Power Consumption Of A Data Center Is Augmented And More Cost Is Spent On The Power Usage Of The Cooling System Rather Than The Equipment Purchase. As A Result Power Savings For The Cooling System Is Strongly Desired. In This Paper We Conferred Two Primary Free Cooling Systems Namely Air Economizer And Water Economizer. A Free Cooling Economizer System Uses The Outside Air Which Is Forced To The Data Center When Outside Climate Is Suitable To Meet The Ashre's Cooling Requirements. We Have Also Conducted A Survey And Simulation Based Estimation Using Trace[tm] Chiller Plant Analyzer Tool. In This Study, The Energy Consumption In A Data Center Using Conventional Cooling System Is Compared With Air Economizer And Water Economizer For Three Different Zones Namely Chicago, Atlanta And Phoenix In View Of The Fact That The Outside Air Is Relatively Cool Most Of The Year. From The Projected Result It Is Observed That Both Economizers Reduce Energy And Cost When Compared With Conventional System And The Usage Of Economizer Permits The Chiller To Shut Down Or Reduce Chiller Energy Load Under Suitable Weather Conditions. The Results Show That Water Economizers Are Shown To Consistently Outperform Air Economizer Which Provides Significant Improvement In Cooling System Efficiency And Cost At Data Center. The Performance Ratio Of The Conventional, Air Economizer And The Water Economizers Are 50 76% And 79% Respectively That Shows Economizers Provide More Savings Relative To The Conventional System.},
  doi       = {10.1109/CloudCom.2011.100},
  keywords  = {Air Conditioning, Air Economizer, Ashre's Cooling Requirements, Atlanta, Chicago, Chiller Energy Load Reduction, Computer Centres, Cooling, Data Center, Energy Conservation, Energy Consumption, Energy Efficient Free Cooling System, Free Cooling Economizer System, Heat Production Rate, Humidity, Outside Air, Performance Ratio, Phoenix, Poles And Towers, Power Aware Computing, Power Consumption, Power Demand, Power Saving, Simulation Based Estimation, Temperature Distribution, Temperature Measurement, Trace[tm] Chiller Plant Analyzer Tool, Water Economizer}
}

@inproceedings{pegus-analyzing:2016,
  author    = {Pegus, Ii, Patrick And Varghese, Benoy And Guo, Tian And Irwin, David And Shenoy, Prashant And Mahanti, Anirban And Culbert, James And Goodhue, John And Hill, Chris},
  title     = {Analyzing The Efficiency Of A Green University Data Center},
  booktitle = {7\textsuperscript{th} {ACM/SPEC}},
  year      = {2016},
  publisher = {ACM},
  abstract  = {Data Centers Are An Indispensable Part Of Today's It Infrastructure. To Keep Pace With Modern Computing Needs, Data Centers Continue To Grow In Scale And Consume Increasing Amounts Of Power. While Prior Work On Data Centers Has Led To Significant Improvements In Their Energy-efficiency, Detailed Measurements From These Facilities' Operations Are Not Widely Available, As Data Center Design Is Often Considered Part Of A Company's Competitive Advantage. However, Such Detailed Measurements Are Critical To The Research Community In Motivating And Evaluating New Energy-efficiency Optimizations. In This Paper, We Present A Detailed Analysis Of A State-of-the-art 15mw Green Multi-tenant Data Center That Incorporates Many Of The Technological Advances Used In Commercial Data Centers. We Analyze The Data Center's Computing Load And Its Impact On Power, Water, And Carbon Usage Using Standard Effectiveness Metrics, Including Pue, Wue, And Cue. Our Results Reveal The Benefits Of Optimizations, Such As Free Cooling, And Provide Insights Into How The Various Effectiveness Metrics Change With The Seasons And Increasing Capacity Usage. More Broadly, Our Pue, Wue, And Cue Analysis Validate The Green Design Of This Leed Platinum Data Center.},
  doi       = {10.1145/2851553.2851557},
  isbn      = {978-1-4503-4080-9},
  keywords  = {Data Centers, Energy Efficiency, Sustainability},
  location  = {New York, Ny, Usa},
  urldate   = {2016-05-05}
}

@article{lee-design:2016,
  author       = {Lee, H. C. And Lin, H. H.},
  title        = {Design And Evaluation Of An Open-source Wireless Mesh Networking Module For Environmental Monitoring},
  journal      = {IEEE Sensors Journal},
  year         = {2016},
  volume       = {16},
  number       = {7},
  pages        = {2162--2171},
  abstract     = {Wireless Mesh Networking Extends The Communication Range Among Cooperating Multiple Low-power Wireless Radio Transceivers And Is Useful For Collecting Data From Sensors Widely Distributed Over A Large Area. By Integrating An Off-the-shelf Wireless Design, Such As The Xbee Module, Development Of Sensor Systems With Mesh Networking Capability Can Be Accelerated. This Study Introduces An Open-source Wireless Mesh Network (wmn) Module, Which Integrates The Functions Of Network Discovery, Automatic Routing Control, And Transmission Scheduling. In Addition, This Design Is Open Source In Order To Promote The Use Of Wireless Mesh Networking For Environmental Monitoring Applications. Testing Of The Design And The Proposed Networking Module Is Reported. The Proposed Wireless Mesh Networking Module Was Evaluated And Compared With Xbee. The Average Package Delivery Ratio And Standard Deviation Of The Proposed Wmn Module And The Xbee Are 94.09 91.19 5.14 And 10.25 Respectively, In A 20 Node Experiment. The Proposed System Was Demonstrated To Have The Advantages Of Low-cost Combined With High Reliability And Performance, And Can Aid Scientists In Implementing Monitoring Applications Without The Complications Of Complex Wireless Networking Issues.},
  date         = {2016},
  doi          = {10.1109/JSEN.2015.2507596},
  issn         = {1530-437X},
  journaltitle = {IEEE Sensors Journal},
  keywords     = {802.15.4, Automatic Routing Control, Average Package Delivery Ratio, Environmental Monitoring, Environmental Monitoring (geophysics), Mesh Network Module, Monitoring, Network Discovery, Open-source, Open-source Wireless Mesh Networking Module, Sensor Systems, Transmission Scheduling, Wireless Communication, Wireless Mesh Networks, Wireless Sensor, Wireless Sensor Networks, Xbee, Zigbee}
}

@inproceedings{montoya-zenergy:2011,
  author     = {Montoya, F. G. And Alcayde, A. And S{\'{a}}nchez, P. And G{\'{o}}mez, J. And Mart{\'{i}}n, F.},
  title      = {Zenergy: An Open Source Project For Power Quality Assessment And Monitoring},
  booktitle  = {2011 International Conference On Power Engineering, Energy And Electrical Drives (powereng)},
  year       = {2011},
  pages      = {1--6},
  abstract   = {In This Paper, A New Open Source Project Focused On Power Quality Assessment And Monitoring For Low Voltage Power Systems Is Presented. Power Quality (pq) Is A Crucial Matter For Proper And Reliable Operation Of Industrial Or Home Electrical Appliances. In Order To Improve Pq Techniques, Efforts Are Made To Develop Smart Sensors That Can Report Near Real-time Data. Proprietary Software And Hardware On Dedicated Computers Or Servers Processes These Data And Shows Relevant Information Through Tables Or Graphics. In This Situation, Interoperability, Compatibility And Scalability Are Not Possible Because Of The Lack Of Open Protocols. In Our Work, We Introduce Zenergy, An Open Source Platform For Computing, Storing And Managing All Of The Information Generated From Smart Sensors. We Apply The Most Up-to-date Algorithms Developed For Power Quality, Event Detection, And Harmonic Analysis Or Power Metering. Zenergy Makes Use Of Cutting-edge Web Technologies Such As Html5, Css3 And Javascript To Provide User-friendly Interaction And Powerful Capabilities For The Analysis, Measurement And Monitoring Of Power Systems. All Software Used In Our Work Is Open Source, Running On Linux.},
  date       = {2011},
  doi        = {10.1109/PowerEng.2011.6036474},
  eventtitle = {2011 International Conference On Power Engineering, Energy And Electrical Drives (powereng)},
  keywords   = {Computer Architecture, Computers Process, Css3, Cutting-edge Web Technology, Databases, Graphics, Harmonic Analysis, Home Electrical Appliance, Html5, Instruction Sets, Intelligent Sensors, Internet, Javascript, Linux, Low Voltage Power Systems, Monitoring, Power Engineering Computing, Power Quality, Power Quality Assessment, Power Supply Quality, Power System Measurement, Power System Monitoring, Pq Technique, Protocols, Public Domain Software, Real Time Systems, Scalability, Server Process, Smart Sensors, User-friendly Interaction, Zenergy},
  shorttitle = {Zenergy}
}

@inproceedings{sato-seeking:2015,
  author     = {Sato, M. And Matsunaga, A. And Chiba, M. And Shoujiguchi, A. And Yoshikawa, M.},
  title      = {Seeking An Energy-efficient Modular Data Center: Impact Of Pressure Loss On The Server Fan Power},
  booktitle  = {2015 International Conference On Electronics Packaging And Imaps All Asia Conference (icep-iacc)},
  year       = {2015},
  pages      = {617--622},
  abstract   = {With The Recent Development Of Cloud Computing, The Amount Of Information To Be Processed In Data Centers Has Increased In Recent Years, Which Promotes The Construction Of New Data Centers. Modular Data Center, Which Is Often Packaged In Standard Shipping Formats, Has Been Introduced To Construct And Deploy Data Centers More Quickly And Less Expensively Than Conventional Data Centers. To Conserve Cooling Costs In Modular Data Centers, A Hot Aisle/cold Aisle Arrangement Of The It Racks Is Employed By Dividing The Top Of The Racks Using The Partition. However, Dividing The Top Of The Racks Increases The Pressure Loss Of The Server Fans, Leading To The Increase Of The Server Fan Power. To Examine The Impact Of This Effect On Annual Cooling Power, We Perform Simulations Of Power Consumption In Modular Data Center That Introduces Outside Air And Louvers On The Top Of The Racks. By Varying The Opening Of The Louver As A Function Of The Outside Air Temperature And Rack Power, An Operation To Minimize The Power Consumption Of The Outside Air Fans And Server Fans Is Performed. We Find That Total Cooling Power In Case Where The Louver Is Operated So As To Minimize The Total Cooling Power Can Be Reduced Than That In Case Where The Louver Is Fully Closed By About 5% (10 For 10kw (20kw) Rack Power. We Discuss That The Popular Method For Calculating Energy Efficiency In Data Centers, I.e. Power Usage Effectiveness (pue), Defined By The Ratio Of Total Amount Of Energy Used To The Energy Used In It Equipment, Is Probably Incomplete Metric. Therefore, We Finally Propose That A Revised Pue That Removes The Server Fan Power From It Equipment Energy, And It Should Be Used To Estimate The Energy Efficiency To Avoid The Wrong Interpretation.},
  date       = {2015-04},
  doi        = {10.1109/ICEP-IAAC.2015.7111088},
  eventtitle = {2015 International Conference On Electronics Packaging And Imaps All Asia Conference (icep-iacc)},
  keywords   = {Air Fans, Annual Cooling Power, Central Processing Unit, Cloud Computing, Cold Aisle Arrangement, Computer Centres, Containers, Cooling, Cooling Cost, Data Center, Energy Conservation, Energy Efficiency, Energy-efficient Modular Data Center, Fan, Fans, Heating, Hot Aisle Arrangement, It Equipment Energy, It Racks, Power Consumption, Power Demand, Power Usage Effectiveness, Pressure Loss, Pue, Server Fan Power, Server Fans, Servers, Simulation, Standard Shipping Format},
  shorttitle = {Seeking An Energy-efficient Modular Data Center}
}

@misc{sartor-better:2016,
  author     = {Sartor, Dale},
  title      = {Better Buildings, Better Data Centers: Applying Best Practices},
  year       = {2016},
  note       = {Rocky Mountain Green 2016},
  langid     = {American},
  location   = {Denver, Colorado},
  shorttitle = {Better Buildings, Better Data Centers},
  url        = {https://datacenters.lbl.gov/resources/better-buildings-better-data-centers-0},
  urldate    = {2016-05-04}
}

@inproceedings{wiboonrat-life:2014,
  author     = {Wiboonrat, M.},
  title      = {Life Cycle Cost Analysis Of Data Center Project},
  booktitle  = {2014 Ninth International Conference On Ecological Vehicles And Renewable Energies (ever)},
  year       = {2014},
  pages      = {1--6},
  abstract   = {The Reexamining The Feasibility And Cost Impact Of Sustainable Data Center Design Is In The Light Of Increased Market Adoption. Life Cycle Cost Analysis (lcca) Of Data Centers Is A System Approach For Appraising And Predicting The Total Cost Of Facility Ownership. It Must Be Taken Into Account All Costs Of Feasible, Estimating, Acquiring, Operating, Maintaining, And Disposing Of Data Center Ecosystem. This Research Classified Lcca Of Data Center Into Four Phases: Planning, Implementing, Operating, And Transforming. The Qualitative Research Was Conducted Through Investigating Triangulation, Interviews, Focus Groups And Case Studies. Data Center's Consultants, System Integrators, And Project Owners Are The Focus Groups For In-depth Interviews. The Research Findings Propose Data Center Cost Capsule (dccc) Model Which Identifies All Associated Costs Of Entire Data Center Life Cycle; Before, During, And After Operations. The Dccc Model Is Designed To Comply With International Standards E.g., Iso 9001: 2008 And Tia 942. Moreover, The Dccc Model Foresees The Total Costs Of Ownership Of Data Center.},
  doi        = {10.1109/EVER.2014.6844139},
  eventtitle = {2014 Ninth International Conference On Ecological Vehicles And Renewable Energies (ever)},
  keywords   = {Analytical Models, Buildings, Computer Centres, Cost Benefit Analysis, Data Center, Data Center Cost Capsule, Data Center Cost Capsule Model, Data Center Ecosystem, Data Models, Dccc Model, Facility Ownership, International Standard, Iso 9001:2008, Iso Standards, Lcca, Life Cycle Cost Analysis, Life Cycle Costing, Project Management, Standards, Sustainable Data Center Design, Tia 942, Total Cost Of Ownership}
}

@inproceedings{jeong-holistic:2014,
  author     = {Jeong, S. And Kim, Y. W.},
  title      = {A Holistic Investigation Method For Data Center Resource Efficiency},
  booktitle  = {2014 International Conference On Information And Communication Technology Convergence (ictc)},
  year       = {2014},
  pages      = {548--551},
  abstract   = {The Rapid Increase In Energy Consumption Of Data Centers Accelerates The Development Of Metrics For Measuring Data Center Energy Efficiency. In Response To This Demand, Iso/iec Jtc1/sc39 Is Developing Iso/iec 30134 Series Standards Defining Multiple Key Performance Indicators (kpis) For Measuring Data Center Resource Efficiency. However, There Is Another Emerging Demand To Observe The Overall Trend Of All Kpis In A Single View And The Inter-relationship Among The Kpis. The Main Objective Of This Paper Is To Describe The General Holistic Investigation Method And Identify Issues Associated With Various Strategies. Then It Proposes A Control Chart-based Holistic Investigation Method For Resource Efficiency Evaluation And Interrelationship Identification Of Data Center Multiple Kpis. Through The Swot Analysis On The Holistic Investigation Method Presented In This Paper, The Usefulness And Applicability Of Holistic Investigation Method Are Discussed.},
  doi        = {10.1109/ICTC.2014.6983207},
  eventtitle = {2014 International Conference On Information And Communication Technology Convergence (ictc)},
  keywords   = {Computer Centres, Control Chart-based Holistic Investigation Method, Control Charts, Current Measurement, Data Center, Data Center Energy Consumption, Data Center Energy Efficiency, Data Center Resource Efficiency, Energy Conservation, Energy Consumption, Energy Efficiency, Energy Measurement, Iso-iec 30134 Series Standards, Iso-iec Jtc1-sc39, Iso Standards, Key Performance Indicator, Key Performance Indicators, Kpis, Metric, Monitoring, Radar Chart, Spider Web Chart, Swot Analysis}
}

@misc{isoiec-30134-2:2016,
  author     = {Iso/iec},
  title      = {Iso/iec 30134-2:2016 - Information Technology -- Data Centres -- Key Performance Indicators -- Part 2: Power Usage Effectiveness (pue)},
  year       = {2016},
  editor     = {Iso/iec},
  shorttitle = {Iso/iec 30134-2},
  titleaddon = {Iso},
  url        = {http://www.iso.org/iso/catalogue_detail.htm?csnumber=63451},
  urldate    = {2016-05-03}
}

@Report{machado-operational:2015,
  author      = {Machado, Jose-Pedro And Forina, Marl{\`{e}}ne},
  title       = {Operational Energy Efficiency For Users (oeu); Referential Specification To Define Sustainable Levels Of Ict Sites},
  month       = jun,
  year        = {2015},
  institution = {Etsi},
  language    = {En-us},
  location    = {France},
  number      = {Etsi Gs Oeu 006},
  pages       = {13},
  shorttitle  = {Referential Specification To Define Sustainable Levels Of Ict Sites},
  type        = {Standard}
}

@inproceedings{rotem-energy:2014,
  author    = {Rotem, E. And Weisser, U. C. And Mendelson, A. And Yassin, A. And Ginosar, R.},
  title     = {Energy Management Of Highly Dynamic Server Workloads In An Heterogeneous Data Center},
  booktitle = {2014 24\textsuperscript{th} International Workshop On Power And Timing Modeling, Optimization And Simulation (patmos)},
  year      = {2014},
  pages     = {1--5},
  month     = sep,
  abstract  = {We Propose A Hybrid Management Model To Address Heterogeneous Data Center Energy Efficiency With Highly Dynamic Workload. A Central Dispatch And Control Algorithm With Distributed System Energy Management Was Implemented And Validated On Real Processor And System. We Demonstrate Up To 20% Energy Savings (11% Average) Without Compromising Quality Of Service. Additional 5% Average Energy Savings Was Achieved By Exploiting System Heterogeneity.},
  doi       = {10.1109/PATMOS.2014.6951868},
  keywords  = {Central Dispatch And Control Algorithm, Computer Centres, Data Center, Dispatching, Distributed System Energy Management, Dynamic Server Workload, Dynamic Workload, Earth, Energy Conservation, Energy Efficiency, Energy Savings, Heterogeneous Data Center Energy Efficiency, Hybrid Management Model, Optimization, Power Aware Computing, Power Management, Quality Of Service, Real Processor, Throughput}
}

@inproceedings{cheung-energy:2014,
  author     = {Cheung, H.y. And Greenberg, Steve And Mahdavi, Roozbeh And Brown, Richard And Tscudi, William},
  title      = {Energy Efficiency In Small Server Rooms: Field Surveys And Findings},
  booktitle  = {2014 Aceee Summer Study On Energy Efficiency In Buildings},
  year       = {2014},
  abstract   = {Fifty-seven Percent Of Us Servers Are Housed In Server Closets, Server Rooms, And Localized Data Centers, In What Are Commonly Referred To As Small Server Rooms, Which Comprise 99textbackslash% Of All Server Spaces In The Us. While Many Mid-tier And Enterprise-class Data Centers Are Owned By Large Corporations That Consider Energy Efficiency A Goal To Minimize Business Operating Costs, Small Server Rooms Typically Are Not Similarly Motivated. They Are Characterized By Decentralized Ownership And Management And Come In Many Configurations, Which Creates A Unique Set Of Efficiency Challenges. To Develop Energy Efficiency Strategies For These Spaces, We Surveyed 30 Small Server Rooms Across Eight Institutions, And Selected Four Of Them For Detailed Assessments. The Four Rooms Had Power Usage Effectiveness (pue) Values Ranging From 1.5 To 2.1. Energy Saving Opportunities Ranged From No- To Low-cost Measures Such As Raising Cooling Set Points And Better Airflow Management, To More Involved But Cost-effective Measures Including Server Consolidation And Virtualization, And Dedicated Cooling With Economizers. We Found That Inefficiencies Mainly Resulted From Organizational Rather Than Technical Issues. Because Of The Inherent Space And Resource Limitations, The Most Effective Measure Is To Operate Servers Through Energy-efficient Cloud-based Services Or Well-managed Larger Data Centers, Rather Than Server Rooms. Backup Power Requirement, And It And Cooling Efficiency Should Be Evaluated To Minimize Energy Waste In The Server Space. Utility Programs Are Instrumental In Raising Awareness And Spreading Technical Knowledge On Server Operation, And The Implementation Of Energy Efficiency Measures In Small Server Rooms.},
  language   = {En-us},
  location   = {Pacific Grove, California},
  shorttitle = {Energy Efficiency In Small Server Rooms}
}

@book{dai-optimum:2014,
  title      = {Optimum Cooling Of Data Centers: Application Of Risk Assessment And Mitigation Techniques},
  publisher  = {Springer New York},
  year       = {2014},
  author     = {Dai, Jun And Ohadi, Michael M. And Das, Diganta And Pecht, Michael G.},
  abstract   = {This Book Describes The Use Of Free Air Cooling To Improve The Efficiency Of, And Cooling Of, Equipment For Use In Telecom Infrastructures. Discussed At Length Is The Cooling Of Communication Installation Rooms Such As Data Centers Or Base Stations, And This Is Intended As A Valuable Tool For The People Designing And Manufacturing Key Parts Of Communication Networks. This Book Provides An Introduction To Current Cooling Methods Used For Energy Reduction, And Also Compares Present Cooling Methods In Use In The Field. The Qualification Methods And Standard Reliability Assessments Are Reviewed, And Their Inability To Assess The Risks Of Free Air Cooling Is Discussed. The Method Of Identifying The Risks Associated With Free Air Cooling On Equipment Performance And Reliability Is Introduced. A Novel Method Of Assessment For Free Air Cooling Is Also Proposed That Utilizes Prognostics And Health Management (phm).this Book Also: Describes How The Implementation Of Free Air Cooling Can Save Energy For Cooling Within The Telecommunications Infrastructure.analyzes The Potential Risks And Failures Of Mechanisms Possible In The Implementation Of Free Air Cooling, Which Benefits Manufacturers And Equipment Designers.presents Prognostics-based Assessments To Identify And Mitigate The Risks Of Telecommunications Equipment Under Free Air Cooling Conditions, Which Can Provide The Early Warning Of Equipment Failures At Operation Stage Without Disturbing The Data Centers' Service.optimum Cooling For Data Centers Is An Ideal Book For Researchers And Engineers Interested In Designing And Manufacturing Equipment For Use In Telecom Infrastructures.},
  doi        = {10.1007/978-1-4614-5602-5},
  isbn       = {978-1-4614-5602-5},
  keywords   = {Computers / Databases / General, Computers / Hardware / General, Computers / Software Development & Engineering / Systems Analysis & Design, Technology & Engineering / Construction / General, Technology & Engineering / Construction / Heating, Ventilation & Air Conditioning, Technology & Engineering / Environmental / General, Technology & Engineering / Telecommunications},
  language   = {En},
  location   = {New York, Ny},
  shorttitle = {Optimum Cooling Of Data Centers},
  urldate    = {2016-04-27}
}

@techreport{mahdavi-data:2014,
  author      = {Mahdavi, Rod},
  title       = {Data Center Energy Efficiency Measurement Assessment Kit Guide And Specification},
  institution = {U.s. Department Of Energy},
  year        = {2014},
  type        = {Governamental},
  month       = jul,
  abstract    = {The Purpose Of This Document Is To Empower Data Center Owners And Operators With Information On The Importance Of Energy Assessments And Provide Structured Guidance For Conducting Them. Additionally, This Guide Covers How A Portable And Temporary Wireless Mesh Assessment Kit Can Be Used To Speed Up The Process And Reduce The Costs Of A Data Center Energy Use Assessment And Overcome The Issues With Respect To Shutdowns. This Kit Is Suitable Only For Data Centers With Air-cooled It Equipment. Author(s): Mahdavi, R.},
  language    = {En-us},
  location    = {Lawrence Berkeley National Laboratory},
  pages       = {20},
  url         = {https://datacenters.lbl.gov/resources/data-center-energy-efficiency},
  urldate     = {2016-04-26}
}

@techreport{usde-data:2016,
  author      = {{{U}.{S}. Department Of Energy}},
  title       = {Data Center Master List Of Energy Efficiency Actions},
  institution = {U.s. Department Of Energy},
  year        = {2016},
  type        = {Governamental},
  number      = {8},
  month       = feb,
  abstract    = {Comprehensive List Of Recommended Efficiency Actions For Data Centers. The Master List Also Feeds Into Our Data Center Profiler (dc Pro) Tool To Provide Tailored Recommendations For Improvement. Technologies: Cooling Air / Air Management, Monitoring And Controls, General It Equipment Power, Environmental Conditions.},
  language    = {En-us},
  location    = {Lawrence Berkeley National Laboratory},
  pages       = {48},
  url         = {https://datacenters.lbl.gov/resources/data-center-master-list-energy},
  urldate     = {2016-04-26}
}

@mastersThesis{aroca-eficiencia:2016,
  author      = {Aroca, Jorge Arjona},
  title       = {Eficiencia Energ{\'{e}}tica En Los Centros De Datos},
  year        = {2016},
  abstract    = {[es] Con El Auge De La Computaci{\'{o}}n En Nube, Los Centros De Datos Han Sido Llamados A Desempe{\~{n}}ar Un Papel Principal En El Escenario De Internet Hoy En D{\'{i}}a. A Pesar De Esta Relevancia, Est{\'{a}}n Probablemente Lejos De Su Apogeo, Debido A La Creciente Demanda De Almacenamiento Y Distribuci{\'{o}}n De Contenidos En La Nube, La Necesidad De Potencia De C{\'{a}}lculo O Las Cantidades Cada Vez Mayores De Datos Que Est{\'{a}}n Siendo Analizados Por Las Principales Empresas Como Google, Microsoft O Amazon. Tener Un Centro De Datos Implica Dos Cuestiones Principales: Son Terriblemente Caros De Construir, Y Que Consumen Enormes Cantidades De Energ{\'{i}}a, Por Lo Tanto, Muy Caro De Mantener. Por Esta Raz{\'{o}}n, Reduciendo El Costo De La Construcci{\'{o}}n Y El Aumento De La Eficiencia Energ{\'{e}}tica (y Por Lo Tanto La Reducci{\'{o}}n De La Huella De Carbono) De Los Centros De Datos Ha Sido Uno De Los Temas M{\'{a}}s Candentes De Investigaci{\'{o}}n En Los {\'{u}}ltimos A{\~{n}}os. En Esta Tesis Se Propone Diferentes T{\'{e}}cnicas Que Pueden Tener Un Impacto En Los Costes De Mantenimiento De Los Centros De Datos De Cualquier Tama{\~{n}}o, Desde Peque{\~{n}}as Escala Para Grandes Centros De Datos.},
  institution = {Universitat Polit{\`{e}}cnica De Val{\`{e}}ncia},
  location    = {Val{\`{e}}ncia, Espa{\~{n}}a}
}

@misc{bailey-idc:2007,
  author  = {M Bailey And M Eastwood And T Grieser And L Borovick And V. Turner And R.c. Gray},
  title   = {International Data Corporation Special Study: Data Center Of The Future},
  month   = apr,
  year    = {2007},
  journal = {International Data Corporation -- Idc},
  local   = {New York, Ny},
  number  = {06c4799}
}

@inproceedings{xu-calculating:2013,
  author    = {Xu, Yongmei And Deng, Yuhui And Du, Lan},
  title     = {Calculating The Power Usage Effectiveness Of Data Centers By Using Weighted Average Workload},
  booktitle = {2013 8\textsuperscript{th} 3pgcic},
  year      = {2013},
  month     = oct,
  abstract  = {The Traditional Approaches Of Calculating Pue (power Usage Effectiveness) In Data Centers Ignore The Impacts Of The Time Factor. The Methods Cannot Accurately Reflect The Long-term Operation Efficiency Of Data Centers. This Paper Investigates The Impact Of Workload On The Pue, And Proposes To Compute The Pue By Leveraging Weighted Average Workload. Theoretical Analysis And Experimental Evaluation Demonstrate That Workload Normally Has A Significant Impact On The Average Pue. The Proposed Approach Can Achieve A More Accurate Pue In Contrast To The Traditional Methods.},
  doi       = {10.1109/3PGCIC.2013.54},
  keywords  = {Average Pue, Computer Centres, Data Centers, Energy Consumption, Energy Efficiency, Green Products, Long-term Operation Efficiency, Power Measurement, Power Usage Effectiveness Calculation, Pue, Temperature Distribution, Time Factor, Time Measurement, Uninterruptible Power Systems, Weighted Average Workload, Weight Measurement}
}

@inproceedings{rossigneux-generic:2014,
  author    = {Rossigneux, F. And Lefevre, L. And Gelas, J. P. And Assuncao, M. D. D},
  title     = {A Generic And Extensible Framework For Monitoring Energy Consumption Of Openstack Clouds},
  booktitle = {2014 IEEE 4\textsuperscript{th} Bdcloud},
  year      = {2014},
  pages     = {696--702},
  month     = dec,
  abstract  = {Although Cloud Computing Has Been Transformational To The It Industry, It Is Built On Large Data Centres That Often Consume Massive Amounts Of Electrical Power. Efforts Have Been Made To Reduce The Energy Clouds Consume, With Certain Data Centres Now Approaching A Power Usage Effectiveness (pue) Factor Of 1.08. While This Is An Incredible Mark, It Also Means That The It Infrastructure Accounts For A Large Part Of The Power Consumed By A Data Centre. Hence, Means To Monitor And Analyse How Energy Is Spent Have Never Been So Crucial. Such Monitoring Is Required Not Only For Understanding How Power Is Consumed, But Also For Assessing The Impact Of Energy Management Policies. In This Article, We Draw Lessons From Experience On Monitoring Large-scale Systems And Introduce An Energy Monitoring Software Framework Called Kilo Watt Api (kwapi), Able To Handle Open-stack Clouds. The Framework - Whose Architecture Is Scalable, Extensible, And Completely Integrated Into Open Stack - Supports Several Wattmeter Devices, Multiple Measurement Formats, And Minimises Communication Overhead.},
  doi       = {10.1109/BDCloud.2014.105},
  keywords  = {Cloud, Cloud Computing, Computer Architecture, Computer Centres, Data Centres, Electrical Power, Energy Consumption, Energy Consumption Monitoring, Energy Efficiency, Energy Management Policies, Energy Monitoring, Extensible Framework, Generic Framework, It Infrastructure, Kilo Watt Api, Kwapi, Kwapi, Measurement, Message Systems, Monitoring, Openstack Clouds, Open Stack Clouds, Power Demand, Power Usage Effectiveness, Pue, Wattmeters}
}

#

@article{brown2-report:2008,
  author      = {Richard E., Brown And Eric R., Masanet And Bruce, Nordman And William F., Tschudi And Arman, Shehabi And John, Stanley And Jonathan G., Koomey And Dale A., Sartor And Peter T., Chan},
  title       = {Server And Data Center Energy Efficiency: Public Law 109-431},
  journal     = {Usa Federal Congress},
  year        = {2008},
  month       = jun,
  abstract    = {This Report Was Prepared In Response To The Request From Congress Stated In Public Law 109-431 (h.r. 5646), ''an Act To Study And Promote The Use Of Energy Efficient Computer Servers In The United States.'' This Report Assesses Current Trends In Energy Use And Energy Costs Of Data Centers And Servers In The U.s. (especially Federal Government Facilities) And Outlines Existing And Emerging Opportunities Fo Improved Energy Efficiency. It Also Makes Recommendations For Pursuing These Energy-efficiency Opportunities Broadly Across The Country Though The Use Of Information And Incentive-based Programs. Findings From This Report Include:an Estimate That Data Centers Consumed About 61 Billion Kilowatt-hours (kwh) In 2006, Roughly 1.5% Of Total U.s. Electricity Consumption, Or About 4.5 Billion In Electricity Costs.federal Servers And Data Centers Alone Account For Approximately 6 Billion Kwh (10 Of This Electricity Consumption, Or About 4.5 Billion In Electricity Costs.assuming Current Trends Continue, In 5 Years The National Energy Consumption By Servers And Data Centers Is Expected To Nearly Double, To Nearly 100 Billion Kwh.existing Technologies And Strategies Could Reduce Typical Server Energy Use By An Estimated 25% - Even Greater Energy Savings Are Possible With Advanced Technologies.assuming State-of-the-art Energy Efficiency Practices Are Implemented Throughout U.s. Data Centers, This Projected Energy Use Can Be Reduced By Up To 55% Compared To Current Efficiency Trends. This Report Makes Several Recommendations For Policies To Achieve This Savings Potential. Among These Recommendations Are Standarized Permormance Measurement For Data Centers And Their Equipment, Leadership On Energy Efficiency In Federal Data Centers, A Private Sector Energy Challenge, Information On Best Practices, And Further Research And Development On Energy Efficiency Technologies And Practices.},
  attachments = {Http://eetd.lbl.gov/sites/all/files/pdf_4.pdf},
  keywords    = {Combined Heat And Power, Computers, Data Centers, Energy Forecasting, Energy Star, Information Technology, Servers},
  location    = {Berkeley, Ca}
}

@misc{thibodeau-data:2014,
  author   = {Thibodeau, Patrick},
  title    = {Data Centers Are The New Polluters},
  month    = aug,
  year     = {2014},
  abstract = {U.s. Data Centers Use More Electricity Than They Need, A New Report Finds, And It Managers Are Too Cautious About Managing Power And Businesses Are Unwilling To Invest In Energy Conservation.},
  journal  = {Computerworld},
  url      = {http://www.computerworld.com/article/2598562/data-center/data-centers-are-the-new-polluters.html},
  urldate  = {2016-03-12}
}

@article{morabito-power:2015,
  author     = {Morabito, Roberto},
  title      = {Power Consumption Of Virtualization Technologies: An Empirical Investigation},
  journal    = {IEEE/ACM UCC 2015 SD3C},
  year       = {2015},
  publisher  = {IEEE},
  shorttitle = {Power Consumption Of Virtualization Technologies},
  url        = {http://arxiv.org/abs/1511.01232}
}

@misc{villars-idc:2014,
  author   = {Villars, Richard L. And Shirer, Michael},
  title    = {Idc Finds Growth, Consolidation, And Changing Ownership Patterns In Worldwide Datacenter Forecast},
  month    = nov,
  year     = {2014},
  abstract = {A New Forecast From International Data Corporation (idc) Shows That The Transition To The 3\textsuperscript{rd} Platform Is Having A Direct Impact On Datacenter Construction And Remodeling. Idc Expects The Total Number Of Datacenters (all Types) Deployed Worldwide Will Peak At 8.6 Million In 2017 And Then Begin To Decline Slowly. This Shift Will Be Triggered By A Decline In Internal Datacenter Server Rooms Starting In 2016 And Internal Server Closets Starting In 2017. All Other Datacenter Categories Will Continue To Grow Throughout The Forecast Period, With The Number Of Service Provider Datacenters Increasing Much Faster. Despite A Decline In The Number Of Datacenters, Total Worldwide Datacenter Space Will Continue To Increase, Growing From 1.58 Billion Square Feet In 2013 To 1.94 Billion Square Feet In 2018},
  journal  = {Www.idc.com},
  url      = {http://www.idc.com/getdoc.jsp?containerId=prUS25237514},
  urldate  = {2016-03-08}
}

@PhdThesis{ganesh-data:2012,
  author      = {Ganesh, Lakshmi},
  title       = {Data Center Energy Management},
  year        = {2012},
  type        = {Phd Thesis},
  month       = jan,
  abstract    = {Data Centers Form The Underpinnings Of The Global Technology Revolution That Is Cloud Computing. There Is Enormous Pressure For Data Center Growth And Expansion, To Meet The Computational Demands Of An Increasingly Digital World. With Energy Costs Overtaking Server Costs In Data Centers, Energy Is Fast Becoming A Significant Bottleneck To Data Center Scale-out. Further, The Global Data Center Energy Footprint Is Growing To Be A Significant Burden On The World{\textquoteright}s Energy Resources. Yet Energy Is A Signally Ill-managed Resource In Most Data Centers; Average Data Center Energy Efficiency Is Less Than 50%. With Increasing Industry Awareness Of The Magnitude And Urgency Of This Problem, Many Solutions Are Cropping Up To Combat Each Of The Several Sources Of Data Center Energy Inefficiency. The Objective Of This Dissertation Is Three-fold: First, We Examine The Causes Of Data Center Energy Inefficiency From First Principles, And Identify The Challenges Involved In Addressing Them. We Find Two Categories Of Energy Inefficiency: Idle Resource Energy Consumption, And Support Infrastructure Energy Consumption. Second, We Present Solutions To Address Each Form Of Inefficiency. We Describe Two Ways To Combat Idle Resource Energy Consumption, And Also Present A Systemic Solution To Tackle Both Forms Of Energy Inefficiency. Finally, Throughout This Dissertation, We Examine The Related Work And Literature, And Attempt To Map Them Into The Solution Space To Identify How The Solutions Relate With Each Other, And What Gaps Remain To Be Addressed. The Cloud Has The Potential To Enable Everything From Ubiquitous Computing And Universal Access To Knowledge, To Smart Power Grids, Greater Social Connectivity, And Near-infinite Extensibility Of Compute/storage Power. The Cloud Turns Computation Into A Utility, And By Doing So, Has The Potential To Make It Accessible To A Much Larger Part Of The World. This Dissertation Explores Ways To Enable Sustainable Scaling Of The Data Centers That Power The Cloud And Enable This Vision.},
  institution = {Cornell},
  language    = {En-us},
  location    = {Ithaca, New York, Usa},
  url         = {http://fireless.cs.cornell.edu/publications/thesis_lakshmi.pdf},
  urldate     = {2016-03-12}
}

@inCollection{patterson-tue:2013,
  author    = {Patterson, Michael K. And Poole, Stephen W. And Hsu, Chung-hsing And Maxwell, Don And Tschudi, William And Coles, Henry And Martinez, David J. And Bates, Natalie},
  title     = {Tue, A New Energy-efficiency Metric Applied At Ornl{\textquoteright}s Jaguar},
  booktitle = {Supercomputing},
  publisher = {Springer Berlin Heidelberg},
  year      = {2013},
  editor    = {Kunkel, Julian Martin And Ludwig, Thomas And Meuer, Hans Werner},
  number    = {7905},
  series    = {Lecture Notes In Computer Science},
  pages     = {372--382},
  month     = jun,
  note      = {Doi: 10.1007/978-3-642-38750-028},
  abstract  = {The Metric, Power Usage Effectiveness (pue), Has Been Successful In Improving Energy Efficiency Of Data Centers, But It Is Not Perfect. One Challenge Is That Pue Does Not Account For The Power Distribution And Cooling Losses Inside It Equipment. This Is Particularly Problematic In The Hpc (high Performance Computing) Space Where System Suppliers Are Moving Cooling And Power Subsystems Into Or Out Of The Cluster. This Paper Proposes Two New Metrics: Itue (it-power Usage Effectiveness), Similar To Pue But {\textquotedblleft}inside{\textquotedblright} The It And Tue (total-power Usage Effectiveness), Which Combines The Two For A Total Efficiency Picture. We Conclude With A Demonstration Of The Method, And A Case Study Of Measurements At Ornl{\textquoteright}s Jaguar System. Tue Provides A Ratio Of Total Energy, (internal And External Support Energy Uses) And The Specific Energy Used In The Hpc. Tue Can Also Be A Means For Comparing Hpc Site To Hpc Site.},
  copyright = {{\copyright}2013 Springer-verlag Berlin Heidelberg},
  doi       = {10.1007/978-3-642-38750-0_28},
  isbn      = {978-3-642-38749-4 978-3-642-38750-0},
  keywords  = {Computer System Implementation, Data Center, Energy-efficiency, Hpc, Metrics, Performance And Reliability, Processor Architectures, Special Purpose And Application-based Systems, System Performance And Evaluation},
  language  = {En},
  urldate   = {2016-03-12}
}

@book{ashrae-real-time:2010,
  title     = {Real-time Energy Consumption Measurements In Data Centers: Ashrae Datacom},
  publisher = {American Society Of Heating, Refrigerating And Air-conditioning Engineers},
  year      = {2010},
  author    = {Ashrae},
  number    = {9},
  series    = {Ashrae Datacom Series},
  month     = jan,
  isbn      = {978-1-933742-73-1},
  language  = {English},
  lccn      = {2011377217},
  location  = {Atlanta, Ga}
}

@misc{delforge-americas:2014,
  author   = {Delforge, Pierre},
  title    = {America's Data Centers Consuming And Wasting Growing Amounts Of Energy},
  year     = {2014},
  abstract = {Data Centers Are One Of The Largest And Fastest Growing Consumers Of Electricity In The United States. In 2013, U.s. Data Centers Consumed An Estimated 91 Billion Kilowatt-hours Of Electricity -- Enough Electricity To Power All The Households In New York City Twice Over -- And Are On-track To Reach 140 Billion Kilowatt-hours By 2020.},
  journal  = {Natural Resources Defense Council -- Nrdc},
  language = {En-us},
  url      = {http://www.nrdc.org/energy/data-center-efficiency-assessment.asp},
  urldate  = {2016-03-11}
}

@techreport{turner-digital:2014,
  author      = {Turner, Vernon And Reinsel, David And Gantz, John F. And Minton, Stephen},
  title       = {The Digital Universe Of Opportunities: Rich Data And The Increasing Value Of The Internet Of Things},
  institution = {Emc And Idc},
  year        = {2014},
  type        = {White Paper},
  number      = {1672},
  month       = apr,
  copyright   = {Reserved},
  location    = {Usa},
  pages       = {10},
  url         = {http://www.emc.com/leadership/digital-universe/2014iview/executive-summary.htm},
  urldate     = {2016-03-10}
}

@PhdThesis{silva-c2:2009,
  author      = {Silva, Marcio Augusto De Lima E},
  title       = {Uma Infraestrutura De Comando E Controle De Data Center Para Um Conjunto De Recursos Computacionais.},
  year        = {2009},
  type        = {Tese},
  month       = jun,
  abstract    = {O Crescimento Das Necessidades De Recursos Computacionais Gerado Por Novas Classes De Aplica{\c{c}}{\~{o}}es Comerciais E Cient{\'{i}}ficas Apresenta Um Novo Tipo De Desafio Para Infraestruturas Computacionais. O Acelerado Crescimento Das Demandas Por Recursos Promove Um Acelerado Crescimento No N{\'{u}}mero Absoluto De Elementos Computacionais Nestas. Nesse Cen{\'{a}}rio, O Provisionamento E A Opera{\c{c}}{\~{a}}o De Sistemas Tornam-se Tarefas Progressivamente Complexas, Devido Primariamente Ao Aumento Em Escala. Este Trabalho Prop{\~{o}}e Um Modelo Para Uma Infraestrutura Computacional Que Opera Como Um Reposit{\'{o}}rio Abstrato De Recursos Computacionais De Tempo De Execu{\c{c}}{\~{a}}o Com N{\'{i}}veis Vari{\'{a}}veis De Consumo. Desenhado Para Operar Como Um Ensemble (i.e. Um Conjunto Coordenado) De Recursos Computacionais, Grandes N{\'{u}}meros De Elementos S{\~{a}}o Agregados Em Conjuntos De Servidores De Recursos De Processamento, Armazenamento E Comunica{\c{c}}{\~{a}}o. O Ensemble {\'{e}} Concebido E Implementado Com Ampla Utiliza{\c{c}}{\~{a}}o De Tecnologias De Virtualiza{\c{c}}{\~{a}}o E Possui Um Mecanismo De Provisionamento E Opera{\c{c}}{\~{a}}o Organizado Como Uma Estrutura Distribu{\'{i}}da De Comando E Controle (command And Control, Ou C\textsuperscript{2}). A Implementa{\c{c}}{\~{a}}o De Uma Prova De Conceito De Tal Infraestrutura Computacional {\'{e}} Apresentada, E A Valida{\c{c}}{\~{a}}o Da Proposta {\'{e}} Realizada Atrav{\'{e}}s De Uma Combina{\c{c}}{\~{a}}o De Resultados Experimentais E Emula{\c{c}}{\~{a}}o.},
  institution = {Usp},
  language    = {Pt-br},
  url         = {http://www.teses.usp.br/teses/disponiveis/3/3141/tde-01092009-151011/},
  urldate     = {2016-03-10}
}

@inproceedings{piatek-modeling:2015,
  author    = {Piatek, Wojciech And Oleksiak, Ariel And Vor Dem Berge, Micha},
  title     = {Modeling Impact Of Power- And Thermal-aware Fans Management On Data Center Energy Consumption},
  booktitle = {Proceedings Of The 2015 ACM Sixth International Conference On Future Energy Systems},
  year      = {2015},
  series    = {E-energy '15},
  pages     = {253--258},
  publisher = {ACM},
  abstract  = {In This Paper We Study The Power Usage And Thermal Management Of Micro Servers To Analyze Their Impact On The Overall Data Center Energy Consumption. We Propose Thermal Models Of Micro Servers Based On Analytical Approach Tuned With Parameters Derived From Empirical Tests. We Demonstrate How Fan Management Configuration Affects The Energy Consumption Of Servers And The Whole Data Center. We Also Apply The Proposed Model To Predict Temperature Changes In A Short Time Ahead And Take Advantage Of These Predictions To Improve Fan Management. We Show Why Pue Is Not Sufficient Or Can Be Even Misleading In Minimizing Data Center Energy Consumption. To Mitigate This Issue, We Propose Metrics That Can Be Used To Reflect Correctly Fans Management Impact On The Overall Energy Consumption.},
  doi       = {10.1145/2768510.2768525},
  isbn      = {978-1-4503-3609-3},
  keywords  = {Data Centers, Energy-efficiency, Fans Management, Microservers, Power And Thermal Simulations, Power Leakage},
  location  = {New York, Ny, Usa},
  urldate   = {2016-03-09}
}

	volume = {11}, number = {1}, pages = {2:1--2:33},

@article{toosi-auction:2016,
  author   = {Toosi, Adel Nadjaran And Vanmechelen, Kurt And Khodadadi, Farzad And Buyya, Rajkumar},
  title    = {An Auction Mechanism For Cloud Spot Markets},
  journal  = {ACM 11\textsuperscript{th} Taas},
  year     = {2016},
  month    = feb,
  abstract = {Dynamic Forms Of Resource Pricing Have Recently Been Introduced By Cloud Providers That Offer Infrastructure As A Service (iaas) Capabilities In Order To Maximize Profits And Balance Resource Supply And Demand. The Design Of A Mechanism That Efficiently Prices Perishable Cloud Resources In Line With A Provider{\textquoteright}s Profit Maximization Goal Remains An Open Research Challenge, However. In This Article, We Propose The Online Extended Consensus Revenue Estimate Mechanism In The Setting Of A Recurrent, Multiunit And Single Price Auction For Iaas Cloud Resources. The Mechanism Is Envy-free, Has A High Probability Of Being Truthful, And Generates A Near Optimal Profit For The Provider. We Combine The Proposed Auction Design With A Scheme For Dynamically Calculating Reserve Prices Based On Data Center Power Usage Effectiveness (pue) And Electricity Costs. Our Simulation-based Evaluation Of The Mechanism Demonstrates Its Effectiveness Under A Broad Variety Of Market Conditions. In Particular, We Show How It Improves On The Classical Uniform Price Auction, And We Investigate The Value Of Prior Knowledge On The Execution Time Of Virtual Machines For Maximizing Profit. We Also Developed A System Prototype And Conducted A Small-scale Experimental Study With A Group Of 10 Users That Confirms The Truthfulness Property Of The Mechanism In A Real Test Environment.},
  doi      = {10.1145/2843945},
  issn     = {1556-4665},
  keywords = {Auction, Cloud Computing, Mechanism Design, Multi-unit, Online, Pricing, Pue, Reserve Price},
  urldate  = {2016-03-09}
}

@techreport{carvalho-ebook-redesecia:2015,
  author      = {Silva, Fabr{\'{i}}cio Carvalho},
  title       = {E-book - Data Centers (cpd) Para Pequenas E M{\'{e}}dias Empresas},
  institution = {Redes\&cia},
  year        = {2015},
  type        = {White Paper},
  month       = apr,
  abstract    = {Traz Os Principais Conceitos Necess{\'{a}}rios Para Um Bom Projeto De Data Centers Para Pequenas E M{\'{e}}dias Empresa, Tamb{\'{e}}m Conhecido Como Sala Segura Ou Cpd.},
  language    = {Pt-br},
  pages       = {39},
  urldate     = {2016-02-21}
}

@book{minoli-designing:2011,
  title      = {Designing Green Networks And Network Operations: Saving Run-the-engine Costs},
  publisher  = {Crc Press},
  year       = {2011},
  author     = {Minoli, Daniel},
  month      = apr,
  abstract   = {In Recent Years, Socio-political Trends Toward Environmental Responsibility And The Pressing Need To Reduce Run-the-engine (rte) Costs Have Resulted In The Concept Of Green It. Although A Significant Amount Of Energy Is Used To Operate Routing, Switching, And Transmission Equipment, Comparatively Less Attention Has Been Paid To Green Networking. A Clear And Concise Introduction To Green Networks And Green Network Operations, Designing Green Networks And Network Operations: Saving Run-the-engine Costs{~}guides You Through The Techniques Available To Achieve Efficiency Goals For Corporate And Carrier Networks, Including Deploying More Efficient Hardware, Blade Form-factor Routers And Switches, And Pursuing Consolidation, Virtualization, And Network And Cloud Computing. The Book: Delineates Techniques To Minimize Network Power, Cooling, Floor Space, And Online Storage While Optimizing Service Performance, Capacity, And Availability Discusses Virtualization, Network Computing, And Web Services As Approaches For Green Data Centers And Networks Emphasizes Best Practices And Compliance With International Standards For Green Operations Extends The Green Data Center Techniques To The Networking Environment Incorporates Green Principles In The Intranet, Extranet, And The Entire It Infrastructures Reviews Networking, Power Management, Hvac And Crac Basics Presents Methodical Steps Toward A Seamless Migration To Green It And Green Networking},
  isbn       = {978-1-4398-1639-4},
  keywords   = {Business & Economics / Production & Operations Management, Computers / Information Technology, Computers / Networking / General, Technology & Engineering / Engineering (general)},
  language   = {En},
  shorttitle = {Designing Green Networks And Network Operations}
}

@PhdThesis{framework:2009,
  author      = {Goldhar, Marcos Porto},
  title       = {Um Framework De M{\'{e}}tricas De Produtividade E Efici{\^{e}}ncia Energ{\'{e}}tica Em Data Centers},
  year        = {2009},
  type        = {Disserta{\c{c}}{\~{a}}o},
  institution = {Ufpe},
  language    = {Ptbr},
  location    = {Recife},
  url         = {http://repositorio.ufpe.br:8080/xmlui/handle/123456789/2306},
  urldate     = {2016-01-25}
}

@book{li-wireless:2008,
  title     = {Wireless Sensor Networks And Applications},
  publisher = {Springer Us},
  year      = {2008},
  author    = {Li, Yingshu And Thai, My T. And Wu, Weili},
  series    = {Signals And Communication Technology},
  doi       = {10.1007/978-0-387-49592-7},
  isbn      = {978-0-387-49591-0 978-0-387-49592-7},
  keywords  = {Computers / Networking / General, Computers / Networking / Local Area Networks (lans), Technology & Engineering / Mobile & Wireless Communications},
  location  = {Boston, Ma},
  urldate   = {2015-03-24}
}

@inCollection{abbas-monitoring:2015,
  author    = {Abbas, Cl{\'{a}}udia Jacy Barenco And Orozco, Ana Lucila Sandoval And Villalba, Luis Javier Garc{\'{i}}a},
  title     = {Monitoring Of Data Centers Using Wireless Sensor Networks},
  booktitle = {Handbook On Data Centers},
  publisher = {Springer New York},
  year      = {2015},
  editor    = {Khan, Samee U. And Zomaya, Albert Y.},
  pages     = {1171--1183},
  note      = {Doi: 10.1007/978-1-4939-2092-140},
  abstract  = {As Data Center Energy Densities, Measured In Power Per Square Foot, Increase, Energy Savings For Cooling Can Be Carried Out By Applying Wsn Technology And Using The Gathered Information To Efficiently Manage The Data Center.},
  copyright = {2015 Springer Science Business Media New York},
  isbn      = {978-1-4939-2091-4 978-1-4939-2092-1},
  keywords  = {Communications Engineering, Networks, Database Management, Data Storage Representation, Systems And Data Security},
  language  = {En},
  url       = {http://link.springer.com/chapter/10.1007/978-1-4939-2092-1\_40},
  urldate   = {2015-11-13}
}

@inproceedings{khanjani-aspects:2011,
  author    = {Khanjani, A. And Sulaiman, Riza},
  title     = {The Aspects Of Choosing Open Source Versus Closed Source},
  booktitle = {2011 IEEE Symposium On Computers Informatics (isci)},
  year      = {2011},
  pages     = {646--649},
  month     = mar,
  abstract  = {Closed Source Software, Is A Type Of Software That Is Licensed Under The Exclusive Legal Right Of Its Owner. It Is Also Purchasable By Users By Paying Amount Of Money. Open Source Software (oss) Is Software Available With Its Source Code Under An Open Source License To Study And Modify The Code. Open Source Software Development (ossd) Is The Process To Develop Oss. Many Industries Try Using Ossd As They See The Advantages Of Open Source Compared To Closed Source Software Development. This Research Presents The Reasons Of Recently Using Ossd Model Rather Than Traditional Closed Source Approach. The Result Is To Show The Differences Between Closed Source And Open Source Process And How Open Source Can Effect On Quality Through Its Particular Features. It Also Identifies And Addresses The Challenges And Benefits Faced By The Users Against Traditional Closed Source Model.},
  doi       = {10.1109/ISCI.2011.5958992},
  keywords  = {Closed Source, Closed Source Software, Companies, Encyclopedias, Internet, Licenses, Open Source Software, Open Source Software Development, Ossd Model, Procedures And Open Source, Process, Programming, Public Domain Software, Software Development Management}
}

@article{fernandez-usosl:2013,
  author   = {Rafael Fernandez},
  title    = {O Uso De Softwares Livres Na Gest{\~{a}}o P{\'{u}}blica De Acervos Informacionais: O Caso Do Koha Nas Bibliotecas De S{\~{a}}o Bernardo Do Campo},
  journal  = {Informa{\c{c}}{\~{a}}o \& Informa{\c{c}}{\~{a}}o},
  year     = {2013},
  volume   = {18},
  number   = {2},
  pages    = {231--248},
  issn     = {1981-8920},
  keywords = {Automa{\c{c}}{\~{a}}o De Bibliotecas; Gest{\~{a}}o P{\'{u}}blica; Bibliotecas Escolares; Bibliotecas P{\'{u}}blicas; Koha.},
  url      = {http://www.uel.br/revistas/uel/index.php/informacao/article/view/16174}
}

@book{khan-handbook:2015,
  title     = {Handbook On Data Centers},
  publisher = {Springer},
  year      = {2015},
  author    = {Khan, Samee Ullah And Zomaya, Albert Y.},
  month     = may,
  abstract  = {This Handbook Offers A Comprehensive Review Of The State-of-the-art Research Achievements In The Field Of Data Centers. Contributions From International, Leading Researchers And Scholars Offer Topics In Cloud Computing, Virtualization In Data Centers, Energy Efficient Data Centers, And Next Generation Data Center Architecture. It Also Comprises Current Research Trends In Emerging Areas, Such As Data Security, Data Protection Management, And Network Resource Management In Data Centers. Specific Attention Is Devoted To Industry Needs Associated With The Challenges Faced By Data Centers, Such As Various Power, Cooling, Floor Space, And Associated Environmental Health And Safety Issues, While Still Working To Support Growth Without Disrupting Quality Of Service. The Contributions Cut Across Various It Data Technology Domains As A Single Source To Discuss The Interdependencies That Need To Be Supported To Enable A Virtualized, Next-generation, Energy Efficient, Economical, And Environmentally Friendly Data Center. This Book Appeals To A Broad Spectrum Of Readers, Including Server, Storage, Networking, Database, And Applications Analysts, Administrators, And Architects. It Is Intended For Those Seeking To Gain A Stronger Grasp On Data Center Networks: The Fundamental Protocol Used By The Applications And The Network, The Typical Network Technologies, And Their Design Aspects. The Handbook Of Data Centers Is A Leading Reference On Design And Implementation For Planning, Implementing, And Operating Data Center Networks.},
  isbn      = {978-1-4939-2092-1},
  keywords  = {Computers / Databases / Data Mining, Computers / Databases / General, Computers / Information Technology, Computers / Security / General, Computers / System Administration / Storage & Retrieval, Technology & Engineering / Telecommunications},
  language  = {En}
}

@book{geng-data:2014,
  title     = {Data Center Handbook},
  publisher = {John Wiley \& Sons},
  year      = {2014},
  author    = {Geng, Hwaiyu},
  month     = dec,
  abstract  = {Provides The Fundamentals, Technologies, And Best Practices In Designing, Constructing And Managing Mission Critical, Energy Efficient Data Centers Organizations In Need Of High-speed Connectivity And Nonstop Systems Operations Depend Upon Data Centers For A Range Of Deployment Solutions. A Data Center Is A Facility Used To House Computer Systems And Associated Components, Such As Telecommunications And Storage Systems. It Generally Includes Multiple Power Sources, Redundant Data Communications Connections, Environmental Controls (e.g., Air Conditioning, Fire Suppression) And Security Devices. With Contributions From An International List Of Experts, The Data Center Handbook Instructs Readers To: Prepare Strategic Plan That Includes Location Plan, Site Selection, Roadmap And Capacity Planning Design And Build {\textquotedblleft}green{\textquotedblright} Data Centers, With Mission Critical And Energy-efficient Infrastructure Apply Best Practices To Reduce Energy Consumption And Carbon Emissions Apply It Technologies Such As Cloud And Virtualization Manage Data Centers In Order To Sustain Operations With Minimum Costs Prepare And Practice Disaster Reovery And Business Continuity Plan The Book Imparts Essential Knowledge Needed To Implement Data Center Design And Construction, Apply It Technologies, And Continually Improve Data Center Operations.},
  isbn      = {978-1-118-93757-0},
  keywords  = {Computers / Databases / Data Warehousing, Computers / Information Technology},
  language  = {En}
}

@article{heller-elastictree:2010,
  author     = {Heller, Brandon And Seetharaman, Srinivasan And Mahadevan, Priya And Yiakoumis, Yiannis And Sharma, Puneet And Banerjee, Sujata And Mckeown, Nick},
  title      = {Elastictree: Saving Energy In Data Center Networks.},
  journal    = {Nsdi},
  year       = {2010},
  volume     = {10},
  pages      = {249--264},
  shorttitle = {Elastictree},
  url        = {http://www.usenix.org/event/nsdi10/tech/full_papers/heller.pdf},
  urldate    = {2015-11-13}
}

@article{brown-report:2008,
  author   = {Brown, Richard E. And Masanet, Eric R. And Nordman, Bruce And Tschudi, William F. And Shehabi, Arman And Stanley, John And Koomey, Jonathan G. And Sartor, Dale A. And Chan, Peter T.},
  title    = {Report To Congress On Server And Data Center Energy Efficiency: Public Law 109-431},
  journal  = {Lawrence Berkeley National Laboratory},
  year     = {2008},
  number   = {Lbnl- 363e},
  pages    = {137},
  month    = jun,
  abstract = {This Report Was Prepared In Response To The Request From Congress Stated In Public Law 109-431 (h .r . 5646), {\textquotedblright}an Act To Study And Promote The Use Of Energy Efficient Computer Servers In The United States .{\textquotedblright} This Report Assesses Current Trends In Energy Use And Energy Costs Of Data Centers And Servers In The U.s. (especially Federal Government Facilities) And Outlines Existing And Emerging Opportunities Fo Improved Energy Efficiency . It Also Makes Recommendations For Pursuing These Energy-efficiency Opportunities Broadly Across The Country Though The Use Of Information And Incentive-based Programs .findings From This Report Include:an Estimate That Data Centers Consumed About 61 Billion Kilowatt-hours (kwh) In 2006, Roughly 1 .5% Of Total U.s. Electricity Consumption, Or About $4 .5 Billion In Electricity Costs .federal Servers And Data Centers Alone Account For Approximately 6 Billion Kwh (10 Of This Electricity Consumption, Or About $4 .5 Billion In Electricity Costs .assuming Current Trends Continue, In 5 Years The National Energy Consumption By Servers And Data Centers Is Expected To Nearly Double, To Nearly 100 Billion Kwh .existing Technologies And Strategies Could Reduce Typical Server Energy Use By An Estimated 25% - Even Greater Energy Savings Are Possible With Advanced Technologies .assuming State-of-the-art Energy Efficiency Practices Are Implemented Throughout U.s. Data Centers, This Projected Energy Use Can Be Reduced By Up To 55% Compared To Current Efficiency Trends .this Report Makes Several Recommendations For Policies To Achieve This Savings Potential . Among These Recommendations Are Standarized Permormance Measurement For Data Centers And Their Equipment, Leadership On Energy Efficiency In Federal Data Centers, A Private Sector Energy Challenge, Information On Best Practices, And Further Research And Development On Energy Efficiency Technologies And Practices .},
  keywords = {Combined Heat And Power, Computers, Data Centers, Energy Forecasting, Energy Star, Information Technology, Servers},
  language = {En-us},
  series   = {Lbnl- 363e},
  url      = {https://ses.lbl.gov/sites/all/files/pdf_1.pdf}
}

@article{koomey-growth:2011,
  author  = {Koomey, Jonathan},
  title   = {Growth In Data Center Electricity Use 2005 To 2010},
  journal = {A Report By Analytical Press, Completed At The Request Of The New York Times},
  year    = {2011},
  pages   = {9},
  url     = {http://www.missioncriticalmagazine.com/ext/resources/MC/Home/Files/PDFs/Koomey_Data_Center.pdf},
  urldate = {2015-11-13}
}

@article{bianzino-apples:2011,
  author     = {Bianzino, Aruna Prem And Raju, Anand Kishore And Rossi, Dario},
  title      = {Apples-to-apples: A Framework Analysis For Energy-efficiency In Networks},
  journal    = {Sigmetrics Perform. Eval. Rev.},
  year       = {2011},
  volume     = {38},
  number     = {3},
  pages      = {81--85},
  month      = jan,
  abstract   = {Research On Energy-efficiency Of Communication Networks Has Already Gained The Attention Of A Broad Research Community. Specifically, We Consider Efforts Towards Improving Environmental Sustainability By Making Networks Energyaware. An Important Step In This Direction Is Establishing A Comprehensive Methodology For Measuring And Reporting The Energy Consumption Of The Network. In This Work, We Compare And Contrast Various Energy-related Metrics Used In The Recent Literature, By Means Of A Taxonomy Definition, As Well As Through Relevant Case Studies. We Believe This To Be A First Necessary Step Towards The Definition Of A Common Framework For The Performance Evaluation Of Energy-aware Networks.},
  doi        = {10.1145/1925019.1925036},
  issn       = {0163-5999},
  shorttitle = {Apples-to-apples},
  urldate    = {2015-08-17}
}

@book{veras-datacenter:2009,
  title      = {Datacenter - Componente Central De Infraestrutura De Ti},
  publisher  = {Brasport},
  year       = {2009},
  author     = {Veras, Manoel},
  abstract   = {Este Livro Apresenta Uma Vis{\~{a}}o Sobre O 'datacenter', Componente Cr{\'{i}}tico Da Infraestrutura De Ti. O Livro {\'{e}} Modular E Detalha Os Aspectos Envolvidos Na Constru{\c{c}}{\~{a}}o E No Projeto De Um 'datacenter' Tanto Do Ponto De Vista L{\'{o}}gico Como Do Ponto De Vista F{\'{i}}sico. Temas Como Virtualiza{\c{c}}{\~{a}}o, Processamento, Armazenamento E Redes S{\~{a}}o Amplamente Tratados Sob A {\'{o}}tica Do 'datacenter'. Aspectos Do Projeto Da Estrutura De Energia E Refrigera{\c{c}}{\~{a}}o E Das Instala{\c{c}}{\~{o}}es Fazem Parte Da Obra.},
  isbn       = {978-85-7452-416-0},
  language   = {Pt-br},
  location   = {Rio De Janeiro},
  shorttitle = {Datacenter - Componente Central De Infraestrutura De Ti}
}

@misc{embratel-teleco-conectividade:2015,
  author     = {Embratel-teleco},
  title      = {A Conectividade Das Empresas Brasileiras},
  year       = {2015},
  abstract   = {As Empresas Sempre Contaram Com A Tecnologia Para Aumentar A Sua Produtividade. Nos {\'{u}}ltimos Anos, Por{\'{e}}m, Este Processo Ficou Muito Acelerado, Principalmente Devido Ao Avan{\c{c}}o Das Tecnologias De Informa{\c{c}}{\~{a}}o, Que Resulta Na Forma{\c{c}}{\~{a}}o De Empresas Cada Vez Mais Digitais. Neste Contexto, A Conectividade Passa A Ser Um Elemento B{\'{a}}sico Para O Aumento Da Produtividade Das Empresas De Qualquer Porte E Em Qualquer Atividade. Para Acompanhar Este Processo, A Embratel, Em Parceria Com A Teleco, Selecionou Um Conjunto De Indicadores Para Avaliar O Qu{\~{a}}o Conectadas Est{\~{a}}o As Empresas Brasileiras, Que Deu Origem {\`{a}} Pesquisa ``a Conectividade Das Empresas Brasileiras''.},
  journal    = {A Conectividade Das Empresas Brasileiras},
  language   = {Pt-br},
  shorttitle = {A Conectividade Das Empresas Brasileiras},
  type       = {Institucional},
  urldate    = {2015-11-08}
}

@article{sanchez-antecedents:2012,
  author     = {Sanchez, Otavio Prospero And Cappellozza, Alexandre},
  title      = {Antecedents Of The Adoption Of Cloud Computing: Effects Of Infrastructure, Investment And Size},
  journal    = {Revista De Administra{\c{c}}{\~{a}}o Contempor{\^{a}}nea},
  year       = {2012},
  volume     = {16},
  number     = {5},
  pages      = {646--663},
  month      = oct,
  doi        = {10.1590/S1415-65552012000500002},
  issn       = {1415-6555},
  shorttitle = {Antecedents Of The Adoption Of Cloud Computing},
  urldate    = {2015-11-08}
}

@article{yick-wireless:2008,
  author   = {Yick, Jennifer And Mukherjee, Biswanath And Ghosal, Dipak},
  title    = {Wireless Sensor Network Survey},
  journal  = {Comput. Netw.},
  year     = {2008},
  volume   = {52},
  number   = {12},
  pages    = {2292--2330},
  month    = aug,
  abstract = {A Wireless Sensor Network (wsn) Has Important Applications Such As Remote Environmental Monitoring And Target Tracking. This Has Been Enabled By The Availability, Particularly In Recent Years, Of Sensors That Are Smaller, Cheaper, And Intelligent. These Sensors Are Equipped With Wireless Interfaces With Which They Can Communicate With One Another To Form A Network. The Design Of A Wsn Depends Significantly On The Application, And It Must Consider Factors Such As The Environment, The Application's Design Objectives, Cost, Hardware, And System Constraints. The Goal Of Our Survey Is To Present A Comprehensive Review Of The Recent Literature Since The Publication Of [i.f. Akyildiz, W. Su, Y. Sankarasubramaniam, E. Cayirci, A Survey On Sensor Networks, IEEE Communications Magazine, 2002]. Following A Top-down Approach, We Give An Overview Of Several New Applications And Then Review The Literature On Various Aspects Of Wsns. We Classify The Problems Into Three Different Categories: (1) Internal Platform And Underlying Operating System, (2) Communication Protocol Stack, And (3) Network Services, Provisioning, And Deployment. We Review The Major Development In These Three Categories And Outline New Challenges.},
  doi      = {10.1016/j.comnet.2008.04.002},
  issn     = {1389-1286},
  keywords = {Protocols, Sensor Network Deployment, Sensor Network Services, Survey, Wireless Sensor Network},
  urldate  = {2015-11-11tz}
}

@article{sung-designing:2011,
  author   = {Sung, Wen-tsai And Hsu, Yao-chi},
  title    = {Designing An Industrial Real-time Measurement And Monitoring System Based On Embedded System And Zigbee},
  journal  = {Expert Systems With Applications},
  year     = {2011},
  volume   = {38},
  number   = {4},
  pages    = {4522--4529},
  month    = apr,
  abstract = {With The Increasing Automation Of Factories, Factory Floors Are Being Covered With Machinery. Spaces Crowded With Machinery Are More Difficult And Dangerous For Personnel To Operate In. This System Attempts To Uses The Zigbee Embedded System To Improve Industrial Safety Quality. In Addition To Performing Existing Typical Monitoring Functions, This System Utilizes Zigbee Wireless Transmission Technology For Remote Monitoring. The Measurement Items Of The Industrial Applications Of This System Platform Include Length Filtering, Ground Vibration Sensing, Weight Grading, Electricity Sensing, Energy Monitoring, Temperature Monitoring, And Carbon Dioxide Concentration. Our Application Of Zigbee Combined With An Embedded System To Industrial Real-time Measurements Represents An Innovative Technology. In Addition To Discussing The System Platform In This Study, We Also Discuss Statistics And Analysis Of Measurement Data. Performing Wired And Wireless Synchronized Measurement And Monitoring Using This System Can Achieve Correct And Efficient Industrial Monitoring Operations.},
  doi      = {10.1016/j.eswa.2010.09.126},
  issn     = {0957-4174},
  keywords = {Electricity Sensing, Energy Monitoring, Industrial Monitoring, Linear Differential Transformer, Sensors, Zigbee Wireless Sensor Network},
  urldate  = {2015-11-11tz}
}

@article{mwila-approach:2014,
  author   = {Mwila, Martin K. And Djouani, Karim And Kurien, Anish},
  title    = {Approach To Sensor Node Calibration For Efficient Localisation In Wireless Sensor Networks In Realistic Scenarios},
  journal  = {Procedia Computer Science},
  year     = {2014},
  volume   = {32},
  pages    = {166--173},
  abstract = {Localisation Or Position Determination Is One Of The Most Important Applications For The Wireless Sensor Networks. Numerous Current Techniques For Localisation Of Sensor Nodes Use The Received Signal Strength Indicator (rssi) From Sensor Nodes Because Of Its Simplicity And Cost. Non-linearities In Rssi Circuits, The Antenna Radiation Pattern And Path Loss Model Parameter Estimation May Result In Accuracy Of The Localisation Algorithm. Therefore, Environmental Characterisation Of Radio Propagation Basic Mechanisms Is A Fundamental Step Toward The Design Of Ranging And Localisation Algorithms Able To Work Properly In Realistic Scenarios. Furthermore, Positioning Systems Are Migrating Towards Hybridisation Where Data Coming From Heterogeneous Technologies Are Fused To Improve Localisation Accuracy And Coverage. This Paper Presents An Improved Mathematical Model For Ranging Using Rssi In Realistic Practical Scenarios As Well As Measurement Methodologies To Use During Calibration Experiments In Order To Quantify Each Parameter Involved In A Localisation Algorithm Using A Sensor Data Fusion Approach.},
  doi      = {10.1016/j.procs.2014.05.411},
  issn     = {1877-0509},
  keywords = {Antenna Radiation Pattern, Gauss-newton Optimisation., Node Localisation, Sensor Data Fusion},
  series   = {The 5\textsuperscript{th} International Conference On Ambient Systems, Networks And Technologies (ant-2014), The 4\textsuperscript{th} International Conference On Sustainable Energy Information Technology (seit-2014)},
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050914006115},
  urldate  = {2015-11-11tz}
}

@book{gislason-zigbee:2008,
  title     = {Zigbee Wireless Networking},
  publisher = {Newnes},
  year      = {2008},
  author    = {Gislason, Drew},
  month     = oct,
  abstract  = {Zigbee Is A Standard Based On The IEEE 802.15.4 Standard For Wireless Personal Networks. This Standard Allows For The Creation Of Very Lost Cost And Low Power Networks - These Applications Run For Years Rather Than Months. These Networks Are Created From Sensors And Actuators And Can Wireless Control Many Electrical Products Such As Remote Controls, Medical, Industrial, And Security Sensors. Hundreds Of Companies Are Creating Applications Including Mitsubishi, Motorola, Freescale, And Siemens. This Book Is Written For Engineers Who Plan To Develop Zigbee Applications And Networks, To Understand How They Work, And To Evaluate This Technology To See If It Is Appropriate To A Particular Project. This Book Does Not Simply State Facts But Explains What Zigbee Can Do Through Detailed Code Examples.*details How To Plan And Develop Applications And Networks*zigbee Sensors Have Many Applications Including Industrial Automation, Medical Sensing, Remote Controls, And Security*hot Topic For Today's Electrical Engineer Because It Is Low Cost And Low Power},
  isbn      = {9780080558622},
  keywords  = {Technology & Engineering / Electrical, Technology & Engineering / Electronics / Microelectronics},
  language  = {En}
}

@article{buratti-overview:2009,
  author   = {Buratti, Chiara And Conti, Andrea And Dardari, Davide And Verdone, Roberto},
  title    = {An Overview On Wireless Sensor Networks Technology And Evolution},
  journal  = {Sensors},
  year     = {2009},
  volume   = {9},
  number   = {9},
  pages    = {6869--6896},
  month    = aug,
  doi      = {10.3390/s90906869},
  issn     = {1424-8220},
  language = {En},
  url      = {http://www.mdpi.com/1424-8220/9/9/6869/},
  urldate  = {2015-11-11tz}
}

@misc{koomey:2007,
  author = {Koomey, Jonathan G And Others},
  title  = {Estimating Total Power Consumption By Servers In The Us And The World},
  year   = {2007}
}

@misc{comerford-how:2015,
  author   = {Comerford, Tim},
  title    = {How Data Center Operators Can Avoid Energy Price Hikes This Winter},
  month    = jan,
  year     = {2015},
  abstract = {Energy Consumption Is One Of The Largest Operating Expenses For A Data Center, Contributing To Nearly 50 Percent Of Total Data Center Spend. Data Center Operators And Owners Can Minimize The Impact Of Unpredictable Energy Markets By Better Understanding The Markets And Establishing Smart Energy Procurement Strategies.},
  journal  = {Data Center Knowledge},
  language = {En-us},
  url      = {http://www.datacenterknowledge.com/archives/2015/01/29/data-center-operators-can-avoid-energy-price-hikes-winter/},
  urldate  = {2015-05-16}
}

@article{hoogendoorn-what:2014,
  author   = {Hoogendoorn, Brigitte And Guerra, Daniela And Zwan, Peter Van Der},
  title    = {What Drives Environmental Practices Of Smes?},
  journal  = {Small Bus Econ},
  year     = {2014},
  volume   = {44},
  number   = {4},
  pages    = {759--781},
  month    = nov,
  abstract = {The Objective Of This Paper Is To Develop A Better Understanding Of What Drives Small And Medium-sized Enterprises (smes) To Engage In Environmental Practices, And Whether The Drivers Differ Across Types Of Practices. Two Types Of Environmental Practices Are Distinguished: Practices Related To Production Processes (greening Processes) And Practices Related To Products And Services (greening Product And Service Offerings). Despite A Growing Literature On Socially Responsible Behavior Of Large Firms, The Role Of Smes Remains Underexposed. This Neglect Is Remarkable Given The Substantial Impact Of Smes On The Economy And The Natural Environment. By Using Unique Data For Almost 8,000 Smes Across 12 Sectors In 36 Countries, We Study The Influence Of Firm Characteristics On Smes{\textquoteright} Environmental Behavior. Our Results Suggest That Different Characteristics Have Dissimilar Influences On Both Types Of Environmental Practices Such As The Type Of Customers Served. Stringent Environmental Legislation Encourages Firms To Actively Take On Environmental Activities, But Only In Case Of Green Products And Services. Moreover, The Dominant Idea That Small Firms Are Reluctant To Invest In Environmental Practices Is Clearly More Nuanced: Firm Size Matters Most For Engagement In Greening Processes. Finally, Smes Active In Tangible Sectors And That Receive Financial Support Are More Involved In Either Type Of Environmental Practices.},
  doi      = {10.1007/s11187-014-9618-9},
  issn     = {0921-898X, 1573-0913},
  keywords = {Corporate Social Responsibility, Entrepreneurship, Environmental Practice, Eurobarometer, Industrial Organization, L26, M13, Management/business For Professionals, Microeconomics, O31, Q56, Sme, Stakeholder Theory},
  language = {En},
  urldate  = {2015-10-17}
}

@misc{webarcondicionado-relacao:2014,
  author   = {Webarcondicionado},
  title    = {A Rela{\c{c}}{\~{a}}o Entre Ar Condicionado E Data Centers},
  year     = {2014},
  abstract = {Voc{\^{e}} S{\'{o}} Est{\'{a}} Lendo Este Texto Gra{\c{c}}as A Um Sistema De Climatiza{\c{c}}{\~{a}}o. Essa Liga{\c{c}}{\~{a}}o Entre O Ar Condicionado E Os Computadores {\'{e}} Indireta, Mas Determinante. O Centro De Processamento De Dados (cpd), Conhecido Em Ingl{\^{e}}s Como Data Center, {\'{e}} O {\ldots}},
  journal  = {Portal Web Ar Condicionado},
  language = {Pt-br},
  type     = {Portal De Climatiza{\c{c}}{\~{a}}o},
  url      = {http://www.webarcondicionado.com.br/a-relacao-entre-ar-condicionado-e-data-centers},
  urldate  = {2015-12-09}
}

@misc{ibm-criterios:2013,
  author   = {Ibm Knowledge Center},
  title    = {Crit{\'{e}}rios De Design Ambiental Para Instala{\c{c}}{\~{a}}o Do Servidor Power7},
  month    = sep,
  year     = {2013},
  language = {Pt-br},
  url      = {http://www-01.ibm.com/support/knowledgecenter/api/content/nl/pt-br/POWER7/p7ebe/p7ebetempandhumiditydesign.htm},
  urldate  = {2015-10-17}
}

@inproceedings{raguvaran-raspberry:2015,
  author    = {Raguvaran, K. And Thiyagarajan, J.},
  title     = {Raspberry Pi Based Global Industrial Process Monitoring Through Wireless Communication},
  booktitle = {2015 International Conference On Robotics, Automation, Control And Embedded Systems (race)},
  year      = {2015},
  pages     = {1--6},
  month     = feb,
  abstract  = {This Paper Proposes An Advanced System For Process Management Via A Credit Card Sized Single Board Computer Called Raspberry Pi Based Multi Parameter Monitoring Hardware System Designed Using Rs232 And Microcontroller That Measures And Controls Various Global Parameters. The System Comprises Of A Single Master And Multiple Slaves With Wireless Mode Of Communication And A Raspberry Pi System That Can Either Operate On Windows Or Linux Operating System. The Parameters That Can Be Tracked Are Current, Voltage, Temperature, Light Intensity And Water Level. The Hardware Design Is Done With The Surface Mount Devices (smd) On A Double Layer Printed Circuit Board (pcb) To Reduced The Size And Improve The Power Efficiency. The Various Interesting Features Are Field Device Communication Via Usb-otg Enabled Android Devices, On Field Firm Ware Update Without Any Specific Hardware And Remote Monitoring And Control.},
  doi       = {10.1109/RACE.2015.7097298},
  keywords  = {Hardware, Industrial, Microcontrollers, Pcb, Radio Frequency, Raspberry Pi, Smd, Universal Serial Bus, Voltage Measurement, Wireless, Wireless Communication}
}

@inproceedings{matsumoto-proposal:2013,
  author    = {Matsumoto, K. And Yamagiwa, M. And Uehara, M. And Mori, H.},
  title     = {Proposal Of Sensor Data Gathering With Single Board Computer},
  booktitle = {2013 27\textsuperscript{th} International Conference On Advanced Information Networking And Applications Workshops (waina)},
  year      = {2013},
  pages     = {162--167},
  month     = mar,
  abstract  = {In Japan, The Generation Of Electricity Emits 20% Of The Total Greenhouse Gases. The Use Of Home Electronics, Besides Consuming Power, Also Accounts For 46% Of The Green-house Gas Emissions. We Therefore Need To Reduce Our Power Consumption At Home To Reduce Greenhouse Gas Emissions, Without Sacrificing Home Comforts Such As Watching Television And Using Air Conditioners And Various Other Electronic Devices. We Propose A Sensor Data Gathering System Using A Single Board Computer For Home Energy Management Systems. This Sensor System Should Be Capable Of Handling 100 Sensor Data Per Second. Since A Single Board Computer Has Low Power Consumption And Low Performance, It Is Used As The Sensor Data Gathering Server. Based On Our Benchmark Evaluation, A Single Board Computer Can Receive 5000 Sensor Data Per Second. Since The Basic Requirement Is Only 100 Sensor Data Per Second, This Single Board Computer Has Adequate Performance To Act As An Aggregated Server For 50 Such Sensor Data Gathering Systems.},
  doi       = {10.1109/WAINA.2013.102},
  keywords  = {Aggregated Server, Benchmark Testing, Building Management Systems, Computers, Data Gathering, Electricity Generation, Energy Management Systems, File Servers, Greenhouse Gas Emissions, Hems, Home Comforts, Home Energy Management Systems, Humidity, Japan, Memory, Microcomputers, Power Consumption, Power Demand, Power Engineering Computing, Sensor Data Gathering System, Sensor Network, Sensors, Servers, Single Board Computer, Temperature Sensors}
}

@inproceedings{wiboonrat-data:2014,
  author    = {Wiboonrat, M.},
  title     = {Data Center Infrastructure Management Wlan Networks For Monitoring And Controlling Systems},
  booktitle = {2014 Icoin},
  year      = {2014},
  pages     = {226--231},
  month     = feb,
  abstract  = {Constraints Of Space, Network, Power, And Cooling, Along With The Vast Complexity Of Managing A Large Data Center, Have Given Ascend To A New Principle Of Tools With Integrated Processes Called Data Center Infrastructure Management (dcim). Dcim Model Provides Data Center Operating Provision In Term Of System Connectivity And Interrelationship Among System Operations To Support Data Center Operations Managers. The Benefits Of Wireless Technology Are Reduced Investment Subject To Time To Implement, Cost Of Installation Labor And Material, And Flexibility Of Mobility. Moreover, Wlan And Vlan Are Deployed To Eliminate The Limitations Of Cabling Infrastructure E.g. Fast Installation, Less Costs Per Switching Port And Cable Wiring, Limited Working Space, Reduce Risk During Installation, Etc. This Model Can Also Reduce Investment Cabling And Network Operating Costs, Control Energy Costs, Improve Energy Efficiency, And Increase Operational Efficiency.},
  doi       = {10.1109/ICOIN.2014.6799696},
  keywords  = {Cable Wiring, Cabling Infrastructure, Computer Centres, Controlling Systems, Cooling, Cost Reduction, Data Center Infrastructure Management, Data Center Infrastructure Management, Data Center Operations Managers, Dcim Model, Energy Costs, Energy Efficiency, IEEE 802.11n Standard, Installation Labor Cost, Investment, Investment Cabling, Investment Subject, Load Shedding, Mobility, Monitoring, Monitoring Systems, Network Operating Costs, Reliability, Servers, Switching Port, System Connectivity, Telecommunication Network Management, Uninterruptible Power Systems, Vlan, Wireless Lan, Wireless Lan, Wireless Technology, Wlan, Wlan Networks}
}

@misc{neto-dcim:2013,
  author     = {Neto, Moacyr Franco},
  title      = {Os Principais Sistemas De Automa{\c{c}}{\~{a}}o De Data Centers Do Mercado - Dcim: Uma Vis{\~{a}}o T{\'{e}}cnica E Metodologias De Escolha},
  year       = {2013},
  location   = {6\textsuperscript{th} Netcomm, Sp},
  shorttitle = {Os Principais Sistemas De Automa{\c{c}}{\~{a}}o De Data Centers Do Mercado - Dcim}
}

@misc{congdon-8advantages:2015,
  author    = {Congdon, Lee},
  title     = {8 Advantages Of Using Open Source In The Enterprise Textbar The Enterprisers Project},
  month     = feb,
  year      = {2015},
  abstract  = {I Work With It Teams That Are So Passionate About Red Hat{\textquoteright}s Open Source Mission That They Bring A ''default To Open Source'' Mentality To Every Project We Work On. We{\textquoteright}ve Been Quite Successful In Finding Open Source Solutions For Many Of Our Business Needs. Naturally, We Turn To Our Own Open Source Solutions For Our Operating System, Middleware, And Cloud Needs. Beyond That, We Always Seek Out Open Source Solutions First For Our Other Business Needs, Such As User Authorization And Telephony.},
  copyright = {Copyright},
  journal   = {Enterprisers Project},
  language  = {En-us},
  url       = {https://enterprisersproject.com/article/2015/1/top-advantages-open-source-offers-over-proprietary-solutions},
  urldate   = {2015-05-16}
}

@misc{balter-open-source:2015,
  author     = {Balter, Benjamin},
  title      = {Open-source Alternatives To Proprietary Enterprise Software},
  year       = {2015},
  abstract   = {Open-source-alternatives - A Collaborative List Of Open-source Alternatives To Typical Government And Enterprise Software Needs. Https://github.com/benbalter/open-source-alternatives},
  copyright  = {Creative Commons Attribution-sharealike License},
  journal    = {Open-source Alternatives To Proprietary Enterprise Software},
  language   = {En-us},
  shorttitle = {Open-source Alternatives},
  url        = {http://ben.balter.com/open-source-alternatives/},
  urldate    = {2015-05-16}
}

@inproceedings{eiland-air:2012,
  author    = {Eiland, R. And Fernandes, J. And Gebrehiwot, B. And Vallejo, M. And Agonafer, D. And Mulay, V.},
  title     = {Air Filter Effects On Data Center Supply Fan Power},
  booktitle = {2012 13\textsuperscript{th} IEEE Intersociety Conference On Thermal And Thermomechanical Phenomena In Electronic Systems (itherm)},
  year      = {2012},
  pages     = {377--384},
  month     = may,
  abstract  = {Driven By Need To Reduce Energy Use, Many New Data Centers Are Built With Air-side Economizers. This Method Of Bringing In Outside Air As The Primary Cooling Resource Greatly Reduces Overall Facility Power By Eliminating Need For The Compressors And Pumps Required By Chilled Water And Refrigerant Based Cooling Systems. However, System Fans Are Still Necessary To Supply And Move Large Amounts Of Air Through The Facility. The Operating Power Of Fans Is Dependent On The Static Pressure Which Must Be Overcome To Move Air. The Static Pressure Of A Data Center Is Generally Fixed For A Given Configuration, With The Exception Of Air Filters Which Become Clogged Over Time. In This Work, Airflow Versus Pressure Drop Curves Of Filters Removed After Eight And A Half Months Of Service In A Large Data Center Operating An Air-side Economizer Are Experimentally Characterized. Comparisons Of This Data Against Clean Filters Provides Insight Into The Change In Pressure Drop Of Both Low-efficiency Pleated Pre-filters And High-efficiency Cartridge Final Filters As They Become Dirty. Incorporating These System Resistance Curves Into The Power Curve Of The Data Center Supply Fans Indicates Only Minimal Increase In Energy Use Resulting From Dust And Particle Collection Of The Filters.},
  doi       = {10.1109/ITHERM.2012.6231454},
  keywords  = {Air Cleaners, Air Cleaners, Air Filter, Air Filter Effects, Airflow, Air-side Economizer, Air-side Economizers, Chilled Water, Compressors, Computer Centres, Cooling, Data Center, Data Center Supply Fan Power, Energy Consumption, Energy Efficiency, Energy Use Reduction, Fan Power, Fans, Fans, Filter Banks, Filtration, High-efficiency Cartridge Final Filters, Low-efficiency Pleated Pre-filters, Power Curve, Pressure Drop Curves, Primary Cooling Resource, Refrigerant Based Cooling Systems, Refrigerants, Resistance, Static Pressure, System Resistance, System Resistance Curves, Water}
}

@article{lim-3d:2015,
  author   = {Lim, J. And Lim, H. And Kang, S.},
  title    = {3d Stacked Dram Refresh Management With Guaranteed Data Reliability},
  journal  = {IEEE Transactions On Computer-aided Design Of Integrated Circuits And Systems},
  year     = {2015},
  volume   = {Pp},
  number   = {99},
  pages    = {1--1},
  abstract = {The Three-dimensional (3d) Integrated Dynamic Random-access Memory (dram) Structure With A Processor Is Being Widely Studied Due To Advantages, Such As A Large Band-width And Data Communication Power Reduction. In These Structures, The Massive Heat Generation Of The Processor Results In A High Operating Temperature And A High Refresh Rate Of The Dram. Thus, In The 3d Dram Over Processor Architecture, Temperature-aware Refresh Management Is Necessary. However, Temperature Determination Is Difficult, Because In The 3d Dram, The Temperature Changes Dynamically And Temperature Variation In A Dram Die Is Complicated. In This Paper, A Thermal Guard-band Set-up Method For The 3d Stacked Dram Is Proposed. It Considers The Latency Of The Temperature Data And The Position Difference Between The Temperature Sensor And The Dram Cell. With This Method, The Data Reliability Of The On-chip Temperature Sensor Dependent Adaptive Refresh Control Is Guaranteed. In Addition, An Efficient Temperature Sensor Built-in And Refresh Control Method Is Analyzed. The Expected Refresh Power Reduction Is Examined Through A Simulation.},
  doi      = {10.1109/TCAD.2015.2413411},
  issn     = {0278-0070},
  keywords = {Computer Architecture, Data Reliability, Dram Refresh, Microprocessors, Random Access Memory, Reliability, Temperature Distribution, Temperature Sensors, Terms---3d Integration, Three-dimensional Displays}
}

@inproceedings{zhang-temperature-aware:2015,
  author    = {Zhang, Ying And Peng, Zebo And Jiang, Jianhui And Li, Huawei And Fujita, M.},
  title     = {Temperature-aware Software-based Self-testing For Delay Faults},
  booktitle = {Design, Automation Test In Europe Conference Exhibition (date), 2015},
  year      = {2015},
  pages     = {423--428},
  month     = mar,
  abstract  = {Delay Defects Under High Temperature Have Been One Of The Most Critical Factors To Affect The Reliability Of Computer Systems, And The Current Test Methods Don't Address This Problem Properly. In This Paper, A Temperature-aware Software-based Self-testing (sbst) Technique Is Proposed To Self-heat The Processors Within A High Temperature Range And Effectively Test Delay Faults Under High Temperature. First, It Automatically Generates High-quality Test Programs Through Automatic Test Instruction Generation (atig), And Avoids Over-testing Caused By Nonfunctional Patterns. Second, It Exploits Two Effective Powerintensive Program Transformations To Self-heat Up The Processors Internally. Third, It Applies A Greedy Algorithm To Search The Optimized Schedule Of The Test Templates In Order To Generate The Test Program While Making Sure That The Temperature Of The Processor Under Test Is Within The Specified Range. Experimental Results Show That The Generated Program Is Successful To Guarantee Delay Test Within The Given Temperature Range, And Achieves High Test Performance With Functional Patterns.},
  keywords  = {Atig, Automatic Test Instruction Generation, Automatic Test Pattern Generation, Circuit Faults, Computer Systems, Delay Faults, Delays, Fault Diagnosis, Greedy Algorithm, Greedy Algorithms, High-quality Test Program, Power Dissipation, Power-intensive Program Transformation, Program Processors, Reliability, Sbst Technique, Schedules, Temperature-aware Software-based Self-testing, Temperature Distribution}
}

@misc{beamish-dcim:2012,
  author   = {Beamish, Brad},
  title    = {Dcim Myths And Realities},
  month    = nov,
  year     = {2012},
  language = {En-us},
  location = {Bicsi Canadian Region Meeting, Ottawa, On, Canada},
  type     = {Meeting},
  urldate  = {2015-05-14}
}

@misc{filho-fazion-dcim:2012,
  author   = {Filho, M. F. And Neto, M. F.},
  title    = {Data Center Infrastructure Management And Automation Systems: An Evaluation Method},
  month    = nov,
  year     = {2012},
  abstract = {Information Technology Is Growing Faster Then Ever And New Challenges Appear Everyday. One Of These Challenges Is Data Storage And Processing, And Data Centers Have A Crucial Role In This Scenario. But As Data Centers Get Bigger, More Energy Is Necessary And Availability Is Fundamental. Considering Worries About Energy Costs And Availability Management, New Systems Of Data Center Infrastructure Automation Are Under Development. This Paper Presents A Proposal For A Method To Evaluate Hardware And Software Platforms That Compose These Systems, Called Dcim -- Data Center Infrastructure Management},
  doi      = {978-1-880843-88-8/ISCA},
  journal  = {Isca, Caine},
  language = {En-us}
}

@misc{uptime-dc-survey:2013,
  author    = {Stansberry, Matt},
  title     = {Uptime Institute - Data Center Industry Survey 2013},
  year      = {2013},
  abstract  = {The Third Annual Uptime Institute Data Center Industry Survey Is An Indepth Study, Collecting Responses Via Email (february To April 2013) From 1,000 Data Center Facilities Operators, It Managers And Senior Executives From Around The Globe.},
  language  = {En-us},
  publisher = {Uptime Institute},
  type      = {White Paper},
  urldate   = {2015-05-14}
}

Transactions on Industry Applications, 	volume = {48}, number = {2},

@article{arno-reliability:2012,
  author   = {Arno, R. And Friedl, A. And Gross, P. And Schuerger, R.j.},
  title    = {Reliability Of Data Centers By Tier Classification},
  journal  = {IEEE-ia},
  year     = {2012},
  pages    = {777--783},
  month    = mar,
  abstract = {When The Concept Of Reliability Began To Formally Become An Integrated Engineering Approach In The 50s, Reliability Was Associated With Failure Rate. Today The Term {\textquotedblleft}reliability{\textquotedblright} Is Used As An Umbrella Definition Covering A Variety Of Subjects Including Availability, Durability, Quality, And Sometimes The Function Of The Product. Reliability Engineering Was Developed To Quantify {\textquotedblleft}how Reliable{\textquotedblright} A Component, Product, Or System Was When Used In A Specific Application For A Specific Period Of Time. The Data Center Industry Has Come To Rely On {\textquotedblleft}tier Classifications{\textquotedblright} As Presented In A Number Of Papers By The Uptime Institute As A Gradient Scale Of Data Center Configurations And Requirements From Least (tier 1) To Most Reliable (tier 4). This Paper Will Apply The Principles And Modeling Techniques Of Reliability Engineering To Specific Examples Of Each Of The Tier Classifications And Discuss The Results. A Review Of The Metrics Of Reliability Engineering Being Used Will Also Be Included.},
  doi      = {10.1109/TIA.2011.2180872},
  issn     = {0093-9994},
  keywords = {Availability, Component, Computer Centres, Data Center Configuration, Data Center Industry, Data Center Reliability, Durability, Failure Rate, Generators, Integrated Engineering Approach, Maintenance Engineering, Mean Time Between Failures (mtbf), Mean Time To Repair (mttr), Product Availability, Product Durability, Product Quality, Reliability, Reliability Engineering, Switches, Tier Classification, Uninterruptible Power Systems}
}

@techreport{mike-data:2014,
  author      = {Andrea, Mike And Wallace, Byron},
  title       = {Data Center Size And Density Standards},
  institution = {Data Center Institute Standards Endorsed},
  year        = {2014},
  type        = {White Paper},
  number      = {Dcise-001},
  abstract    = {Under The Guidance Of Afcom{\textquoteright}s Data Center Institute Board, Industry Consultancy The Strategic Directions Group Was Commissioned To Develop A Standard Set Of Facility Size And Density Ratings To Inform The Development Of Regulatory Obligations, Such As Building Energy Efficiency Reporting, At The State, Regional And Local Levels.},
  copyright   = {Reserved},
  language    = {En-us},
  pages       = {19},
  urldate     = {2015-05-12}
}

@inproceedings{mescheryakov-adaptive:2014,
  author    = {Mescheryakov, S. And Shchemelinin, D. And Efimov, V.},
  title     = {Adaptive Control Of Cloud Computing Resources In The Internet Telecommunication Multiservice System},
  booktitle = {2014 6\textsuperscript{th} International Congress On Ultra Modern Telecommunications And Control Systems And Workshops (icumt)},
  year      = {2014},
  pages     = {287--293},
  month     = oct,
  abstract  = {In The Last Decade, The Internet Telecommunication Companies Are Growing Rapidly And Now Are Based On The Cloud Computing Environments. Management Of A Big Distributed Production Infrastructure With Multiple Business Services Requires A Centralized Control System. This Paper Describes How The Zabbix Enterprise-class Monitoring System Can Be Used As An Adaptive Solution For The Purpose Of Real-time Control Of Cloud Computing Resources, Auto-detection Of Critical Anomalies In Advance And, When Possible, Auto-restore Production Services Using A Predefined Workaround Procedure. Real-world Company Examples Are Provided.},
  doi       = {10.1109/ICUMT.2014.7002117},
  keywords  = {Adaptive Control, Adaptive Solution, Auto-restore Production Services, Big Data, Big Data, Big Distributed Production Infrastructure, Business Services, Centralised Control, Centralized Control, Centralized Control System, Cloud Computing, Cloud Computing Environments, Cloud Computing Resources, Computerised Monitoring, Critical Anomaly Autodetection, Distributed Environments, Facsimile, Fax Broadcasting, Internet Telecommunication Companies, Internet Telecommunications, Java, Measurement, Monitoring, Random Access Memory, Real-time Control, Servers, Telecommunication Industry, Telecommunications, Zabbix Enterprise-class Monitoring System}
}

@inproceedings{marik-comparative:2014,
  author    = {Marik, O. And Zitta, S.},
  title     = {Comparative Analysis Of Monitoring System For Data Networks},
  booktitle = {2014 International Conference On Multimedia Computing And Systems (icmcs)},
  year      = {2014},
  pages     = {563--568},
  month     = apr,
  abstract  = {The Document Is Focused On Comparative Analysis Of Monitoring Systems For Data Networks And Their Subsequent Application To The Data Network With Smaller Range. In The Text, The Author Describes Methodology Of Comparison Of Monitoring Systems And A Description Of Their Implementation And Testing. In The Introduction The Document Deals With The Theory Of Design Patterns For Deployment Of Monitoring Systems.},
  doi       = {10.1109/ICMCS.2014.6911307},
  keywords  = {Cacti, Comparative Analysis, Comparison, Comparison Methodology, Data Communication, Data Networks, Design Patterns Theory, Documentation, Lan Networks, Local Area Networks, Local Area Networks, Man Networks, Metropolitan Area Networks, Monitoring, Monitoring Systems, Monitoring System Testing, Nagios, Protocols, Scom, Servers, Telecommunication Equipment Testing, Testing, Testing, User Interfaces, Wan Networks, Wide Area Networks, Zabbix}
}

@inproceedings{arghode-anemometric:2015,
  author    = {Arghode, V.k. And Kang, T. And Joshi, Y. And Phelps, W. And Michaels, M.},
  title     = {Anemometric Tool For Air Flow Rate Measurement Through Perforated Tiles In A Raised Floor Data Center},
  booktitle = {Thermal Measurement, Modeling Management Symposium (semi-therm), 2015 31\textsuperscript{st}},
  year      = {2015},
  pages     = {163--171},
  month     = mar,
  abstract  = {In A Raised Floor Data Center, Cold Air From A Pressurized Sub-floor Plenum Reaches The Data Center Room Space Through Perforated Floor Tiles. Presently, Commercially Available Tool ''flow Hood'' (also Known As ''balometer'') Is Used To Measure The Air Flow Rate Through The Tiles. In The Present Paper, We Will Discuss The Operating Principle And The Shortcomings Of The Commercial Tool And Will Investigate A Simple Tile Air Flow Rate Measurement Tool Having An Array Of Thermal Anemometers (here Termed As ''anemometric Tool''). The Performance Of Both The Tools Is Compared For Different Types Of Tiles (passive And Active) For A Wide Range Of Tile Air Flow Rates. It Is Found That The Anemometric Tool Results In Lower Flow Rate Measurement Uncertainty And Works More Effectively For High Porosity Tiles, As Compared To The Commercial Tool Flow Hood.},
  doi       = {10.1109/SEMI-THERM.2015.7100155},
  keywords  = {Anemometric Tool, Data Center Cooling, Electrical Resistance Measurement, Floors, Flowhood, Fluid Flow Measurement, Measurement Uncertainty, Perforated Floor Tiles, Pressure Measurement, Resistance, Temperature Measurement, Tile Air Flow Rate Measurement, Tool Resistance Compensation}
}

booktitle = {2015 48th {Hawaii} {International} {Conference} on {System} {Sciences} ({HICSS})},

@inproceedings{jokonya-oss:2015,
  author    = {Jokonya, O.},
  title     = {Investigating Open Source Software Benefits In Public Sector},
  booktitle = {2015 48\textsuperscript{th} Hicss},
  year      = {2015},
  pages     = {2242--2251},
  month     = jan,
  abstract  = {This Paper Investigates The Benefits Of Oss In Public Sector Organizations In Order To Understand The Trends And Patterns In Different Regions Over Time. Although Open Source Software Is Used Widely, In This Study The Authors Examine The Adoption Of Open Source Software In The Public Sector. As Such, The Paper Uses Content Analysis To Review Published Articles On Open Source Software In The Public Sector Or Government Organizations Between 2003 And 2012 Across The Regions (africa, America, Asia, And Europe). The Results Suggest That That There Is No-one-size-fit-all To Open Source Software Adoption Benefits To The Public Sector In Different Regions. The Results Also Show That Technical Benefits, Vendor Independence And Customization Are Considered To Be Important For Open Source Software Adoption In Public Sector Organizations. While This Suggests That Public Sector Organizations Perceive Open Source Software As One Step Towards Vendor Independence, Customization Is Considered A Very Important Benefit Of Open Source Software Adoption In Asia Than Is The Case In America.},
  doi       = {10.1109/HICSS.2015.268},
  keywords  = {Adoption, Content Analysis, Customization, Digital Divide, Economics, Government, Government Organization, Industries, Interoperability, Lock-in, Open Source Software, Open Source Software Benefit, Open Standards, Organisational Aspects, Oss, Proprietary Software, Public Administration, Public Domain Software, Public Sector, Public Sector Organization, Standards, Vender Independence, Vendor Customization, Vendor Independence}
}

@article{alaraifi-application:2012,
  author     = {Alaraifi, Adel},
  title      = {The Application And Impact Of Sensor Based Information Systems In Data Centers: A Literature Review},
  journal    = {Procedia Engineering},
  year       = {2012},
  volume     = {41},
  pages      = {819--826},
  abstract   = {The Demand For And On Data Centers Continue To Pose Several Power, Cooling, And Performance Constraints Associated With Operational, Economic And Environmental Inefficiency. Sensor Based Information Systems (sbis) Are One Of The Best Practices For Addressing These Constraints. The Aim Of The Paper Is To Review The Research On The Applications Of Sbis In Data Centers And Discusses The Opportunities For Utilizing Sbis To Support The Business Functions Of The Data Centers Including The Management Of Cooling, Power Delivery And Computing Platforms. Although The Use Of Sensors To Monitor Temperature, Smoke, Heat And Security Is Considered An Old Practice In Data Centers, The Full Utilization And Integration Of These Sensors Into Information Systems To Automate Data Centre Management Functions, Inform Decision Making In Data Centre Management And Transform Data Centers To Improve Their Operational, Economic And Environmental Performance Appears To Be Very Limited. The Paper Reviews The Current Literature And Concludes That There Is A Dearth For Empirical Studies That Focus On The Use Of Sbis And The Benefits Of Sbis To The Data Centers. Thus, The Paper Calls For More Theoretical And Empirical Research To Investigate The Utilization Of Sbis To Manage Data Centers{\textquoteright} Platforms And Its Impact On Data Centers Performance.},
  doi        = {10.1016/j.proeng.2012.07.249},
  issn       = {1877-7058},
  keywords   = {Adoption, Data Centers, Information System, Monitoring, Sensors},
  series     = {International Symposium On Robotics And Intelligent Sensors 2012 (iris 2012)},
  shorttitle = {The Application And Impact Of Sensor Based Information Systems In Data Centers},
  urldate    = {2015-05-08}
}

@inproceedings{bhagwat-thermal:2012,
  author     = {Bhagwat, H. And Singh, A. And Vasan, A. And Sivasubramaniam, Anand},
  title      = {Thermal Influence Indices: Causality Metrics For Efficient Exploration Of Data Center Cooling},
  booktitle  = {{IGCC} 2012},
  year       = {2012},
  abstract   = {Cooling Is An Important Issue In Data Center Design And Operation. Accurate Evaluation Of A Design Or Operational Parameter Choice For Cooling Is Difficult As It Requires Several Runs Of Computationally Intensive Computational Fluid Dynamics (cfd) Based Models. Therefore There Is Need For An Exploration Method That Does Not Incur Enormous Computation. In Addition, The Exploration Should Also Provide Insights That Enable Informed Decision Making. Given These Twin Goals Of Reduced Computation And Improved Insights, We Present A Novel Approach To Data Center Cooling Exploration. The Key Idea Is To Do A Local Search Around The Current Design/operation Of A Data Center To Obtain Better Design/operation Parameters Subject To The Desired Constraints. To Do This, All The Microscopic Information About Airflow And Temperature In Data Center Available From A Single Run Of Cfd Computation Is Converted Into Macroscopic Metrics Called Influence Indices. The Influence Indices, Which Characterize The Causal Relationship Between Heat Sources And Sinks, Are Used To Refine The Design/operation Of The Data Center Either Manually Or Programmatically. New Designs Are Evaluated With Further Cfd Runs To Compute New Influence Indices And The Process Is Repeated To Yield Improved Designs As Per The Computation Budget Available. We Have Carried Out Design Exploration Of A Realistic Data Center Using This Methodology. Specifically, We Considered Maximization Of The Heat Load In The Data Center Subject To The Constraints That: 1) Servers Are Kept At Appropriate Temperatures And 2) Overloading Of Cracs Is Avoided. Our Evaluation Shows That The Use Of Influence Indices Cuts Down The Exploration Time By 80 % For A 1500 Sq. Ft. Data Center.},
  doi        = {10.1109/IGCC.2012.6322254},
  eventtitle = {{IGCC} 2012},
  keywords   = {Air, Airflow, Causality Metrics, Computational Fluid Dynamics, Computational Fluid Dynamics (cfd), Computationally Cfd-based Models, Computationally Intensive Computational Fluid Dynamics-based Models, Computational Modeling, Computer Centres, Cooling, Crac Overloading, Data Center, Data Center Cooling Exploration, Data Center Design, Data Center Operation, Data Center Temperature, Decision Making, Design Exploration, Efficient Cooling, Heating, Heat Load, Heat Sinks, Heat Sources, Influence Indices, Macroscopic Metrics, Mathematical Model, Microscopic Information, Operation Parameters, Servers, Temperature Distribution, Thermal Influence Indices, Ubiquitous Computing},
  shorttitle = {Thermal Influence Indices}
}

@techreport{pultz-magic:2014,
  author      = {Pultz, Jay E. And Cappuccio, David J. And Adams, April And Silva, Federico De And Mishra, Naveen And Cecci, Henrique And Kumar, Rakesh},
  title       = {Magic Quadrant For Data Center Infrastructure Management Tools},
  institution = {Gartner Inc},
  year        = {2014},
  number      = {G00259286},
  month       = sep,
  abstract    = {Data Center Infrastructure Management Tools Optimize Data Centers By Monitoring And Managing It And Facilities Resources And Energy Consumption. Data Center And Facilities Managers Can Use This Magic Quadrant To Identify Dcim Technology Providers And Determine Which Meet Their Prioritized Needs.},
  language    = {En-us},
  pages       = {17},
  urldate     = {2015-05-07}
}

@article{mittal-power:2014,
  author     = {Mittal, Sparsh},
  title      = {Power Management Techniques For Data Centers: A Survey},
  journal    = {Corr},
  year       = {2014},
  month      = apr,
  note       = {Arxiv: 1404.6681},
  abstract   = {With Growing Use Of Internet And Exponential Growth In Amount Of Data To Be Stored And Processed (known As 'big Data'), The Size Of Data Centers Has Greatly Increased. This, However, Has Resulted In Significant Increase In The Power Consumption Of The Data Centers. For This Reason, Managing Power Consumption Of Data Centers Has Become Essential. In This Paper, We Highlight The Need Of Achieving Energy Efficiency In Data Centers And Survey Several Recent Architectural Techniques Designed For Power Management Of Data Centers. We Also Present A Classification Of These Techniques Based On Their Characteristics. This Paper Aims To Provide Insights Into The Techniques For Improving Energy Efficiency Of Data Centers And Encourage The Designers To Invent Novel Solutions For Managing The Large Power Dissipation Of Data Centers.},
  annotation = {Comment: Keywords: Data Centers, Power Management, Low-power Design, Energy Efficiency, Green Computing, Dvfs, Server Consolidation},
  keywords   = {Computer Science - Distributed, Parallel, And Cluster Computing},
  shorttitle = {Power Management Techniques For Data Centers},
  urldate    = {2015-04-30}
}

% rever: http://wenku.baidu.com/view/c17b29c458f5f61fb7366690.html

Bailey, M., M. Eastwood, T Grieser, L. Borovick, V. Turner, and R.C. Gray. 2007. Special Study: Data Center of the Future. New York, NY: IDC. IDC #06C4799. April.

@article{symanski-380vdc:2010,
  author  = {Symanski, D. And Watkins, C.},
  title   = {380vdc Data Center At Duke Energy},
  journal = {Emerging Technology Summit At Electric Power Research Institute},
  year    = {2010},
  volume  = {9},
  month   = nov,
}

@article{avelar-guidance:2011,
  author  = {Avelar, Victor},
  title   = {Guidance For Calculation Of Efficiency (pue) In Data Centers},
  journal = {Schneider Electric, Rueil Malmaison, France, White Paper},
  year    = {2011},
  volume  = {158}
}

@inproceedings{ye-design:2014,
  author     = {Ye, Hanmin And Song, Zihang And Sun, Qianting},
  title      = {Design Of Green Data Center Deployment Model Based On Cloud Computing And Tia942 Heat Dissipation Standard},
  booktitle  = {2014 IEEE Iweca},
  year       = {2014},
  pages      = {433--437},
  abstract   = {Data Center Is A Field Which Has High Investment Of Funds, Manpower And Operations In It Components. Now, The Green Data Center Construction Which Has The Core Idea Of Energy Conservation And Emission Reduction Is The Main Projection Of It Industry. New Generation Unified Switch Architecture Can Provide Users A Brief And Green Data Center. Combined With The Development Status Of The Current Data Center, This Paper Has Discussed The Key Techniques And Methods Based On Tia942 Green Data Center Energy Conservation And Emission Reduction And The Cloud Computing Data Center. It Has Also Combined Cloud Computing And Green Data Center Based On Tia942 Heat Dissipation Standards To Propose The Fusion Model And Finish The Application Deployment Of Green Data Center Fusion Model.},
  doi        = {10.1109/IWECA.2014.6845649},
  eventtitle = {2014 IEEE Workshop On Electronics, Computer And Applications},
  keywords   = {Air Pollution Control, Application Deployment, Cloud Computing, Com Green Data Center, Computational Modeling, Computer Architecture, Computer Centres, Cooling, Emission Reduction, Energy Conservation, Green Computing, Green Data Center Deployment Model, Green Data Center Fusion Model, Information Technology, It Components, It Industry, Optimization, Redundancy, Servers, Sun, Switches, Tia942 Heat Dissipation Standard, Tia942 Heating Dissipation Standard Component, Unified Switch Architecture}
}

@inproceedings{rubenstein-data:2014,
  author     = {Rubenstein, B. And Faist, M.},
  title      = {Dc Cold Aisle Set Point Optimization Through Total Operating Cost Modeling},
  booktitle  = {IEEE-itherm},
  year       = {2014},
  pages      = {1111},
  abstract   = {Operational Expenses Of Servers And The Data Center To Support Them Account For A Significant Part Of The Total Cost Of Ownership Of A Data Center And Potentially The Total Business. Manipulating The Inlet Temperature To The Servers Can Provide A Possible Method Of Lowering The Operating Cost Of A Data Center. Conventional Wisdom Regarding Management Of The Cold Aisle Temperature In The Data Center Has Traditionally Been That Colder Temperatures Kept The Failure Rate Of The Equipment Down And Higher Temperatures Reduced Energy Costs. While It Is True That In Most Cooling Strategies, Increasing The Cold Aisle Set Point Temperature Reduces The Power Consumed By The Facilities, The Overall Cost Savings May Not Be Realized Due To Increases In Server Power And Decreased Reliability. An Investigation Using The Total Operational Expense Of The Data Center Would Be Required To Find The Optimum Operating Point Of The Environmental Controls. The Simulation Described In This Paper Demonstrates That When Accounting For Total Operational Cost Including Component Reliability And Servicing In Addition To Energy And Water Resource Costs, There Is An Optimal Data Center Cold Aisle Set Point. This Point Will Vary With Resource Rates And Climate Variations. The Run Cost Effectiveness Metric, Rce, Allows Data Center Designers And Managers To Monitor And Optimize Their Data Center For The Given Static Costs Of The Region. It's A Measurable Value For Many Data Centers That Can Break Out These Costs Either In Real Time, Or More Likely Tabulated Form Collected From Monitoring Data Over Time.},
  doi        = {10.1109/ITHERM.2014.6892405},
  eventtitle = {IEEE Itherm},
  keywords   = {Cold Aisle Set Point Temperature, Cold Aisle Temperature, Component Reliability, Computer Centres, Conditions, Cooling, Cooling Strategies, Costing, Cost Modeling, Datacenter, Data Center Cold Aisle Set Point Optimization, Energy Costs, Equations, Fans, Maintenance Engineering, Mathematical Model, Operating, Operational, Optimisation, Power Aware Computing, Power Demand, Rce, Reliability, Run Cost Effectiveness Metric, Servers, Setpoint, Temperature Distribution, Total Business, Total Operating Cost Modeling, Total Operational Cost, Water Resource Costs}
}

@inproceedings{david-impact:2014,
  author     = {David, M.p. And Schmidt, R.r.},
  title      = {Impact Of Ashrae Environmental Classes On Data Centers},
  booktitle  = {2014 IEEE Itherm},
  year       = {2014},
  pages      = {1092--1099},
  abstract   = {Data Centers Consume A Significant Amount Of Energy In The Us And Worldwide, Much Of Which Is Consumed By The Cooling Infrastructure, Particularly The Chiller Plant And Computer Room Air Conditioners And Air Handlers. To Enable Energy Efficient Data Center Designs, Ashrae Added Two New It Environmental Classes, A3 And A4, With Associated Allowable Inlet Air Temperatures Of 40c And 45c Respectively. It Equipment That Meet These New Allowable Environmental Envelopes Can Operate In Data Centers With Minimal Refrigeration Cooling And Instead Rely On Ambient Free Cooling. In This Paper We Investigate The Impact Of Allowing A Data Center To Operate Up To The A3 Limit Of 40c On Total Data Center Energy Use For 3 Different Types Of Servers In A Chiller-less Data Center Located In A Variety Of Locations. The Study Finds That Though Facility Power Reduces As The Demand For Cold Air Reduces, The Increase In It Power Consumption, Due To Fan Speed-up, Can Offset These Savings And In Some Cases Result In An Overall Increase In Data Center Power. Thus The Most Energy Efficient Operating Point Is Dependant On The Specific Energy Use Profiles Of The Infrastructure And The It Equipment. The Higher Allowable Temperature Can Also Result In Higher Failure Rates And An Increased Risk Of Equipment Or Service Loss Due To Data Center Cooling Failures. This Paper Also Presents A Study On The Potential For Chiller Elimination And Chiller Use Reduction Across The Us, Europe And In India By Operating In The Various Ashrae Envelopes. For Wet, Water Side Economized Data Centers, A2 And A3 Equipment Is Sufficient To Almost Completely Remove The Need For Chillers In Many Geographic Locations.},
  doi        = {10.1109/ITHERM.2014.6892403},
  eventtitle = {2014 IEEE Itherm},
  keywords   = {A3 Limit, Air Conditioning, Air Handlers, Allowable Environmental Envelopes, Ambient Free Cooling, Ashrae, Atmospheric Modeling, Chiller Elimination, Chiller-less Data Center, Chiller Plant, Chiller Use Reduction, Computer Centres, Computer Room Air Conditioners, Computers, Cooling, Cooling Infrastructure, Data Center Cooling Failures, Data Centers, Data Models, Energy Conservation, Energy-efficiency, Energy Efficient Data Center Designs, Energy Efficient Operating Point, It Environmental Classes, It Equipment, It Power Consumption, Power Consumption, Refrigeration Cooling, Reliability, Servers, Specific Energy Use Profiles, Temperature Distribution, Total Data Center Energy Use}
}

@book{paim-gestao:2009,
  title      = {Gest{\~{a}}o De Processos: Pensar, Agir E Aprender},
  publisher  = {Bookman},
  year       = {2009},
  author     = {Paim, R. And Cardoso, V. And Caulliraux, H. And Clemente, R.},
  abstract   = {Baseado Em Mais De 20 Anos De Pesquisa, Projetos De Aplica{\c{c}}{\~{a}}o E Testes, 'gest{\~{a}}o De Processos' {\'{e}} Direcionado A Acad{\^{e}}micos E Profissionais.},
  isbn       = {9788577804849},
  langid     = {Portuguese},
  location   = {Porto Alegre},
  pagetotal  = {15},
  shorttitle = {Gest{\~{a}}o De Processos}
}

@article{ganga-fuzzy:2011,
  author  = {Ganga, Gilberto Miller Dev{\'{o}}s And Carpinetti, Luiz Cesar Ribeiro And Politano, Paulo Rog{\'{e}}rio},
  title   = {A Fuzzy Logic Approach To Supply Chain Performance Management},
  journal = {Gest{\~{a}}o E Produ{\c{c}}{\~{a}}o},
  year    = {2011},
  volume  = {18},
  number  = {4},
  pages   = {755--774},
  doi     = {10.1590/S0104-530X2011000400006},
  issn    = {0104-530X},
  urldate = {2014-10-02}
}

@book{banzi-getting:2008,
  title     = {Getting Started With Arduino},
  publisher = {Make Books - Imprint Of: O'reilly Media},
  year      = {2008},
  author    = {Banzi, Massimo},
  edition   = {Ill},
  abstract  = {This Valuable Little Book Offers A Thorough Introduction To The Open-source Electronics Prototyping Platform That's Taking The Design And Hobbyist World By Storm. Getting Started With Arduino Gives You Lots Of Ideas For Arduino Projects And Helps You Get Going On Them Right Away. From Getting Organized To Putting The Final Touches On Your Prototype, All The Information You Need Is Right In The Book. Inside, You'll Learn About:interaction Design And Physical Computing The Arduino Hardware And Software Development Environment Basics Of Electricity And Electronics Prototyping On A Solderless Breadboard Drawing A Schematic Diagram And More. With Inexpensive Hardware And Open-source Software Components That You Can Download Free, Getting Started With Arduino Is A Snap. To Use The Introductory Examples In This Book, All You Need Is A Usb Arduino, Usb A-b Cable, And An Led.join The Tens Of Thousands Of Hobbyists Who Have Discovered This Incredible (and Educational) Platform. Written By The Co-founder Of The Arduino Project, With Illustrations By Elisa Canducci, Getting Started With Arduino Gets You In On The Fun! This 128-page Book Is A Greatly Expanded Follow-up To The Author's Original Short Pdf That's Available On The Arduino Website.},
  isbn      = {0596155514, 9780596155513},
  location  = {Sebastopol, Ca}
}

@article{netto-analysis:2014,
  author   = {Evangelista Netto, Joao And Hernane Paulicena, Edesio And Amorim Silva, Rafael And Anzaloni, Alessandro},
  title    = {Analysis Of Energy Consumption Using Http And Ftp Protocols Over IEEE 802.11},
  journal  = {Latin America Transactions, IEEE (revista IEEE America Latina)},
  year     = {2014},
  volume   = {12},
  number   = {4},
  pages    = {668--674},
  abstract = {This Paper Presents An Overview On Green Computing And Energy Aware To Network Communication. There Was A Measurement Of Energy Efficiency And Comparison Of The Main Network Transfer Protocols Used On The Internet. A Tool Named Energy Consumption Model Was Developed And Inserted Into The Discrete Event Simulator Opnet Modeler To Run The Tests. An Exhaustive Analysis Of Consumption Was Performed During The Data Transfer Phase With Http And Ftp Protocol Using Different Packet Sizes. From Data Obtained It Was Possible Not Only To Quantify The Energy Consumed By The Protocols, But Also Perform A Comparative Analysis Between Them. The Results Suggest That The Use Of Http Is Most Suitable Than The Ftp. However, This Advantage Decreases Proportionately To Larger Objects.},
  doi      = {10.1109/TLA.2014.6868868},
  issn     = {1548-0992},
  keywords = {Energy Consumption, Green Networks, Network Simulation, Protocols}
}

@article{mogami-rti:2014,
  author   = {Mogami, Sandra And Rodrigues, Simone},
  title    = {Data Centers Para Pequenas Empresas},
  journal  = {Revista Rti},
  year     = {2014},
  volume   = {167},
  pages    = {20},
  abstract = {Http://www.arandanet.com.br/midiaonline/rti/2014/abril/index.html},
  series   = {Xv},
  urldate  = {2014-10-04}
}

@article{severance-massimo:2014,
  author     = {Severance, Charles},
  title      = {Massimo Banzi: Building Arduino},
  journal    = {Computer},
  year       = {2014},
  volume     = {47},
  number     = {1},
  pages      = {11--12},
  month      = jan,
  abstract   = {Massimo Banzi Describes The Origins And Evolution Of The Arduino Microcontroller. The First Web Extra At Http://youtu.be/0vabvq2ti50 Is A Video Interview In Which Author Charles Severance Speaks With Massimo Banzi About The Origins And Evolution Of The Arduino Microcontroller. The Second Web Extra At Http://youtu.be/n6wn1qlfeq Is An Audio Recording Of Author Charles Severance Reading His Computing Conversations Column, In Which He Discusses His Interview With Massimo Banzi About The Origins And Evolution Of The Arduino Microcontroller.},
  doi        = {10.1109/MC.2014.19},
  issn       = {0018-9162},
  keywords   = {Arduino, Computing Conversations, Massimo Banzi, Microcontrollers},
  shorttitle = {Massimo Banzi}
}

@inproceedings{lin-zigbee:2007,
  author    = {Lin, Shizhuang And Liu, Jingyu And Fang, Yanjun},
  title     = {Zigbee Based Wireless Sensor Networks And Its Applications In Industrial},
  booktitle = {2007 IEEE International Conference On Automation And Logistics},
  year      = {2007},
  pages     = {1979--1983},
  month     = aug,
  abstract  = {Based On The Study Of The Characteristics Of Zigbee Technology, And The Analysis Of The Structure Of Wireless Sensor Networks. Proposed A New Reliable, Flexible And Inexpensive Wsn System Based On The Zigbee Technology. Its Structure That The Mac Layer And The Network Layer Of Zigbee Been Taken Over Wholly Is Given, And Its Node That Integrates The Wsn Nodes And Zigbee Module Together, Include Both The Hardware Implementation And The Software Implementation Based On Tinyos, Is Designed. At The End, Analyzed The Desired Characteristics Of The Wsn System Applied In Industrial And Proved That The New Wsn System Has A More Vast Range Of Prospects In The Application In Industrial.},
  doi       = {10.1109/ICAL.2007.4338898},
  keywords  = {Access Protocols, Application Software, Automatic Control, Automation, Communication System Security, Computer Peripherals, Costs, Hardware, Industrial Application, Industrial Applications, Mac, Sensor Systems, Tinyos, Wireless Sensor Network, Wireless Sensor Networks, Wireless Sensor Networks, Wireless Sensor Networks, Zigbee, Zigbee Technology}
}

@inproceedings{ramsey-improved:2012,
  author    = {Ramsey, B.w. And Mullins, B.e. And White, E.d.},
  title     = {Improved Tools For Indoor Zigbee Warwalking},
  booktitle = {2012 IEEE 37\textsuperscript{th} Conference On Local Computer Networks Workshops (lcn Workshops)},
  year      = {2012},
  pages     = {921--924},
  month     = oct,
  abstract  = {Secure Zigbee Wireless Sensor And Control Networks Use 128-bit Aes Encryption To Defend Against Message Sniffing And Unauthorized Access. However, The Low Cost And Low Complexity Of Zigbee Devices Makes Them Vulnerable To Physical Attacks Such As Tampering And Network Key Extraction. Network Administrators And Penetration Testers Require Tools Such As Zbfind To Accurately Locate Zigbee Hardware And Evaluate Physical Security. The Open Source Zbfind Tool Estimates Distance To Zigbee Devices In Real Time Using Received Signal Strength And A Distance Prediction Model. We Collect 4500 Signal Strength Measurements Along Nine Walking Paths Toward Zigbee Transmitters In Three Office Buildings. We Find That The Log-distance Path Loss Model Used By Zbfind Predicts Transmitter Distance With 92.5% Mean Absolute Percentage Error. We Construct An Alternative Linear Model That Reduces Error To 21%.},
  doi       = {10.1109/LCNW.2012.6424083},
  keywords  = {Access Protocols, Aes Encryption, Buildings, Distance Prediction Model, Estimation, Hardware, Log Distance Path Loss Model, Message Sniffing, Network Administrator, Network Vulnerability, Office Automation, Office Buildings, Open Source Zbfind Tool, Penetration Tester, Physical Security Evaluation, Radio Transmitters, Received Signal Strength Measurement, Security, Telecommunication Security, Transmitters, Unauthorized Access, Wireless Communication, Wireless Sensor Networks, Wireless Sensor Networks, Zigbee, Zigbee, Zigbee Control Network Security, Zigbee Device, Zigbee Hardware Security, Zigbee Transmitter, Zigbee Wireless Sensor Network}
}

@article{liu-microsoft:2012,
  author   = {Jie Liu And Andreas Terzis},
  title    = {Sensing Data Centers For Energy Efficiency},
  journal  = {Philosophical Transactions Of The Royal Society A. January 13, 2012 370 1958 136-157},
  year     = {2012},
  month    = jan,
  abstract = {Data Centers Are Large Energy Consumers Today And Their Consumption Is Expected To Increase Further, Driven By The Growth In Cloud Services. The Large Costs And The Environmental Impact Of This Consumption Have Motivated Data Center Operators To Optimize Data Center Operations. We Argue That One Of The Underlying Reasons For The Low Energy Utilization Is The Lack Of Visibility Into A Data Center's Highly Dynamic Operating Conditions. Wireless Sensor Networks Promise To Remove This Veil Of Uncertainty By Delivering Large Volumes Of Data Collected At High Spatial And Temporal Fifidelities. The Paper Summarizes Data Center Operations In Order To Describe The Parameters That A Data Center Sensing Network Would Need To Collect And Motivate The Challenges That Such A Network Would Face. We Present Technical Approaches For The Problems Of Data Collection And Management And Close With An Overview Of Data Center Genome, An End-to-end Data Center Sensing System.}
}

@inCollection{dai-data:2014,
  author    = {Dai, Jun And Ohadi, Michael M. And Das, Diganta And Pecht, Michael G.},
  title     = {Data Center Energy Flow And Efficiency},
  booktitle = {Optimum Cooling Of Dcs},
  publisher = {Springer Ny},
  year      = {2014},
  pages     = {9--30},
  month     = jan,
  abstract  = {Data Centers Form The Backbone Of Information Management In Every Sector Of The Economy, And Their Energy Consumption Has Been Of Concern To Governments And The Telecom Industry. This Chapter Introduces Data Center Energy Efficiency, Including The Main Components And Operating Environments In Data Centers, As Well As The Standards, Thermal Guidelines, And Metrics Used To Quantify The Energy Efficiency. This Chapter Also Presents The Major Cooling Methods Used In The Industry To Improve Energy Efficiency. A Case Study Is Discussed In Which Energy Consumption Of A Medium-size Primary Data Center At An Academic Campus Is Analyzed And Compared With Experimental Measurements.},
  copyright = {{\copyright}2014 Springer Science+business Media New York},
  isbn      = {978-1-4614-5601-8, 978-1-4614-5602-5},
  keywords  = {Building Construction, Communications Engineering, Networks, Performance And Reliability},
  language  = {En},
  urldate   = {2014-08-14}
}

@inproceedings{genova-thermal:2009,
  author    = {Genova, Fernando And Bellifemine, Fabio And Gaspardone, Marco And Beoni, Maurizio And Cuda, Alberto And Fici, Gian Piero},
  title     = {Management System Based On Low Cost Wireless Sensor Network Technology, To Monitor, Control And Optimize Energy Consumption In Telecom Switch Plants And Data Centres},
  booktitle = {2009 4\textsuperscript{th} Escon},
  year      = {2009},
  pages     = {1--8},
  month     = may,
  abstract  = {Telecom Italia (ti), Being One Of The Top Italian Electricity Consumers, Realized And Started To Deploy A Real-time Energy Management System (kaleidos) Based On Wireless Sensor Network Technology (wsn), To Monitor All Relevant Energy Parameters Of Its Switching Plants (e.g. Per-line Energy Consumption, Room Temperatures, Humidity And Lighting) And To Remotely Control Room Temperatures And Air Conditioning. Among The Features Of This System We Outline: (-) Average Cost Of Each Measurement Point Lower Than 100 Euro (excluding The Service Platform); (-) Negligible Installation And Maintenance Costs; (-) Long Life (textgreater2 Years, Better 3) Sensor Node Battery; (-) Reliability, Scalability And Security; (-) Self-configuring Wsn. The Architecture Of The System Consists Of 4 Layers: (-) A Low Cost Set Of Sensor Nodes Deployed In Each Switching Plant. Each Node Includes One Or More Sensors Interfaced With A Radio Communication Chip, Compliant To Zigbee Standard; (-) A Gateway For Each Wsn, Which Acts As A Data Sink For The Sensor Nodes And Which Connects The Wsn To The Server Platform Through An Internet Connection (lan Or Gsm-gprs); (-) A Service Platform (wsn-c), Able To Manage And Control Different Kinds Of Sensor Networks (energy Management, Health Care, Automotive, ...), To Collect And Store Data And To Make Them Available To Applications Via A Web Service; (-) A Web Application Which Provides A Graphical User Interface (gui) And Data Analysis Facilities. The First Trial Started In April 2007 And Demonstrated That An Energy Saving In The Order Of 10-15 % Was Possible By Simply Optimizing The Air Conditioning System Working Parameters. In 2008 Ti Decided To Deploy Kaleidos Into Its 300 Larger Plants. Typical Site Consists Of 10{\"{i}}{\textquestiondown}{\textquestiondown}{\"{i}}{\textquestiondown}{\textquestiondown}15 Rooms, 2000{\"{i}}{\textquestiondown}{\textquestiondown}{\"{i}}{\textquestiondown}{\textquestiondown}6000 M2, 1{\"{i}}{\textquestiondown}{\textquestiondown}{\"{i}}{\textquestiondown}{\textquestiondown}5 Gwh/year Energy Consumption And It Is Equipped With A Sensor Network Of 20{\"{i}}{\textquestiondown}{\textquestiondown}{\"{i}}{\textquestiondown}{\textquestiondown}30 Current Nodes And 20{\"{i}}{\textquestiondown}{\textquestiondown}{\"{i}}{\textquestiondown}{\textquestiondown}25 Environmental Nodes. Kaleidos Is Used Not Only To Monitor And Control The Energy And Thermal Behaviour Of Si- - Tes, But It Has Been Shown To Be Effective In Supporting The Design Of Fine-grained Energy Saving Actions And In Real-time Evaluation Of Those Actions. Kaleidos Is Easily Extendable To Other Industrial Building Or Offices And Can Be Interfaced Or Overlapped To A Bms.},
  keywords  = {Calibration, Irrigation, Logic Gates, Servers, Switches, Wireless Sensor Networks, Zigbee}
}

@inproceedings{russell-low-cost:2012,
  author    = {Russell, L. And Steele, A.l. And Goubran, R.},
  title     = {Low-cost, Rapid Prototyping Of Imu And Pressure Monitoring System Using An Open Source Hardware Design},
  booktitle = {Instrumentation And Measurement Technology Conference (i2mtc), 2012 IEEE International},
  year      = {2012},
  pages     = {2695--2699},
  month     = may,
  abstract  = {Open Source Hardware Is A Type Of Hardware Where The Schematics And Designs Are Made Unrestricted And Available To All. They Are Often Accompanied By Open Source Software. This Can Bring Reliability, Ease Of Debugging, And Modular Development For Rapid Prototyping Using Pre-written Libraries. Merits Of Using Open Source Hardware Are Discussed And Then Applied To A Portable Sensor System Based On The Open Hardware Arduino-derived Jeenode Microcontroller Board. The System Uses An Inertial Measurement Unit (imu) And Seamless Integration Of Other Sensors, Including A Piezo-resistive Pressure Sensor. It Is Shown That Open Source Hardware Can Help To Increase Rapid Development, Reduce Costs, And Encourage Further Development.},
  doi       = {10.1109/I2MTC.2012.6229719},
  keywords  = {Accelerometer, Bluetooth, Computerised Instrumentation, Graphical User Interfaces, Imu Rapid Prototyping, Inertial Measurement Unit, Microcontrollers, Microcontrollers, Open Hardware Arduino-derived Jeenode Microcontroller Board, Open Source Hardware, Open Source Hardware Design, Open Source Software, Open Source Software, Piezoelectric Transducers, Piezoresistive Pressure Sensor, Portable Instruments, Portable Sensor System, Pressure Measurement, Pressure Monitoring System, Pressure Sensors, Prewritten Libraries, Prototypes, Public Domain Software, Reliability, Software Libraries, Software Prototyping, Units (measurement)}
}

@inproceedings{squicciarini-policy-based:2008,
  author    = {Squicciarini, A.c. And Lee, Wonjun And Bertino, E. And Song, C.x.},
  title     = {A Policy-based Accountability Tool For Grid Computing Systems},
  booktitle = {IEEE Asia-pacific Services Computing Conference, 2008. Apscc '08},
  year      = {2008},
  pages     = {95--100},
  month     = dec,
  abstract  = {The Dynamic And Multi-organizational Nature Of Grid Systems Requires Effective And Efficient Accountability Systems To Scale For Accommodating Large Number Of Users And Resources. The Availability Of Detailed And Complete Accountability Data Is Crucial For Both The Grid Administrators And The Overall Grid Community. In This Paper We Present A Layered Architecture For Addressing The End-to-end Accountability Problem. We Introduce The Concept Of Accountability Agents, Entities In Charge Of Collecting Accountability Data, Keeping Track Of Submitted Jobs And Their Users. We Present A Simple Yet Effective Language To Specify The Relevant Accountability Data To Be Collected And Selectively Distributed By The Accountability Agents. Additionally, We Design A Decentralized And Scalable Approach To Accountability, So To Be Able To Monitor Jobs Workflow With Relatively Little Intrusion.},
  doi       = {10.1109/APSCC.2008.257},
  keywords  = {Access Control, Accountability, Authorization, Availability, Computerized Monitoring, Computer Science, Educational Institutions, Grid Computing, Grid Computing, Grid Computing Systems, Job Design, Jobs Workflow, Peer To Peer Computing, Policy-based Accountability Tool, Resource Management}
}

@inproceedings{kipp-green:2011,
  author    = {Kipp, A. And Jiang, Tao And Fugini, M.},
  title     = {Green Metrics For Energy-aware It Systems},
  booktitle = {2011 International Conference On Complex, Intelligent And Software Intensive Systems (cisis)},
  year      = {2011},
  pages     = {241--248},
  month     = jun,
  abstract  = {This Paper Presents A Novel Approach To Characterise Applications With Respect To Their Energy Consumption By Using A Set Of Energy-related Metrics, Called Green Metrics. These Indicators Are Based On Energy Consumption Measurements, Such As Indexes Of Computing Resource Usage, Of Environmental Impact, And Even Of Development Costs Required To (re)design An Application In Order To Optimise Its Energy Consumption Footprint, Or Of Organizational Factors Related To Application Management. Our Approach Is Framed In The Games (green Active Management Of Energy In It Service Centres) Eu Project1 About Green It. In This Paper, We Define Four Clusters Of Green Metrics Enabling To Feature An Application In Terms Of The Energy It Consumes At Run Time. Such Metrics Are The Basis For Measuring The ''greenness'' Of An Application And To Detect Where It Consumes And Wastes Energy. Hints Are Provided To Improve Applications Design And Execution. We Show Within An Application Scenario How Monitoring And Evaluation Of The Green Metrics Helps To Improve Energy Efficiency.},
  doi       = {10.1109/CISIS.2011.42},
  keywords  = {Benchmark Testing, Computing Resource Usage, Energy Aware It Systems, Energy-aware It Systems, Energy Consumption, Energy Consumption, Energy Consumption Footprint, Energy Efficiency, Energy Efficiency Measurement, Energy Measurement, Games, Green Metrics, Green Products, Indexes, Organisational Aspects, Organizational Factors, Performance Measurement, Power Aware Computing}
}

@book{trappe-introduction:2006,
  title      = {Introduction To Cryptography: With Coding Theory},
  publisher  = {Pearson Prentice Hall},
  year       = {2006},
  author     = {Trappe, Wade And Washington, Lawrence C},
  abstract   = {This Text Is For A Course In Cryptography For Advanced Undergraduate And Graduate Students. Material Is Accessible To Mathematically Mature Students Having Little Background In Number Theory And Computer Programming. Core Material Is Treated In The First Eight Chapters On Areas Such As Classical Cryptosystems, Basic Number Theory, The Rsa Algorithm, And Digital Signatures. The Remaining Nine Chapters Cover Optional Topics Including Secret Sharing Schemes, Games, And Information Theory. Appendices Contain Computer Examples In Mathematica, Maple, And Matlab. The Text Can Be Taught Without Computers.},
  isbn       = {0131862391 9780131862395 0131981994  9780131981997},
  language   = {English},
  location   = {Upper Saddle River, N.j.},
  shorttitle = {Introduction To Cryptography}
}

@techreport{sharma-applications:2009,
  author      = {Sharma, Bikash},
  title       = {Applications Of Data Mining In The Management Of Performance And Power In Data Centers},
  institution = {Dcse, Psu},
  year        = {2009},
  abstract    = {Performance And Power Issues Are Becoming Increasingly Important In The Design Of Large Data Centers For Supporting A Multitude Of Services. There Are Many Perspectives Of Addressing These Issues Using Various Computer Science Principles. In This Survey Report, I Will Discuss The Applications Of Data Mining Techniques To Manage Power And Performance In Data Centers. Although, The Use Of Data Mining In Designing Performance Centric And Energy Efficient Of Computer Systems Is Still In Its Infancy, I Will Elaborate On How Researchers Are Exploiting Data Mining And Machine Learning Approaches To Save Energy And Improve The Performance Of Computer Systems Ranging From Laptops To Large Data Centers. Specifically, I Will Summarize The Motivations, Current State Of The Art And Future Directions Of The Research In This Topic. I Will Brief Some Of The Recent And Notable Research Works In This Discipline. Towards The End, I Will Brief My Vision To Leverage The Recent Advances In The Applications Of Data Mining Techniques To Data Centers In My Phd Research Work.}
}

@techreport{tia-942:2005,
  author      = {{{TIA}-942},},
  title       = {ANSI/TIA-942 - Telecommunications Infrastructure Standard For Data Centers},
  institution = {Telecom. Industry Assossiation (tia)},
  year        = {2005},
  type        = {White Paper},
  number      = {942},
  abstract    = {This standard specifies the minimum requirements for telecommunications infrastructure of data centers and computer rooms, including single tenant enterprise data centers and multi-tenant internet hosting data centers. The topology specified in this document is intended to be applicable to any size data center.},
  copyright   = {Todos os direitos reservados},
  language    = {En-us},
  pages       = {148},
  shorttitle  = {Tia-942},
  urldate     = {2014-06-15}
}

@inproceedings{arno-reliability:2010,
  author     = {Arno, R. And Friedl, A And Gross, P. And Schuerger, R.},
  title      = {Reliability Of Example Data Center Designs Selected By Tier Classification},
  booktitle  = {2010 IEEE Industrial And Commercial Power Systems Technical Conference (i Cps)},
  year       = {2010},
  pages      = {1--8},
  abstract   = {When The Concept Of Reliability Began To Formally Become An Integrated Engineering Approach In The 50's, Reliability Was Associated With Failure Rate. Today The Term {\textquotedblleft}reliability{\textquotedblright} Is Used As An Umbrella Definition Covering A Variety Of Subjects Including Availability, Durability, Quality And Sometimes The Function Of The Product. Reliability Engineering Was Developed To Quantify {\textquotedblleft}how Reliable{\textquotedblright} A Component, Product Or System Was When Used In A Specific Application For A Specific Period Of Time. The Data Center Industry Has Come To Rely On {\textquotedblleft}tier Classifications{\textquotedblright} As Presented In A Number Of Papers By The Uptime Institute [1] As A Gradient Scale Of Data Center Configurations And Requirements From Least (tier 1) To Most Reliable (tier 4). This Paper Will Apply The Principles And Modeling Techniques Of Reliability Engineering To Specific Examples That Were Selected Based On Gradient Scale Provided By The Tier Classifications And Discuss The Results. A Review Of The Metrics Of Reliability Engineering Being Used Will Also Be Included.},
  date       = {2010-05},
  doi        = {10.1109/ICPS.2010.5489890},
  eventtitle = {2010 IEEE Industrial And Commercial Power Systems Technical Conference (i Cps)},
  keywords   = {Availability, Decision Support Systems, Failure Rate, Fiber Reinforced Plastics, Mean Time Between Failures (mtbf), Mean Time To Repair (mttr), Reliability}
}

@misc{romer-tier:2013,
  author     = {Romer, Rafael},
  title      = {Tier: Como {\'{e}} Feita A Classifica{\c{c}}{\~{a}}o E Quais As Diferen{\c{c}}as Entre Data Centers?},
  month      = dec,
  year       = {2013},
  abstract   = {Assim Como Grande Parte Dos Servi{\c{c}}os Oferecidos No Mercado, Data Centers Tamb{\'{e}}m Possuem Uma Classifica{\c{c}}{\~{a}}o Pr{\'{o}}pria Que Indica O Qu{\~{a}}o Preparados Eles Est{\~{a}}o Para Lidar Com Problemas E Qu{\~{a}}o S{\'{o}}lidas S{\~{a}}o Suas Infra-estruturas. Entenda.},
  langid     = {Brazil},
  shorttitle = {Tier},
  titleaddon = {Canaltech},
  type       = {Corporate},
  urldate    = {2014-08-19}
}
%http://corporate.canaltech.com.br/noticia/hosting/Entenda-como-e-feita-a-classificacao-de-Data-Centers-e-como-escolher-o-melhor/

@misc{osier-hardware:2010,
  author      = {Osier, Mixon, J.},
  title       = {Hardware Aberto: Como e Quando Funciona},
  month       = dec,
  year        = {2010},
  copyright   = {{\copyright} Copyright{~}IBM Corporation{~}2010},
  institution = {Ibm Corporation},
  keywords    = {Tt400},
  language    = {Pt-br},
  shorttitle  = {Hardware Aberto},
  type        = {Ct316},
  urldate     = {2014-05-31}
}
%http://www.ibm.com/developerworks/br/library/os-openhardware/

@inproceedings{nelson-locating:2013,
  author    = {Nelson, J.c. And Santala, T. And Lenchner, J. And Calio, R. And Frissora, M. And Miller, J.e.},
  title     = {Locating And Tracking Data Center Assets Using Active Rfid Tags And A Mobile Robot},
  booktitle = {2013 10\textsuperscript{th} International Conference And Expo On Emerging Technologies For A Smarter World (cewit)},
  year      = {2013},
  pages     = {1--6},
  month     = oct,
  abstract  = {We Describe An Approach To Completely Automated Asset Tracking In Data Centers Using A Vision-based Mobile Robot In Conjunction With Active Rfid Tags. Typically, Active Rfid Tags Are Tracked Using Fixed Readers. The Granularity With Which One Can Localize Tags Is Based On The Number Of These Fixed Readers, Each Of Which Is Not Inexpensive. In Large Data Centers, The Cost Of Such A Solution Can Therefore Become Excessive. We Describe The Use Of A Mobile Robot, Utilizing A Single Rfid Reader And A Variety Of Algorithms For Locating The Plethora Of Rfid Tags One Can Encounter In Such Data Centers. These Approaches Are Validated Through Experiments Performed In A Production Industrial Data Center.},
  doi       = {10.1109/CEWIT.2013.6713757},
  keywords  = {Active Rfid Tags, Assets, Asset Tracking, Automated Asset Tracking, Autonomous, Computer Centres, Data Center Assets Tracking, Data Centers, Mobile Robots, Navigation, Production Industrial Data Center, Radiofrequency Identification, Rfid, Rfid Tags, Robot, Robot Kinematics, Single Rfid Reader, Tiles, Vision Based Mobile Robot}
}

@misc{forbes-facebook:2014,
  author   = {Marko, Kurt},
  title    = {Facebook Hastens The Era Of Open Source Hardware},
  month    = jun,
  year     = {2014},
  abstract = {If Necessity Is The Mother Of Invention, Then The Need For Cheap, Efficient, Compact Servers And Network Equipment Has Made Facebook An Innovator Of Gear Optimized For Cloud Data Centers And Workloads. It{\textquoteright}s Leadership In The Development Of Standard, Hyper Scale Hardware Using Interchangeable Commodity Components Led To The Open [...]},
  journal  = {Forbes},
  keywords = {Cio Network, Cloud Computing, Cumulus Networks, Facebook, Game Changers, Gear, Linux, On Demand, Open Compute Project, Openflow, Open Source, Tech, Tor, Transformational Tech},
  urldate  = {2014-07-17}
}


@inproceedings{nunez-metamodel:2013,
  author    = {Nunez, D. And Fernandez-gago, C. And Pearson, S. And Felici, M.},
  title     = {A Metamodel For Measuring Accountability Attributes In The Cloud},
  booktitle = {2013 IEEE 5\textsuperscript{th} International Conference On Cloud Computing Technology And Science (cloudcom)},
  year      = {2013},
  volume    = {1},
  pages     = {355--362},
  month     = dec,
  abstract  = {Cloud Governance, And In Particular Data Governance In The Cloud, Relies On Different Technical And Organizational Practices And Procedures, Such As Policy Enforcement, Risk Management, Incident Management And Remediation. The Concept Of Accountability Encompasses Such Practices, And Is Essential For Enhancing Security And Trustworthiness In The Cloud. Besides This, Proper Measurement Of Cloud Services, Both At A Technical And Governance Level, Is A Distinctive Aspect Of The Cloud Computing Model. Hence, A Natural Problem That Arises Is How To Measure The Impact On Accountability Of The Procedures Held In Practice By Organizations That Participate In The Cloud Ecosystem. In This Paper, We Describe A Metamodel For Addressing The Problem Of Measuring Accountability Properties For Cloud Computing, As Discussed And Defined By The Cloud Accountability Project (a4cloud). The Goal Of This Metamodel Is To Act As A Language For Describing: (i) Accountability Properties In Terms Of Actions Between Entities, And (ii) Metrics For Measuring The Fulfillment Of Such Properties. It Also Allows The Recursive Decomposition Of Properties And Metrics, From A High-level And Abstract World To A Tangible And Measurable One. Finally, We Illustrate Our Proposal Of The Metamodel By Modelling The Transparency Property, And Define Some Metrics For It.},
  doi       = {10.1109/CloudCom.2013.53},
  keywords  = {A4cloud, Accountability, Accountability Attribute Measurement, Atmospheric Measurements, Cloud Accountability Project, Cloud Computing, Cloud Computing, Cloud Computing Model, Cloud Ecosystem, Cloud Governance, Cloud Services, Computational Modeling, Context, Data Governance, Incident Management, Metamodel, Metamodel, Metrics, Non-functional Properties, Organizations, Particle Measurements, Policy Enforcement, Recursive Decomposition, Risk Management, Security Of Data}
}

@inproceedings{guo-take:2013,
  author     = {Guo, Yukang And Jones, Matt And Cowan, Benjamin And Beale, Russell},
  title      = {Take It Personally: Personal Accountability And Energy Consumption In Domestic Households},
  booktitle  = {Chi '13 Extended Abstracts On Human Factors In Computing Systems},
  year       = {2013},
  series     = {Chi Ea '13},
  pages      = {1467--1472},
  publisher  = {ACM},
  abstract   = {We Explore The Overlooked Area Of Personal Energy Consumption In The Context Of A Shared Domestic Household. We Discuss The Potential Benefits Of Such An Approach. We Report The Results Of A Lab Study And Field Trial With Four Households Using A Personal Energy Monitoring System. We Describe The Results Of The Studies And Discuss How Such Previously Hidden Information Might Raise Awareness Of Individual Energy Consumption And The Benefits And Problems This Entails.},
  doi        = {10.1145/2468356.2468618},
  isbn       = {978-1-4503-1952-2},
  keywords   = {Energy Consumption, Mobiles, Wearable Computing.},
  location   = {New York, Ny, Usa},
  shorttitle = {Take It Personally},
  urldate    = {2014-05-13}
}

@misc{embedds-adc:2011,
  author   = {Embedds},
  title    = {Adc On Atmega328. Part 1},
  year     = {2011},
  abstract = {Microcontrollers Are Meant To Deal With Digital Information. They Only Understant '0' And '1' Values. So What If We Need To Get Some Non Digital Data In To Microcontroller. The Only Way Is To Digit...},
  journal  = {Embedded Projects From Around The Web},
  urldate  = {2014-06-02}
}
%http://www.embedds.com/adc-on-atmega328-part-1/

@inproceedings{trobec-energy:2013,
  author    = {Trobec, R. And Depolli, M. And Skala, K. And Lipic, T.},
  title     = {Energy Efficiency In Large-scale Distributed Computing Systems},
  booktitle = {2013 36\textsuperscript{th} International Convention On Information Communication Technology Electronics Microelectronics (mipro)},
  year      = {2013},
  pages     = {253--257},
  month     = may,
  abstract  = {The Ever-increasing Energy Consumption In Large-scale Distributed Computing Systems Such As Clusters, Grids And Clouds Raises Social, Technical, Economical, And Environmental Concerns. Therefore, Designing Novel Energy-efficient Approaches, To Reduce Energy Consumption, At All Levels Of Distributed System Architecture Is Of Great Importance For The Whole Society. However, The Essential Step Towards The Introduction Of Energy-efficiency In Large-scale Distributed Systems Is To Measure The Power Consumption, Accurately, Reliably, And Continually In Each Component Of The System. This Paper Briefly Surveys The Current Approaches For Measuring And Profiling Power Consumption In Large Scale Distributed Systems. Furthermore, The Practical Case Study Of A Real-time Power Measurement In Multi-core Computing System, As A Basic Building Block Of A Distributed Computing System, Is Presented.},
  keywords  = {Clouds, Clusters, Computers, Current Measurement, Distributed Processing, Energy Conservation, Energy Consumption, Energy Consumption, Energy Efficiency, Energy Measurement, Environmental Concerns, Environmental Factors, Grids, Hardware, Large-scale Distributed Computing Systems, Multicore Computing System, Multiprocessing Systems, Power Aware Computing, Power Demand, Power Measurement, Real-time Power Measurement}
}

@article{wang-review:2011,
  author     = {Wang, Lizhe And Khan, Samee U.},
  title      = {Review Of Performance Metrics For Green Dc: A Taxonomy Study},
  journal    = {The Journal Of Supercomputing},
  year       = {2011},
  pages      = {639--656},
  month      = oct,
  abstract   = {Data Centers Now Play An Important Role In Modern It Infrastructures. Although Much Research Effort Has Been Made In The Field Of Green Data Center Computing, Performance Metrics For Green Data Centers Have Been Left Ignored. This Paper Is Devoted To Categorization Of Green Computing Performance Metrics In Data Centers, Such As Basic Metrics Like Power Metrics, Thermal Metrics And Extended Performance Metrics I.e. Multiple Data Center Indicators. Based On A Taxonomy Of Performance Metrics, This Paper Summarizes Features Of Currently Available Metrics And Presents Insights For The Study On Green Data Center Computing.},
  doi        = {10.1007/s11227-011-0704-3},
  issn       = {0920-8542, 1573-0484},
  keywords   = {Computer Science, General, Data Center, Green Computing, Performance Metrics, Processor Architectures, Programming Languages, Compilers, Interpreters},
  language   = {En},
  shorttitle = {Review Of Performance Metrics For Green Data Centers},
  urldate    = {2014-06-30}
}

@book{jia-distributed:2006,
  title      = {Distributed Network Systems: From Concepts To Implementations},
  publisher  = {Springer},
  year       = {2006},
  author     = {Jia, Weijia And Zhou, Wanlei},
  month      = jun,
  abstract   = {This Volume Covers Both Theoretical And Practical Aspects Of Distributed Computing. It Describes The Client-server Model For Developing Distributed Network Systems, The Communication Paradigms Used In A Distributed Network System, And The Principles Of Reliability And Security In The Design Of Distributed Network Systems. Based On Theoretical Introductions, The Book Presents Various Implementation Strategies And Techniques For Building Distributed Network Systems, Including Examples In Tcp/ip Communications, The Use Of Remote Procedure Call And Remote Method Invocation Techniques, And The Development Of Web-based Applications, Distributed Databases, And Mobile Computing Systems.},
  isbn       = {9780387238401},
  keywords   = {Computers / Cad-cam, Computers / Computer Science, Computers / Networking / Hardware, Computers / Systems Architecture / General},
  language   = {En},
  shorttitle = {Distributed Network Systems}
}

@inproceedings{liaperdos-building:2010,
  author    = {Liaperdos, I. And Paraskevas, I. And Potirakis, S.m. And Rangoussi, M.},
  title     = {Building A Low-cost Network For Power-quality Monitoring With Open-source-hardware Nodes},
  booktitle = {7\textsuperscript{th} Medpower 2010},
  year      = {2010},
  pages     = {1--5},
  abstract  = {This Paper Presents The Guidelines For Building A Low-cost Network Suitable For Power-quality Monitoring. The Implementation Of A Standalone Basic Node Capable Of Extracting Various Power-quality Metrics (total Harmonic Distortion-thd, Crest Factor, Etc) In An Open-source Hardware Embedded System Board Is Described. By Utilizing Simple Signal Processing Techniques Directly In Hardware, This Node Maintains High Portability Due To Its Small Dimensions. Furthermore, Exploitation Of Its Built-in Tcp/ip Capabilities Allows The Deployment Of A Wide Area Network By The Interconnection Of Basic Nodes, In Order To Provide Power-quality Data Collection For Further Processing And Evaluation. Due To The Distributed Processing Load, The Proposed Network Can Achieve High Efficiency And Reliability.},
  doi       = {10.1049/cp.2010.0895},
  keywords  = {Built-in Tcp-ip Capabilities, Crest Factor, Data Acquisition, Digital Signal Processing, Distributed Processing Load, Embedded Systems, Harmonic Distortion, Low-cost Network, Open-source Hardware Embedded System Board, Power Engineering Computing, Power Quality Metrics, Power-quality Metrics, Power-quality Monitoring, Power Supply Quality, Power System Monitoring, Signal Processing Techniques, Thd, Total Harmonic Distortion, Wide Area Network}
}

@inproceedings{lenchner-towards:2011,
  author    = {Lenchner, Jonathan And Isci, Canturk And Kephart, Jeffrey O. And Mansley, Christopher And Connell, Jonathan And Mcintosh, Suzanne},
  title     = {Towards Data Center Self-diagnosis Using A Mobile Robot},
  booktitle = {Proceedings Of The 8\textsuperscript{th} ACM International Conference On Autonomic Computing},
  year      = {2011},
  series    = {Icac '11},
  pages     = {81--90},
  publisher = {ACM},
  abstract  = {We Describe An Inexpensive Robot That Serves As A Physical Autonomic Element, Capable Of Navigating, Mapping And Monitoring Data Centers With Little Or No Human Involvement, Even Ones That It Has Never Seen Before. Through A Series Of Real Experiments And Simulations, We Establish That The Robot Is Sufficiently Accurate, Efficient And Robust To Be Of Practical Benefit In Real Data Center Environments. We Demonstrate How The Robot's Integration With Maximo For Energy Optimization, A Commercial Data Center Energy Management Product, Supports Autonomic Management At The Level Of The Data Center As A Whole, Particularly Self-diagnosis Of Emerging Thermal Problems.},
  doi       = {10.1145/1998582.1998597},
  isbn      = {978-1-4503-0607-2},
  keywords  = {Autonomous Systems, Data Centers, Energy Efficiency, Mobile Robots, Self-managing},
  location  = {New York, Ny, Usa},
  urldate   = {2014-05-30}
}

@misc{gartner-gartner:2013,
  author   = {Gartner},
  title    = {Gartner It Glossary: Term ``data Center''},
  year     = {2013},
  abstract = {The Data Center Is The Department In An Enterprise That Houses And Maintains Back-end Information Technology (it) Systems And Data Stores---its Mainframes, Servers And Databases. In The Days Of Large, Centralized It Operations, This Department And All The Systems Resided In One Physical Place, Hence The Name Data Center. With Today{\textquoteright}s More Distributed Computing Methods,...},
  journal  = {Gartner It Glossary},
  keywords = {It Glossary},
  language = {English},
  urldate  = {2014-07-18}
}

@article{harnett-open:2011,
  author   = {Harnett, C.},
  title    = {Open Source Hardware For Instrumentation And Measurement},
  journal  = {IEEE Instrumentation Measurement Magazine},
  year     = {2011},
  volume   = {14},
  number   = {3},
  pages    = {34--38},
  month    = jun,
  abstract = {The Term ''open Source'' Originally Applied To Software Projects With Publicly Available Source Code For Others To Modify, Improve, And Compile. Modified Software Projects Were Then Often Required To Release Their Source Code Under The Terms Of The ''open Source'' Agreement. Currently, ''open Source'' Is Also Available For Hardware Projects And Includes Printed Circuit Board Designs, Photomask Layouts And Mechanical Assemblies. While The Scientific Community Requests Journal Authors To Provide Enough Information For Other Groups To Replicate Their Work, And Patent Examiners Hold Inventors To The Same Test, The Osh Community Requires Even More Details And Prefers That They Be Available Online. For Example, Downloadable Electronic Design Files For Printed Circuit Boards And 3-d Printable Enclosures Make It Possible For An Engineer To Modify An Instrument Design From The Desktop, Order The Parts From Several Different Manufacturers, And Receive A Customized Kit For Assembly - Or Even Have The Parts Assembled And Shipped. The Original Designers May Remain Completely Unaware Of The Development Or May Receive Credit Or A Royalty For Their Work Depending On The Terms Under Which They Released The Design.},
  doi      = {10.1109/MIM.2011.5773535},
  issn     = {1094-6969},
  keywords = {3d Printable Enclosures, Electronic Design Files, Hardware, Instrumentation, Instruments, Masks, Measurement, Mechanical Assemblies, Open Source Hardware, Open Source Software, Photomask Layouts, Printed Circuit Board Designs, Printed Circuit Design, Printed Circuits, Software Engineering, Software Projects, Source Code}
}

	number = {1},	volume = {17},

@article{wang-survey:2012,
  author     = {Wang, Xiaofei And Vasilakos, Athanasios V. And Chen, Min And Liu, Yunhao And Kwon, Ted Taekyoung},
  title      = {A Survey Of Green Mobile Networks: Opportunities And Challenges},
  journal    = {Mna},
  year       = {2012},
  pages      = {4--20},
  month      = feb,
  abstract   = {The Explosive Development Of Information And Communication Technology (ict) Has Significantly Enlarged Both The Energy Demands And The Co 2 Emissions, And Consequently Contributes To Make The Energy Crisis And Global Warming Problems Worse. However, As The Main Force Of The Ict Field, The Mobile Networks, Are Currently Focusing On The Capacity, Variety And Stability Of The Communication Services, Without Paying Too Much Severe Concerns On The Energy Efficiency. The Escalating Energy Costs And Environmental Concerns Have Already Created An Urgent Need For More Energy-efficient ``green'' Wireless Communications. In This Paper, We Survey And Discuss Various Remarkable Techniques Toward Green Mobile Networks To Date, Mainly Targeting Mobile Cellular Networks. We Also Summarize The Current Research Projects Related To Green Mobile Networks, Along With The Taxonomy Of Energy-efficiency Metrics. We Finally Discuss And Elaborate Future Research Opportunities And Design Challenges For Green Mobile Networks.},
  doi        = {10.1007/s11036-011-0316-4},
  issn       = {1383-469X, 1572-8153},
  keywords   = {Business Information Systems, Communications Engineering, Networks, Computer Communication Networks, Electrical Engineering, Energy Efficiency, Green Technique, Mobile Networks},
  language   = {En},
  shorttitle = {A Survey Of Green Mobile Networks},
  urldate    = {2014-05-28}
}

@article{schwartz-uncovering:2013,
  author     = {Schwartz, Tobias And Stevens, Gunnar And Ramirez, Leonardo And Wulf, Volker},
  title      = {Uncovering Practices Of Making Energy Consumption Accountable: A Phenomenological Inquiry},
  journal    = {ACM Transactions On Computer-human Interaction},
  year       = {2013},
  volume     = {20},
  number     = {2},
  pages      = {121--1230},
  month      = may,
  abstract   = {Reacting To The Discussion On Global Warming, The Hci Community Has Started To Explore The Design Of Tools To Support Responsible Energy Consumption. An Important Part Of This Research Focuses On Motivating Energy Savings By Providing Feedback Tools Which Present Consumption Metrics Interactively. In This Line Of Work, The Configuration Of Feedback Has Been Mainly Discussed Using Cognitive Or Behavioral Factors. This Narrow Focus, However, Misses A Highly Relevant Perspective For The Design Of Technology That Supports Sustainable Lifestyles: To Investigate The Multiplicity Of Forms In Which Individuals Or Collectives Actually Consume Energy. In This Article, We Broaden This Focus, By Taking A Phenomenological Lens To Study How People Use Off-the-shelf Eco-feedback Systems In Private Households To Make Energy Consumption Accountable And Explainable. By Reconstructing Accounting Practices, We Delineate Several Constitutive Elements Of The Phenomenon Of Energy Usage In Daily Life. We Complement These Elements With A Description Of The Sophisticated Methods Used By People To Organize Their Energy Practices And To Give A Meaning To Their Energy Consumption. We Describe These Elements And Methods, Providing Examples Coming From The Fieldwork And Uncovering Observed Strategies To Account For Consumption. Based On Our Results, We Provide A Critical Perspective On Existing Eco-feedback Mechanisms And Describe Several Elements For A Design Rationale For Designing Support For Responsible Energy Consumption. We Argue That Interactive Feedback Systems Should Not Simply Be An End, But Rather A Resource For The Construction Of The Artful Practice Of Making Energy Consumption Accountable.},
  doi        = {10.1145/2463579.2463583},
  issn       = {1073-0516},
  keywords   = {Energy, Phenomenology, Sustainability},
  shorttitle = {Uncovering Practices Of Making Energy Consumption Accountable},
  urldate    = {2014-05-13}
}

@inproceedings{wang-optimal:2013,
  author    = {Wang, Yanzhi And Lin, Xue And Pedram, Massoud And Park, Sangyoung And Chang, Naehyuck},
  title     = {Optimal Control Of A Grid-connected Hybrid Electrical Energy Storage System For Homes},
  booktitle = {Proceedings Of The Conference On Design, Automation And Test In Europe},
  year      = {2013},
  series    = {Date '13},
  pages     = {881--886},
  publisher = {Eda Consortium},
  abstract  = {Integrating Residential Photovoltaic (pv) Power Generation And Electrical Energy Storage (ees) Systems Into The Smart Grid Is An Effective Way Of Utilizing Renewable Power And Reducing The Consumption Of Fossil Fuels. This Has Become A Particularly Interesting Problem With The Introduction Of Dynamic Electricity Energy Pricing Models Since Electricity Consumers Can Use Their Pv-based Energy Generation And Ees Systems For Peak Shaving On Their Power Demand Profile From The Grid, And Thereby, Minimize Their Electricity Bill. Due To The Characteristics Of A Realistic Electricity Price Function And The Energy Storage Capacity Limitation, The Control Algorithm For A Residential Ees System Should Accurately Account For Various Energy Loss Components During Operation. Hybrid Electrical Energy Storage (hees) Systems Are Proposed To Exploit The Strengths Of Each Type Of Ees Element And Hide Its Weaknesses So As To Achieve A Combination Of Performance Metrics That Is Superior To Those Of Any Of Its Individual Ees Components. This Paper Introduces The Problem Of How Best To Utilize A Hees System For A Residential Smart Grid User Equipped With Pv Power Generation Facilities. The Optimal Control Algorithm For The Hees System Is Developed, Which Aims At Minimization Of The Total Electricity Cost Over A Billing Period Under A General Electricity Energy Price Function. The Proposed Algorithm Is Based On Dynamic Programming And Has Polynomial Time Complexity. Experimental Results Demonstrate That The Proposed Hees System And Optimal Control Algorithm Achieves 73.9% Average Profit Enhancement Over Baseline Homogeneous Ees Systems.},
  isbn      = {978-1-4503-2153-2},
  keywords  = {Hybrid Electrical Energy Storage System, Optimal Control, Smart Grid},
  location  = {San Jose, Ca, Usa},
  urldate   = {2014-05-13}
}

@inproceedings{chen-wireless:2009,
  author    = {Chen, Wei And Nguyen, Son Tung And Coops, R. And Oetomo, S.b. And Feijs, L.},
  title     = {Wireless Transmission Design For Health Monitoring At Neonatal Intensive Care Units},
  booktitle = {2\textsuperscript{nd} Isabel 2009},
  year      = {2009},
  pages     = {1--6},
  month     = nov,
  abstract  = {Health Monitoring Is Crucial For The Survival Of The Ill And Fragile Infants Admitted At The Neonatal Intensive Care Unit (nicu) In A Hospital. However, The Adhesive Electrodes And Wires Cause Discomfort To The Patients And Hamper The Parent-child Interaction. In This Paper, We Propose The Application Of Wireless Transmission Technology For Neonatal Monitoring At Nicu. To Demonstrate The Design Concept, A Prototype Wireless Transmission System Is Built Using Bluesmirf And Arduino Pro Mini. Software Is Developed For Ensure The Correct Data Transmission, Detection And Display. The System Is Designed To Be Suitable For Integration Into A Non-invasive Monitoring Platform Such As A Smart Neonatal Jacket. Experimental Results Show That The Prototype System Successfully Transmits And Receives Data From Multiple Sensors Within The Range Of 20 M.},
  doi       = {10.1109/ISABEL.2009.5373671},
  keywords  = {Adhesive Electrodes, Application Software, Arduino Pro Mini, Bluesmirf, Bluetooth, Data Communication, Data Detection, Data Display, Data Transmission, Design Process, Displays, Distance 20 M, Electrodes, Health Care, Health Monitoring, Hospitals, Infants, Multiple Sensors, Neonatal Intensive Care Units, Neonatal Monitoring, Nicu, Noninvasive Monitoring Platform, Obstetrics, Parent-child Interaction, Patient Monitoring, Pediatrics, Prototypes, Prototype System, Radio Access Networks, Smart Neonatal Jacket, Software Prototyping, Telemedicine, Wireless Sensor Networks, Wireless Transmission, Wireless Transmission Design, Wires}
}

@inproceedings{batagelj-digital:2009,
  author    = {Batagelj, B. And Marovt, J. And Troha, M. And Mahnic, D.},
  title     = {Digital Airbrush},
  booktitle = {Elmar, 2009. Elmar '09. International Symposium},
  year      = {2009},
  pages     = {305--308},
  month     = sep,
  abstract  = {The Basic Idea Is Simple: Graffiter Paints With A Specially Modified Can, Which When Pressed On The Cap Does Not Leave Color Traces, But Emits Infrared Light. The Computer Application Draws The Appropriate Graffiti On The Canvas, Which Is Positioned In Front Of The Graffiter. Infrared Camera Provides Detection Of The Light Source For The Application, Which Then Correctly Determines The Color, Size And Density (the Graffiter Regulates These Parameters Through The Speed Buttons, Which Are Located On The Can) And In The End Of This Process, The Current Drawing Track Is Projected On The Canvas. The Most Important Algorithms Used In The Implementation Of The Software Solution Are: An Algorithm For Locating The Brightest Area, The Algorithm For The Implementation Of The Drops And The Algorithm For Interpolation. Important Component Of Simulation Is Also A Bluetooth Connection To The Arduino Bt Platform, Which Is Connected To Three Potentiometers. These Are Used By Graffiter To Manipulate Painting Parameters. The Results Of Extensive Tests Have Shown That The Prototype Has Potential And That The Final Simulation Perfectly Follows The Basic Idea. The Problem Occurs Only In The Lack Of Quality Of The Equipment (infrared Camera, Computer Power) For Full Implementation.},
  keywords  = {Airbrush, Application Software, Arduino Bt Platform, Art, Bluetooth, Bluetooth Connection, Cameras, Color, Color Traces, Computer Applications, Computer Graphics, Computer Vision, Digital Airbrush, Graffiter Paints, Graffiti, Image Colour Analysis, Infrared Camera, Infrared Detectors, Infrared Light, Interactive Entertainment, Interpolation, Light Sources, Paints, Potentiometers, Software Algorithms, Virtual Art}
}

%title = {Improving Energy Efficiency in Data Centers and Federated Cloud Environments}, : Comparison of {CoolEmAll} and Eco2Clouds Approaches and Metrics},

@inproceedings{volk-improving:2013,
  author     = {Volk, E. And Tenschert, A. And Gienger, M. And Oleksiak, A. And Siso, L. And Salom, J.},
  title      = {Improving Energy Efficiency In Data Centers And Federated Cloud Environments: Approaches And Metrics},
  booktitle  = {2013 3\textsuperscript{rd} Cgc},
  year       = {2013},
  pages      = {443--450},
  month      = sep,
  abstract   = {Significant Data Centers Energy Footprints And The Increase In Energy Prices Have Stimulated Investigations Into Possible Metrics And Methods To Define, Quantify And Improve The Energy Efficiency Of Data Centers And Federated Cloud Environments. Studies Include Metrics And Analyses From Various Points Of Views, That Address Both Design And Operation Phases. In This Paper We Present Two Complementary Energy-efficiency Optimization Approaches Covered In The Scope Of Eu Projects: Coolemall - With Focus On Building Energy Efficient Data Centers, And Eco2clouds - With Focus On Energy-efficient Cloud-application Deployment In Federated Cloud-environments, And Describe Metrics Applied In These Projects To Assess And Optimize Energy-efficiency. Both Approaches Make Use Of Metrics To Assess Energy-efficiency Of Data Center- And Cloud Resources, And Energy-costs Of Application/workload Execution For Various Data Center Granularity Levels And Federation-sites.},
  doi        = {10.1109/CGC.2013.76},
  keywords   = {Application-workload Execution Energy-costs, Cloud Computing, Cloud Federations, Cloud Resources, Complementary Energy-efficiency Optimization Approach, Computer Centres, Coolemall Approach, Cooling, Data Center Energy Footprint, Data Center Granularity Levels, Design Phase, Eco2clouds Approach, Energy Aware Data Centers, Energy Conservation, Energy Consumption, Energy Efficiency, Energy Efficiency, Energy-efficient Cloud-application Deployment, Eu Projects, Federated Cloud Environments, Federation-sites, Green Products, Heating, Measurement, Metrics, Monitoring, Operation Phase},
  shorttitle = {Improving Energy Efficiency In Data Centers And Federated Cloud Environments}
}

@misc{oshw-definicao:2013,
  author     = {{Open Source Hardware Association}},
  title      = {Defini{\c{c}}{\~{a}}o De Open Source Hardware (oshw) 1.0},
  month      = mar,
  year       = {2013},
  abstract   = {A Vers{\~{a}}o Preliminar Da Defini{\c{c}}{\~{a}}o 1.0 De Oshw Draft Est{\'{a}} Baseada Na Open Source Definition Para Open Source Software E Na Vers{\~{a}}o Preliminar Da Defini{\c{c}}{\~{a}}o 0.5 De Oshw. Esta Defini{\c{c}}{\~{a}}o {\'{e}} Uma Deriva{\c{c}}{\~{a}}o Da Open Source Definition, Que Foi Criada Por Bruce Perens E Os Desenvolvedores Do Debian Como As Guias De Desenvolvimento Do Debian Free Software.},
  copyright  = {Creative Commons Attribution-sharealike License},
  language   = {Pt-br},
  shorttitle = {Defini{\c{c}}{\~{a}}o De Open Source Hardware},
  urldate    = {2014-06-02}
}
%http://freedomdefined.org/OSHW/translations/pt

@inproceedings{iyengar-reducing:2010,
  author    = {Iyengar, M. And Schmidt, R. And Caricari, J.},
  title     = {Reducing Energy Usage In Data Centers Through Control Of Room Air Conditioning Units},
  booktitle = {2010 12{th} IEEE Itherm},
  year      = {2010},
  pages     = {1--11},
  month     = jun,
  abstract  = {Information Technology Data Centers Consume A Large Amount Of Electricity In The Us And World-wide. Cooling Has Been Found To Contribute About One Third Of This Energy Use. The Two Primary Contributors To The Data Center Cooling Energy Use Are The Refrigeration Chiller And The Computer Room Air Conditioning Units (cracs). There Have Been Recent Changes In Specifications For The Data Center Environmental Envelopes As Mandated By Ashrae (american Society For Heating Refrigeration And Air Conditioning Engineers), One Of Which Specifically Pertains To The Upper And Lower Bound Of Air Temperatures At The Inlet To Servers That Are Housed In Data Center Rooms. These Changes Have Been Put In Place In Part To Address The Desire For Greater Cooling Energy Efficiency Of These Facilities. This Paper Primarily Focuses On The Methodologies To Reduce The Energy Usage Of Room Air Conditioning Devices By Exploiting These Recent Changes In Standards For The Equipment Environmental Envelope. A 22000 Square Foot (6706 M2) Data Center With 739 Kilo Watt Of It Load Is Used As A Representative Example For Numerical Cfd Analyses Using A Commercial Software Package To Demonstrate Methodologies To Reduce The Cooling Energy Use Of Information Technology Data Centers. Several Test Case Simulations Are Used To Enable The Calculation Of Room Level Air Temperature Fields For Varying Design Conditions Such As Different Numbers Of Operational Cracs Or The Volumetric Air Flow Rate Setting Of The Cracs. Computation Of Cooling Energy Is Carried Out Using Available Vendor Equipment Information. The Relationship Between The Reduction In Energy Usage In Crac Units And The Server Inlet Air Temperatures Are Quantified And A Systematic Methodology For Crac Shut Off Is Proposed. The Relative Magnitude Of Reduction In Data Center Cooling Energy Use From Shutting Off Cracs Or Reducing Crac Motor Speeds Is Also Compared With Scenarios Involving Increases In Refrigeration Chiller Plant Water Temperatu- - Re Set Point.},
  doi       = {10.1109/ITHERM.2010.5501418},
  keywords  = {Air Conditioning, American Society For Heating Refrigeration And Air Conditioning Engineers, Ashrae, Cfd Analyses, Computer Centres, Computer Room Air Conditioning Units, Cooling, Cooling Energy, Data Center, Data Centers, Data Engineering, Energy Consumption, Energy Efficiency, Energy Usage, Heat Engines, Information Technology, Power Engineering And Energy, Raised Floor, Refrigeration, Refrigeration Chiller Plant, Temperature, Thermal Management}
}

@article{glanz-data:2012,
  author   = {Glanz, James},
  title    = {Data Centers Waste Vast Amounts Of Energy, Belying Industry Image},
  journal  = {The New York Times},
  year     = {2012},
  month    = sep,
  abstract = {Helping To Process The Staggering Amount Of Internet Activity That Occurs, Data Centers Waste Vast Amounts Of Energy, Belying The Information Industry's Image Of Environmental Friendliness.},
  chapter  = {Technology},
  issn     = {0362-4331},
  keywords = {Air Pollution, Amazon.com Inc, Cloud Computing, Cloud Factories The (series), Computer Network Outages, Computers And The Internet, Data Centers, Diesel Power, Electric Light And Power, Energy Efficiency, Facebook Inc, Google Inc, Lexisnexis Group, Mckinsey & Co, Series, Yahoo! Inc},
  urldate  = {2014-05-31}
}

@inproceedings{mcintosh-semi-automated:2011,
  author    = {Mcintosh, S. And Kephart, J.o. And Lenchner, J. And Feridun, M. And Nidd, M. And Tanner, A. And Yang, B. And Barabasi, I.},
  title     = {Semi-automated Data Center Hotspot Diagnosis},
  booktitle = {2011 7\textsuperscript{th} International Conference On Network And Service Management (cnsm)},
  year      = {2011},
  pages     = {1--7},
  month     = oct,
  abstract  = {An Increasingly Important Requirement For Energy-efficient Data Center Operation Is To Diagnose And Fix Thermal Anomalies That Sometimes Occur Due To Excessive Workload Or Equipment Failures. Today, The Task Of Diagnosing Thermal Anomalies Entails Expert But Tedious Analysis Of Data Collected Manually From Disparate Management Systems. Our Ultimate Goal Is To Substantially Reduce The Time, Tedium And Expertise Required To Diagnose Thermal Hotspots By Developing A System That Generates Accurate Diagnoses Automatically. We Describe A Substantial Step Towards This Goal: A Loosely-coupled, Semi-automated Thermal Diagnosis System That Integrates It And Facilities Data, Uses Simple Heuristics To Highlight The Most Likely Culprits, And Provides A Graphical Interface That Enables An Administrator To Narrow The List Further By Exploring Data Correlations. Among The Challenges Addressed By Our Solution Are Coping With Heterogeneous Data Types And Data Access Methods, And Detecting And Managing Erroneous Sensor Readings.},
  keywords  = {Blades, Computer Centres, Cooling, Data Access Methods, Data Analysis, Data Correlations, Disparate Management Systems, Energy-efficient Data Center Operation, Energy Management, Equipment Failures, Erroneous Sensor Reading Detection, Erroneous Sensor Reading Management, Excessive Workload, Graphical Interface, Green Products, Heterogeneous Data Types, Linked Data, Loosely-coupled Semi-automated Thermal Diagnosis System, Monitoring, Semantic Web, Semi-automated Data Center Hotspot Diagnosis, Servers, Systems Management Data Integration, Temperature Measurement, Temperature Sensors, Thermal Anomalies, Thermal Hotspots, Tiles}
}

@book{murugesan-harnessing:2012,
  title      = {Harnessing Green It: Principles And Practices},
  publisher  = {Wiley},
  year       = {2012},
  author     = {Murugesan, San And Gangadharan, G. R.},
  edition    = {First},
  month      = oct,
  abstract   = {ultimately, This Is A Remarkable Book, A Practical Testimonial, And A Comprehensive Bibliography Rolled Into One. It Is A Single, Bright Sword Cut Across The Various Murky Green It Topics. And If My Mistakes And Lessons Learned Through The Green It Journey Are Any Indication, This Book Will Be Used Every Day By Folks Interested In Greening It.''---{~}simon Y. Liu, Ph.d. & Ed.d., Editor-in-chief,{~}it Professional{~}magazine, IEEE Computer Society, Director, U.s. National Agricultural Librarythis Book Presents A Holistic Perspective On Green It By Discussing Its Various Facets And Showing How To Strategically Embrace Itharnessing Green It: Principles And Practices{~}examines Various Ways Of Making Computing And Information Systems Greener -- Environmentally Sustainable -, As Well As Several Means Of Using Information Technology (it) As A Tool And An Enabler To Improve The Environmental Sustainability. The Book Focuses On Both Greening Of It And Greening By It -- Complimentary Approaches To Attaining Environmental Sustainability. {~} In A Single Volume, It {~} Comprehensively Covers Several Key Aspects Of Green It - Green Technologies, Design, Standards, Maturity Models, Strategies And Adoption -, And Presents A Clear Approach To Greening It Encompassing Green Use, Green Disposal, Green Design, And Green Manufacturing. It Also Illustrates How To Strategically Apply Green It In Practice In Several Areas.key Features:presents A Comprehensive Coverage Of Key Topics Of Importance And Practical Relevance{~} - Green Technologies, Design, Standards, Maturity Models, Strategies And Adoptionhighlights Several Useful Approaches To Embracing Green It In Several Areasfeatures Chapters Written By Accomplished Experts From Industry And Academia Who Have First-hand Knowledge And Expertise In Specific Areas Of Green Itpresents A Set Of Review And Discussion Questions For Each Chapter That Will Help The Readers To Examine And Explore The Green It Domain Furtherincludes A Companion Website Providing{~} Resources For Further Information And Presentation Slidesthis Book Will Be An Invaluable Resource For It Professionals, Academics, Students, Researchers, Project Leaders/managers, It Business Executives, Cios, Ctos And Anyone Interested In Green It And Harnessing It To Enhance Our Environment.},
  isbn       = {9781119970057},
  language   = {English},
  location   = {Uk},
  shorttitle = {Harnessing Green It}
}

@inproceedings{cioara-immune-inspired:2010,
  author    = {Cioara, T. And Pop, C.b. And Anghel, I. And Salomie, I. And Dinsoreanu, M. And Condor, I. And Mihaly, F.},
  title     = {Immune-inspired Technique For Optimizing Server's Energy Consumption},
  booktitle = {2010 IEEE International Conference On Intelligent Computer Communication And Processing (iccp)},
  year      = {2010},
  pages     = {273--280},
  month     = aug,
  abstract  = {This Paper Presents An Immune-inspired Technique For Optimizing A Server Energy Consumption. The Proposed Technique Is Similar With An Artificial Immune System Associated To A Server, Aiming To Detect Non-optimal Server Energy Consumption States And To Take The Appropriate Actions That Would Bring The Server Into An Optimal State. The Optimization Technique Has Two Main Stages: An Initialization Stage And A Self-optimization Stage. In The Initialization Stage The Server Is Monitored For A Specific Period Of Time To Collect Energy Consumption Historical Raw Data For Identifying Associations Between The Server Energy Consumption States And The Appropriate Optimization Actions. In The Self-optimization Stage, Energy Consumption Server State Snapshots Are Taken At Regular Time Intervals And Formally Represented Using A Biologically-inspired Antigen Model. The Obtained Antigen Is Then Classified As Self (optimal Energy Consumption State) Or Non-self (non-optimal Energy Consumption State) Using A Set Of Detectors Obtained In The Initialization Stage. For Non-self Antigens A Biologically-inspired Clonal Selection Approach Is Used To Determine The Actions That Need To Be Taken To Bring The Server In An Optimal Energy Consumption State.},
  doi       = {10.1109/ICCP.2010.5606424},
  keywords  = {Artificial Immune System, Artificial Immune Systems, Biologically-inspired Antigen Model, Biologically-inspired Clonal Selection Approach, Clonal Selection, Detectors, Energy Consumption, File Servers, Immune-inspired, Immune-inspired Technique, Immune System, Negative Selection, Nonoptimal Energy Consumption State, Nonoptimal Server Energy Consumption States, Optimization, Pathogens, Power Aware Computing, Self-optimization Stage, Self-optimizing, Server Energy Consumption Optimization, Servers}
}

@inproceedings{busse-who:2011,
  author    = {Busse, Daniela K.},
  title     = {Who Needs Energy Management},
  booktitle = {Chi '11 Extended Abstracts On Human Factors In Computing Systems},
  year      = {2011},
  series    = {Chi Ea '11},
  pages     = {1639--1644},
  publisher = {ACM},
  abstract  = {In This Work-in-progress Report, Research Into The Potential Target Users For An Industrial Energy Management Solution Is Being Discussed With Reference To Both On-site And Remote User Interviews Conducted In 2010 With Energy Managers Of Several Us Companies In High Energy-intensity Manufacturing Industries.},
  doi       = {10.1145/1979742.1979821},
  isbn      = {978-1-4503-0268-5},
  keywords  = {Enterprise, Industrial Energy Management, Manufacturing, Personas, Sustainability, User Interviews},
  location  = {New York, Ny, Usa},
  urldate   = {2014-05-13}
}

@article{bolla-potential:2011,
  author     = {Bolla, R. And Davoli, Franco And Bruschi, R. And Christensen, K. And Cucchietti, F. And Singh, S.},
  title      = {The Potential Impact Of Green Technologies In Next-generation Wireline Networks: Is There Room For Energy Saving Optimization?},
  journal    = {IEEE Communications Magazine},
  year       = {2011},
  volume     = {49},
  number     = {8},
  pages      = {80--86},
  month      = aug,
  abstract   = {Recently, Network Operators Around The World Reported Statistics Of Network Energy Requirements And The Related Carbon Footprint, Showing An Alarming And Growing Trend. Such High Energy Consumption Can Be Mainly Ascribed To Networking Equipment Designed To Work At Maximum Capacity With High And Almost Constant Dissipation, Independent Of The Traffic Load. However, Recent Developments Of Green Network Technologies Suggest The Chance To Build Future Devices Capable Of Adapting Their Performance And Energy Absorption To Meet Actual Workload And Operational Requirements. In Such A Scenario, This Contribution Aims At Evaluating The Potential Impact On Next-generation Wireline Networks Of Green Technologies In Economic And Environmental Terms. We Based Our Impact Analysis On The Real Network Energy-efficiency Targets Of An Ongoing European Project, And Applied Them To The Expected Deployment Of Telecom Italia Infrastructure By 2015-2020.},
  doi        = {10.1109/MCOM.2011.5978419},
  issn       = {0163-6804},
  keywords   = {Carbon Footprint, Communication Networks, Digital Subscriber Lines, Energy Absorption, Energy Conservation, Energy Consumption, Energy Efficiency, Energy Saving Optimization, Green Products, Green Technology, Network Energy-efficiency Targets, Network Energy Requirement, Networking Equipment, Next Generation Networks, Next-generation Wireline Networks, Performance Evaluation, Power Demand, Telecommunication Network Management, Telecommunication Traffic, Telecommunication Traffic, Traffic Load},
  shorttitle = {The Potential Impact Of Green Technologies In Next-generation Wireline Networks}
}

@inproceedings{mansley-robotic:2011,
  author    = {Mansley, C. And Connell, J. And Isci, C. And Lenchner, J. And Kephart, J.o. And Mcintosh, S. And Schappert, M.},
  title     = {Robotic Mapping And Monitoring Of Data Centers},
  booktitle = {2011 IEEE International Conference On Robotics And Automation (icra)},
  year      = {2011},
  pages     = {5905--5910},
  month     = may,
  abstract  = {We Describe An Inexpensive Autonomous Robot Capable Of Navigating Previously Unseen Data Centers And Monitoring Key Metrics Such As Air Temperature. The Robot Provides Real-time Navigation And Sensor Data To Commercial Ibm Software, Thereby Enabling Real-time Generation Of The Data Center Layout, A Thermal Map And Other Visualizations Of Energy Dynamics. Once It Has Mapped A Data Center, The Robot Can Efficiently Monitor It For Hot Spots And Other Anomalies Using Intelligent Sampling. We Demonstrate The Robot's Effectiveness Via Experimental Studies From Two Production Data Centers.},
  doi       = {10.1109/ICRA.2011.5980554},
  keywords  = {Autonomous Robot, Computer Centres, Computerised Monitoring, Cooling, Data Center Monitoring, Data Visualisation, Energy Dynamics Visualization, Ibm Software, Intelligent Sampling, Mobile Robots, Monitoring, Path Planning, Real Time Navigation, Robotic Mapping, Robot Sensing Systems, Robot Vision, Sensors, Temperature Sensors, Tiles}
}

@article{chen-advances:2012,
  author   = {Chen, Min And Vasilakos, Athanasios V. And Grace, David},
  title    = {Advances In Green Mobile Networks},
  journal  = {Mobile Networks And Applications},
  year     = {2012},
  volume   = {17},
  number   = {1},
  pages    = {1--3},
  month    = feb,
  doi      = {10.1007/s11036-011-0346-y},
  issn     = {1383-469X, 1572-8153},
  keywords = {Business Information Systems, Communications Engineering, Networks, Computer Communication Networks, Electrical Engineering},
  language = {En},
  urldate  = {2014-05-28}
}

@article{liu-hardware:2013,
  author   = {Liu, Qixiao And Moreto, Miquel And Jimenez, Victor And Abella, Jaume And Cazorla, Francisco J. And Valero, Mateo},
  title    = {Hardware Support For Accurate Per-task Energy Metering In Multicore Systems},
  journal  = {ACM Transactions On Architecture And Code Optimization},
  year     = {2013},
  volume   = {10},
  number   = {4},
  pages    = {341--3427},
  month    = dec,
  abstract = {Accurately Determining The Energy Consumed By Each Task In A System Will Become Of Prominent Importance In Future Multicore-based Systems Because It Offers Several Benefits, Including (i) Better Application Energy/performance Optimizations, (ii) Improved Energy-aware Task Scheduling, And (iii) Energy-aware Billing In Data Centers. Unfortunately, Existing Methods For Energy Metering In Multicores Fail To Provide Accurate Energy Estimates For Each Task When Several Tasks Run Simultaneously. This Article Makes A Case For Accurate Per-task Energy Metering (ptem) Based On Tracking The Resource Utilization And Occupancy Of Each Task. Different Hardware Implementations With Different Trade-offs Between Energy Prediction Accuracy And Hardware-implementation Complexity Are Proposed. Our Evaluation Shows That The Energy Consumed In A Multicore By Each Task Can Be Accurately Measured. For A 32-core, 2-way, Simultaneous Multithreaded Core Setup, Ptem Reduces The Average Accuracy Error From More Than 12% When Our Hardware Support Is Not Used To Less Than 4% When It Is Used. The Maximum Observed Error For Any Task In The Workload We Used Reduces From 58% Down To 9% When Our Hardware Support Is Used.},
  doi      = {10.1145/2541228.2555291},
  issn     = {1544-3566},
  keywords = {Chip Multiprocessors, Hardware Counters, Modeling And Estimation, Per-task Energy Attribution, Power Modeling, Simultaneous Multithreaded},
  urldate  = {2014-05-13}
}

@misc{opencompute:2011,
  author  = {Shaw, Mark},
  title   = {Server Design On Open Compute Project},
  year    = {2011},
  journal = {Open Compute},
  urldate = {2014-07-17}
}

@inproceedings{wijaya-symbolic:2013,
  author    = {Wijaya, Tri Kurniawan And Eberle, Julien And Aberer, Karl},
  title     = {Symbolic Representation Of Smart Meter Data},
  booktitle = {Proceedings Of The Joint Edbt/icdt 2013 Workshops},
  year      = {2013},
  series    = {Edbt '13},
  pages     = {242--248},
  publisher = {ACM},
  abstract  = {Currently Smart Meter Data Analytics Has Received Enormous Attention Because It Allows Utility Companies To Analyze Customer Consumption Behavior In Real Time. However, The Amount Of Data Generated By These Sensors Is Very Large. As A Result, Analytics Performed On Top Of It Become Very Expensive. Furthermore, Smart Meter Data Contains Very Detailed Energy Consumption Measurement Which Can Lead To Customer Privacy Breach And All Risks Associated With It. In This Work, We Address The Problem On How To Reduce Smart Meter Data Numerosity And Its Detailed Measurement While Maintaining Its Analytics Accuracy. We Convert The Data Into Symbolic Representation And Allow Various Machine Learning Algorithms To Be Performed On Top Of It. In Addition, Our Symbolic Representation Admit An Additional Advantage To Allow Also Algorithms Which Usually Work On Nominal And String To Be Run On Top Of Smart Meter Data. We Provide An Experiment For Classification And Forecasting Tasks Using Real-world Data. And Finally, We Illustrate Several Directions To Extend Our Work Further.},
  doi       = {10.1145/2457317.2457357},
  isbn      = {978-1-4503-1599-9},
  keywords  = {Classification, Data Management, Forecasting, Sensor Networks, Smart Meter, Symbolic Representation, Time Series},
  location  = {New York, Ny, Usa},
  urldate   = {2014-05-13}
}

@misc{facebook-code:2014,
  author   = {Bachar, Yuval And Simpkins, Adam},
  title    = {Introducing ``wedge'' And ``fboss'', The Next Steps Toward A Disaggregated Network},
  month    = jun,
  year     = {2014},
  abstract = {We{\textquoteright}re Big Believers In The Value Of Disaggregation -- Of Breaking Down Traditional Data Center Technologies Into Their Core Components So We Can Build New Systems That Are More Flexible, More Scalable, And More Efficient. This Approach Has Guided Facebook From The Beginning, As We{\textquoteright}ve Grown And Expanded Our Infrastructure To Connect More Than 1.28 Billion People Around The World.},
  journal  = {Facebook Code},
  urldate  = {2014-07-17}
}

@article{glanz-data:2012-1,
  author   = {Glanz, James},
  title    = {Data Centers In Rural Washington State Gobble Power},
  journal  = {The New York Times},
  year     = {2012},
  month    = sep,
  abstract = {When Internet Factories Come To Town, They Can Feel Less Like Their Sleek, Clean And Convenient Image And More Like Old-time Manufacturing.},
  chapter  = {Technology},
  issn     = {0362-4331},
  keywords = {Air Pollution, Cloud Computing, Cloud Factories The (series), Columbia River (pacific Northwest), Data Centers, Dell Inc, Diesel Power, Hydroelectric Power, Microsoft Corporation, Quincy (wash), Series, Washington (state), Yahoo! Inc},
  urldate  = {2014-05-31}
}

@misc{holzer-eco-friendly:2012,
  author   = {Holzer, Daniel},
  title    = {What Does Eco-friendly Mean?},
  year     = {2012},
  abstract = {In Recent Years, Terms Like ''going Green'' And ''eco-friendly'' Have Become Buzz Words On Talk Shows, Commercials And Product Packaging. The Term ''eco-friendly'' Has Been Used For ...},
  journal  = {Home Guides Textbar Sf Gate},
  urldate  = {2014-08-07}
}

@techreport{sacco:2006,
  author      = {Sacco, Peter},
  title       = {The Difference Between Data Centers And Computer Rooms},
  institution = {Global Knowledge},
  year        = {2006},
  type        = {White Paper 1},
  copyright   = {Todos Os Direitos Reservados},
  language    = {En-us},
  pages       = {09},
  series      = {Experts For Your Always Available Data Center},
  shorttitle  = {The Difference Between Data Centers And Computer Rooms},
  urldate     = {2014-08-15},
  url         = {http://datacentersblog.com/wp-content/uploads/2010/09/The-Difference-between-a-Data-Center-and-a-Computer-Room.pdf}
}

@techreport{neto:2013,
  author      = {Neto, Moacyr Franco},
  title       = {Os Principais Sistemas De Automa{\c{c}}{\~{a}}o De Data Centers Do Mercado - Dcim},
  institution = {Fazion Ltda},
  year        = {2013},
  type        = {White Paper},
  copyright   = {Todos Os Direitos Reservados},
  language    = {Portuguese},
  pages       = {17},
  shorttitle  = {Os Principais Sistemas De Automa{\c{c}}{\~{a}}o De Data Centers Do Mercado: Uma Vis{\~{a}}o T{\'{e}}cnica E Metodologias De Escolha},
  urldate     = {2014-10-04},
  url         = {http://www.fazion.com.br/netcom2013/moacyrfranco_doc1.pdf}
}


@book{balloni:2006,
  title      = {Por Que Gesiti: Por Que Gest{\~{a}}o Em Sistemas E Tecnologias De Informa{\c{c}}{\~{a}}o?},
  publisher  = {Komedi},
  year       = {2006},
  author     = {Balloni, A. (org )},
  isbn       = {9788575822852},
  langid     = {Portuguese},
  pagetotal  = {318},
  shorttitle = {Por Que Gesiti}
}

@techreport{emerson-energy:2012,
  author      = {Emerson-network, Power},
  title       = {Energy Logic 2.0 New Strategies For Cutting Data Center Energy Costs And Boosting Capacity},
  institution = {Emerson Network Power},
  year        = {2012},
  type        = {W.p.},
  number      = {03947-2012},
  abstract    = {A Number Of Associations, Consultants And Vendors Have Promoted Best Practices For Enhancing Data Center Energy Efficiency. These Practices Cover Everything From Facility Lighting To Cooling System Design, And Have Proven Useful In Helping Some Companies Slow Or Reverse The Trend Of Rising Data Center Energy Consumption. However, Most Organizations Still Lack A Cohesive, Holistic Approach For Reducing Data Center Energy Use.},
  keywords    = {Cooling Systems Design, Data Center, Efficiency, Energy Consumption},
  pages       = {39},
  shorttitle  = {Energy Logic 2},
  urldate     = {2014-10-10}
}

@misc{ccm-8,
  author     = {CCM},
  title      = {Incluir Cita{\c{c}}{\~{a}}o},
  year       = {8},
  keywords   = {Todo},
  shorttitle = {No Local Indicado}
}

@misc{sproutboard:2013,
  author  = {Sproutboard},
  title   = {Technical Overview Guides - Sproutboard},
  year    = {2013},
  url     = {http://www.sproutboard.com/technical-overview},
  urldate = {2015-05-01}
}

@misc{envmon:2013,
  author  = {Bubon, Robert J.},
  title   = {Envmon},
  month   = jul,
  year    = {2013},
  url     = {http://www.bigi.com/wiki/Envmon},
  urldate = {2015-05-01}
}

@misc{tombox:2011,
  author     = {Guardigli, Marco},
  title      = {Tombox : An Arduino Based Solution For Environmental Monitoring Of Datacenter Racks},
  month      = nov,
  year       = {2011},
  url        = {http://marco.guardigli.it/2010/05/arduino-in-datacenter-rack.html},
  urldate    = {2015-05-01}
}

@inproceedings{kohvakka-performance:2006,
  author    = {Kohvakka, Mikko And Kuorilehto, Mauri And H{\"{a}}nnik{\"{a}}inen, Marko And H{\"{a}}m{\"{a}}l{\"{a}}inen, Timo D.},
  title     = {Performance Analysis Of IEEE 802.15.4 And Zigbee For Large-scale Wireless Sensor Network Applications},
  booktitle = {Proceedings Of The 3\textsuperscript{rd} ACM International Workshop On Performance Evaluation Of Wireless Ad Hoc, Sensor And Ubiquitous Networks},
  year      = {2006},
  series    = {Pe-wasun '06},
  pages     = {48--57},
  address   = {New York, Ny, Usa},
  publisher = {ACM},
  acmid     = {1163619},
  doi       = {10.1145/1163610.1163619},
  isbn      = {1-59593-487-1},
  keywords  = {IEEE 802.15.4, Wpan, Zigbee, Cluster-tree, Performance Evaluation, Simulation, Wireless Networks},
  location  = {Terromolinos, Spain},
  numpages  = {10},
 }

@article{park-design:2013,
  author   = {Park, Sunghoi And Choi, Myeong-in And Kang, Byeongkwan And Park, Sehyun},
  title    = {Design And Implementation Of Smart Energy Management System For Reducing Power Consumption Using Zigbee Wireless Communication Module},
  journal  = {Procedia Computer Science},
  year     = {2013},
  volume   = {19},
  pages    = {662--668},
  abstract = {In This Paper, We Propose A Smart Energy Management System (sems) Which Functions As A Control Using A Motion Sensor And Setting Time Of Power Usage To Reduce Power Consumption. The Sems Not Only Supplies Power As The Way The Common Power Strips Do But Also Controls Sockets Of The Sems Using Zigbee Wireless Communication. A Test Bed For Experiment Consists Of A Motion Sensor, The Sems And Three Appliances Which Are Connected To The Sems And The Experiment Was Conducted For Five Days To Measure The Power Consumption Of Three Appliances With Regard To Both Functions. The Experimental Result Shows That The Power Consumption Of The Sems With Two Functions Is Considerably Reduced When Compared With The Power Consumption Of The Common Power Strip.},
  doi      = {10.1016/j.procs.2013.06.088},
  issn     = {1877-0509},
  keywords = {Motion Sensor, Power Strip, Socket, Zigbee Wireless Communication},
  series   = {The 4\textsuperscript{th} International Conference On Ambient Systems, Networks And Technologies (ant 2013), The 3\textsuperscript{rd} International Conference On Sustainable Energy Information Technology (seit-2013)},
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050913006960},
  urldate  = {2015-05-17}
}

@inproceedings{wireless:2011,
  author    = {Rodriguez, M.G. And Ortiz Uriarte, L.E. And Jia, Yi And Yoshii, K. And Ross, R. And Beckman, P.H.},
  title     = {Wireless Sensor Network For Datacenter Environmental Monitoring},
  booktitle = {2011 5\textsuperscript{th} Icst},
  year      = {2011},
  pages     = {533--537},
  month     = nov,
  abstract  = {Data Centers' Energy Consumption Has Attracted Global Attention Because Of The Fast Growth Of The Information Technology (it) Industry. Up To 60% Of The Energy Consumed In A Data Center Is Used For Cooling In Wasteful Ways As A Result Of Lack Of Environmental Information And Overcompensated Cooling Systems. In This Project, A Wireless Sensor Network For Data-enter Environmental Monitoring Was Developed To Improve Energy Efficiency And To Optimize Data-center Performance. The Sensor Network Consists Of A Suite Of Sensor Nodes For Data Sensing, A Router Node To Relay Sensed Data, And A Coordinator Node To Establish A Network, Receive The Data, And Process The Data. The Prototype Sensor Network Was Built On Arduino Open Source Hardware With A Seamlessly Integrated Xbee Rf Module And Configured To Operate Within The Zigbee Mesh Network Standard. A 24-hour Test Run At Argonne's Data Center Demonstrated That The Wireless Networked Environmental Monitoring Solution Is Easy To Integrate And Manage With The Existing It Infrastructure, While Delivering Better Visibility Into The Data Center's 3d Temperature And Humidity Distribution And Substantial Improvements In Energy Efficiency.},
  doi       = {10.1109/ICSensT.2011.6137036},
  keywords  = {Arduino Open Source Hardware, Argonne Data Center 3d Temperature, Computer Centres, Cooling, Coordinator Node, Data Center, Data Center Energy Consumption, Data Center Environmental Monitoring, Data Center Performance Optimization, Energy Conservation, Energy Consumption, Energy Efficiency, Energy Efficiency Management, Environmental Information, Environmental Monitoring, Humidity, Humidity Distribution, Information Technology, Information Technology Industry, Integratedxbee Rf Module, It Infrastructure, Monitoring, Overcompensated Cooling System, Sensor Node, Temperature Distribution, Temperature Sensors, Wireless Communication, Wireless Mesh Networks, Wireless Networked Environmental Monitoring Solution, Wireless Sensor Network, Wireless Sensor Networks, Zigbee, Zigbee Mesh Network Standard}
}

@misc{aws:2018,
	author={Amazon},
	title={Amazon Web Services},
	url={https://aws.amazon.com},
	year={2018},
	urldate = {maio/2018}
}

@misc{google:2018,
	author={Google},
	title={Google Cloud Platform},
	url={https://cloud.google.com/},
	year={2018},
	urldate = {maio/2018}
}

@misc{heroku:2018,
	author={Heroku},
	title={Heroku},
	url={https://www.heroku.com},
	year={2018},
	urldate = {maio/2018}
}

@misc{ibm:2018,
	author={IBM},
	title={IBM Cloud},
	url={https://www.ibm.com/cloud/},
	year={2018},
	urldate = {maio/2018}
}

@misc{azure:2018,
	author={Microsoft},
	title={Microsoft Azure},
	url={https://azure.microsoft.com},
	year={2018},
	urldate = {maio/2018}
}

@misc{a:2018,
	author={a},
	title={a},
	url={a},
	year={2018},
	urldate = {maio/2018}
}

@Comment{ My articles }

@misc{camargo-automacao-latino:2014,
	author  = {Camargo, Daniel Scheidemantel And Miers, Charles Christian},
	title   = {Automa{\c{c}}{\~{a}}o Clim{\'{a}}tica Em Sala De Servidores Utilizando Hardware Livre},
	year    = {2014},
	journal = {Apresenta{\c{c}}{\~{a}}o De Palestra, Latinoware/PR}
      }

@article{camargo-monitoramento-eradrj:2015,
	author  = {Camargo, Daniel Scheidemantel And Miers, Charles Christian},
	title   = {Monitoramento Ambiental Open Source Para Data Center},
	journal = {SBC - Erad-RJ},
	year    = {2015}
}

@article{camargo-sensoriamento-cotb:2015,
	author  = {Camargo, Daniel Scheidemantel And Miers, Charles Christian},
	title   = {Sensoriamento Clim{\'{a}}tico Em Sala De Servidores Utilizando Solu{\c{c}}{\~{o}}es De Software E Hardware Livre},
	journal = {Anais Do Computer On The Beach},
	year    = {2015},
	pages   = {389--391}
}

@article{camargo-automacao-eradrs:2015,
	author  = {Camargo, Daniel Scheidemantel And Miers, Charles Christian},
	title   = {Automa{\c{c}}{\~{a}}o Clim{\'{a}}tica Em Sala De Servidores Utilizando Hardware Livre},
	journal = {SBC - Erad-RS},
	year    = {2015},
	pages   = {177--180}
}

@article{camargo-sensoriamento-sic:2015,
	author  = {Camargo, Daniel Scheidemantel And Miers, Charles Christian},
	title   = {Sensoriamento Em Sala De Servidores Baseado Em Software E Hardware Livres},
	journal = {Sic-udesc},
	year    = {2015}
}

@inproceedings{camargo-greenhop::2016,
	title = {{GreenHop}: {Open} source {PUE} continuous monitoring for small and medium data centers},
	shorttitle = {{GreenHop}},
	doi = {10.1109/CLEI.2016.7833381},
	abstract = {This paper presents the GreenHop solution, focused on energy and environmental monitoring in small and medium size Data Centers (DCs). The solution enables the DC administrator to monitor the DC PUE (Power Usage Effectiveness) and maintain the environmental parameters in compliance with standards and good practice guidances. The solution is applied in a case study, showing the consumption of the cooling equipment when setting the DC operating temperature on 18°C, 23°C, 25°C, and free cooling. Thus, we identified an improvement on PUE and reduction of power consumption as a result of the adoption GreenHop monitoring solution.},
	booktitle = {2016 {XLII} {Latin} {American} {Computing} {Conference} ({CLEI})},
	author = {Camargo, D. S. and Miers, C. C.},
	year = {2016},
	keywords = {computer centres, cooling, cooling equipment, Data center, Electronic mail, Energy efficiency, energy monitoring, environmental monitoring, free cooling, Green computing, GreenHop monitoring solution, Green products, Hardware, medium data centers, Open Source, open source PUE continuous monitoring, power aware computing, power consumption reduction, power usage effectiveness, PUE, small data centers, temperature 18 degC, temperature 23 degC, temperature 25 degC, Uninterruptible power systems},
	pages = {1--12},
	file = {Camargo e Miers - 2016 - GreenHop Open source PUE continuous monitoring fo.pdf:/home/dani/Insync/Zotero/storage/2W2GDQIH/Camargo e Miers - 2016 - GreenHop Open source PUE continuous monitoring fo.pdf:application/pdf;IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/6SPUXU67/7833381.html:text/html}
}

@inproceedings{camargo-greenhop::2016-1,
	title = {{GreenHop}: {Open} source environmental monitoring for small and medium data centers},
	shorttitle = {{GreenHop}},
	doi = {10.1109/SCCC.2016.7836064},
	abstract = {Several organizations carry out the execution of their systems and data processing services in local processing centers, i.e., data centers (DC). However, small to medium - sized organizations usually do not have technical and financial conditions to monitor the climatic conditions of their DC. Thus, this may imply from excessive energy costs, drastic reduction of the life spam of the equipment and the incorrect processing of data and systems. In this paper we present the open source based solution GreenHop that aims to perform environmental monitoring of the DC server room. This paper presents four tests with different temperature settings, which is also included the application of free cooling method. We present a comparison of the energy impact of all settings. Thus, we aim to provide ambiental monitoring of the DC server room while we keep the system customizable to implement and replicate.},
	booktitle = {2016 35th {International} {Conference} of the {Chilean} {Computer} {Science} {Society} ({SCCC})},
	author = {Camargo, D. S. and Miers, C. C. and Koslovski, G. P. and Pillon, M. A.},
	year = {2016},
	keywords = {computer centres, cooling, Data center, DC climatic conditions, DC server room environmental monitoring, Energy efficiency, energy impact, environmental monitoring, free cooling method, Green computing, GreenHop, Green products, Hardware, local processing centers, medium data centers, Open Source, open source environmental monitoring, Organizations, power aware computing, small data centers, Software},
	pages = {1--12},
	file = {Camargo et al. - 2016 - GreenHop Open source environmental monitoring for.pdf:/home/dani/Insync/Zotero/storage/P273GE2G/Camargo et al. - 2016 - GreenHop Open source environmental monitoring for.pdf:application/pdf;IEEE Xplore Abstract Record:/home/dani/Insync/Zotero/storage/82QZEXVU/7836064.html:text/html}
}

@article{camargo-meharcen:2017,
	title = {{MeHarCEn}: {Um} {Método} de {Harmonização} do {Consumo} de {Energia} em {Data} {Centers}},
	volume = {24},
	copyright = {Direitos autorais 2017 Revista de Informática Teórica e Aplicada},
	issn = {21752745},
	shorttitle = {{MeHarCEn}},
	url = {http://seer.ufrgs.br/index.php/rita/article/view/VOL24-NR2-47},
	doi = {10.22456/2175-2745.76460},
	abstract = {O consumo energético controlado e eficiente é um desafio enfrentado diariamente pelos gestores de Data Centers de pequeno, médio e grande porte. A literatura especializada e técnica define diversos guias, equipamentos e mecanismos para essa finalidade. Entretanto, a aplicação combinada dessas soluções é uma tarefa complexa, que, em muitos casos, requer um elevado investimento financeiro. Nesse contexto, o presente trabalho propõe o MeHarCEn, uma iniciativa para gerenciamento combinado e harmônico do consumo de energia em Data Centers. MeHarCEn não depende de soluções proprietárias e pode ser adaptado a Data Centers com configurações distintas. Aplicado a um estudo de caso, um DC de pequeno porte, o MeHarCEn resulta em uma economia de 52,7\% no consumo de energia com climatização.},
	language = {pt},
	number = {2},
	urldate = {2017-12-10},
	journal = {Revista de Informática Teórica e Aplicada},
	author = {Camargo, Daniel Scheidemantel and Miers, Charles Christian and Pillon, Maurício Aronne and Koslovski, Guilherme Piêgas},
	month = dec,
	year = {2017},
	pages = {47--70},
	file = {Camargo et al. - 2017 - MeHarCEn Um Método de Harmonização do Consumo de .pdf:/home/daniel/Insync/Zotero/storage/PGZC7FXT/Camargo et al. - 2017 - MeHarCEn Um Método de Harmonização do Consumo de .pdf:application/pdf}
}
file:///home/daniel/Insync/Zotero/storage/PGZC7FXT/Camargo%20et%20al.%20-%202017%20-%20MeHarCEn%20Um%20M%C3%A9todo%20de%20Harmoniza%C3%A7%C3%A3o%20do%20Consumo%20de%20.pdf/home/daniel/Insync/Zotero/storage/ETPZ7F9Z/Camargo%20et%20al.%20-%202017%20-%20MeHarCEn%20Um%20M%C3%A9todo%20de%20Harmoniza%C3%A7%C3%A3o%20do%20Consumo%20de%20.html
@inproceedings{artigo-denivy:2017,
	address = {Cutiba/PR/Brazil},
	title = {{EAVIRA}: {Energy}-{Aware} {Virtual} {Infrastructure} {Reallocation} {Algorithm}},
	abstract = {The elastic provisioning of virtual infrastructures enables a dynamic management of cloud resources. Elasticity enables the setup of virtualized resources (computing and communication) in order to meet the hosted application's requirements. Thus, to perform elasticity requests, providers usually rely on reallocation mechanisms and policies. The concerns regarding the environment and the operational costs indicates energy consumption of the data centers as recurring topic in providers policies. Moreover, energy-aware provisioning is beneficial for tenants also. Recent cost models have introduced an implicit incentive to computing and networking resources usage just when requested to avoid high rent costs. In this paper we propose EAVIRA algorithm, which takes into account the proportional sharing of CPU usage of data center servers to calculate individual usage costs to: disable idle equipments, and reallocate virtual infrastructures. EAVIRA acts on online requests for elasticity configuration and performs an offline load balancing, triggered by the IaaS provider. Our experimental analysis indicates a reduction of energy consumption and an increasing on acceptance ratio of allocation requests.},
	booktitle = {Proceedings {SBESC} 2017},
	author = {Ruck, Denivy and Miers, Charles and Pillon, Mauricio Aronne and Koslovski, Guilherme},
	month = {nov},
	year = {2017},
	keywords = {Resource management, Energy and Thermal Aware Systems, Power},
	pages = {14}
}


@Comment{jabref-meta: databaseType:bibtex;}
